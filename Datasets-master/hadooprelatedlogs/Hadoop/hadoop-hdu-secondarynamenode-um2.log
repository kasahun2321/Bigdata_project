2019-08-01 15:07:20,454 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.56.102
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-01 15:07:20,472 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-01 15:07:21,275 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-01 15:07:21,384 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-01 15:07:21,384 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-01 15:07:21,542 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-hdu/dfs/namesecondary/in_use.lock acquired by nodename 5960@um2
2019-08-01 15:07:21,544 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-01 15:07:21,548 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-01 15:07:21,581 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-01 15:07:21,581 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-01 15:07:21,583 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-01 15:07:21,584 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 01 15:07:21
2019-08-01 15:07:21,586 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-01 15:07:21,586 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-01 15:07:21,588 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2019-08-01 15:07:21,588 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-01 15:07:21,609 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-01 15:07:21,609 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-01 15:07:21,609 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-01 15:07:21,609 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-01 15:07:21,609 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-01 15:07:21,609 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-01 15:07:21,609 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-01 15:07:21,610 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-01 15:07:21,610 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-01 15:07:21,610 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-01 15:07:21,610 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-01 15:07:21,610 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-01 15:07:21,611 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-01 15:07:22,115 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-01 15:07:22,115 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-01 15:07:22,115 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2019-08-01 15:07:22,115 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-01 15:07:22,115 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-01 15:07:22,120 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-01 15:07:22,120 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-01 15:07:22,120 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2019-08-01 15:07:22,123 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-01 15:07:22,124 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-01 15:07:22,124 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-01 15:07:22,124 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-01 15:07:22,125 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-01 15:07:22,125 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-01 15:07:22,125 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-01 15:07:22,140 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-01 15:07:22,218 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-01 15:07:22,220 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-01 15:07:22,237 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-01 15:07:22,243 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-01 15:07:22,244 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-01 15:07:22,244 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-01 15:07:22,264 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-01 15:07:22,264 INFO org.mortbay.log: jetty-6.1.26
2019-08-01 15:07:22,548 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-01 15:07:22,548 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-01 15:07:22,548 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-08-01 15:07:22,548 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-01 15:08:22,779 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-08-01 15:08:22,997 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=0&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-01 15:08:23,081 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-08-01 15:08:23,491 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.08s at 0.00 KB/s
2019-08-01 15:08:23,491 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 320 bytes.
2019-08-01 15:08:23,502 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1&endTxId=3&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-01 15:08:23,506 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-01 15:08:23,506 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000003_0000000000015169501 size 0 bytes.
2019-08-01 15:08:23,589 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-08-01 15:08:23,627 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-08-01 15:08:23,627 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage_0000000000000000000
2019-08-01 15:08:23,628 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-08-01 15:08:23,641 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-08-01 15:08:23,646 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000003 expecting start txid #1
2019-08-01 15:08:23,646 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000003
2019-08-01 15:08:23,702 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000003 of size 114 edits # 3 loaded in 0 seconds
2019-08-01 15:08:23,706 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000003 using no compression
2019-08-01 15:08:23,799 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000003 of size 397 bytes saved in 0 seconds.
2019-08-01 15:08:23,813 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-hdu/dfs/namesecondary
2019-08-01 15:08:23,933 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3 to namenode at http://um1:50070 in 0.099 seconds
2019-08-01 15:08:23,933 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 397
2019-08-01 15:13:55,411 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-08-01 15:13:55,412 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.56.102
************************************************************/
2019-08-01 15:15:46,800 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.56.102
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-01 15:15:46,822 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-01 15:15:47,664 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-01 15:15:47,765 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-01 15:15:47,765 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-01 15:15:47,978 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-hdu/dfs/namesecondary/in_use.lock acquired by nodename 6608@um2
2019-08-01 15:15:48,054 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-01 15:15:48,062 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-01 15:15:48,111 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-01 15:15:48,111 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-01 15:15:48,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-01 15:15:48,114 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 01 15:15:48
2019-08-01 15:15:48,115 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-01 15:15:48,115 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-01 15:15:48,117 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2019-08-01 15:15:48,117 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-01 15:15:48,137 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-01 15:15:48,137 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-01 15:15:48,137 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-01 15:15:48,137 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-01 15:15:48,137 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-01 15:15:48,137 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-01 15:15:48,138 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-01 15:15:48,138 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-01 15:15:48,145 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-01 15:15:48,145 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-01 15:15:48,145 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-01 15:15:48,146 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-01 15:15:48,147 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-01 15:15:48,734 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-01 15:15:48,734 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-01 15:15:48,734 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2019-08-01 15:15:48,734 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-01 15:15:48,735 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-01 15:15:48,746 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-01 15:15:48,746 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-01 15:15:48,747 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2019-08-01 15:15:48,747 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-01 15:15:48,760 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-01 15:15:48,760 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-01 15:15:48,760 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-01 15:15:48,762 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-01 15:15:48,762 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-01 15:15:48,763 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-01 15:15:48,779 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-01 15:15:48,847 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-01 15:15:48,853 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-01 15:15:48,869 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-01 15:15:48,870 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-01 15:15:48,870 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-01 15:15:48,871 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-01 15:15:48,899 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-01 15:15:48,899 INFO org.mortbay.log: jetty-6.1.26
2019-08-01 15:15:49,237 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-01 15:15:49,238 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-01 15:15:49,238 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-08-01 15:15:49,238 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-01 15:16:49,605 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-08-01 15:16:49,854 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=3&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-01 15:16:49,919 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-08-01 15:16:50,194 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-08-01 15:16:50,194 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000003 size 397 bytes.
2019-08-01 15:16:50,208 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=4&endTxId=43&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-01 15:16:50,249 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 29257.14 KB/s
2019-08-01 15:16:50,249 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000004-0000000000000000043_0000000000015676207 size 0 bytes.
2019-08-01 15:16:50,250 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=44&endTxId=73&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-01 15:16:50,255 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1000.00 KB/s
2019-08-01 15:16:50,255 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000044-0000000000000000073_0000000000015676249 size 0 bytes.
2019-08-01 15:16:50,315 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 2 INodes.
2019-08-01 15:16:50,344 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-08-01 15:16:50,344 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 3 from /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage_0000000000000000003
2019-08-01 15:16:50,344 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-08-01 15:16:50,348 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2019-08-01 15:16:50,355 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000004-0000000000000000043 expecting start txid #4
2019-08-01 15:16:50,355 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000004-0000000000000000043
2019-08-01 15:16:50,431 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000004-0000000000000000043 of size 1048576 edits # 40 loaded in 0 seconds
2019-08-01 15:16:50,431 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000044-0000000000000000073 expecting start txid #44
2019-08-01 15:16:50,431 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000044-0000000000000000073
2019-08-01 15:16:50,440 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000044-0000000000000000073 of size 3016 edits # 30 loaded in 0 seconds
2019-08-01 15:16:50,444 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000073 using no compression
2019-08-01 15:16:50,574 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000073 of size 1522 bytes saved in 0 seconds.
2019-08-01 15:16:50,586 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3
2019-08-01 15:16:50,586 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-hdu/dfs/namesecondary/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-08-01 15:16:50,641 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 73 to namenode at http://um1:50070 in 0.043 seconds
2019-08-01 15:16:50,641 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1522
2019-08-01 15:22:43,114 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-08-01 15:22:43,116 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.56.102
************************************************************/
2019-08-01 19:51:46,528 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.56.102
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-01 19:51:46,549 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-01 19:51:47,435 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-01 19:51:47,547 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-01 19:51:47,547 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-01 19:51:47,764 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-hdu/dfs/namesecondary/in_use.lock acquired by nodename 2490@um2
2019-08-01 19:51:47,769 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-01 19:51:47,775 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-01 19:51:47,813 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-01 19:51:47,813 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-01 19:51:47,814 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-01 19:51:47,816 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 01 19:51:47
2019-08-01 19:51:47,817 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-01 19:51:47,817 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-01 19:51:47,818 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2019-08-01 19:51:47,818 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-01 19:51:47,845 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-01 19:51:47,845 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-01 19:51:47,845 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-01 19:51:47,845 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-01 19:51:47,845 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-01 19:51:47,845 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-01 19:51:47,845 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-01 19:51:47,846 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-01 19:51:47,846 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-01 19:51:47,846 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-01 19:51:47,846 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-01 19:51:47,847 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-01 19:51:47,849 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-01 19:51:48,734 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-01 19:51:48,734 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-01 19:51:48,734 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2019-08-01 19:51:48,734 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-01 19:51:48,735 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-01 19:51:48,762 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-01 19:51:48,762 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-01 19:51:48,762 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2019-08-01 19:51:48,776 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-01 19:51:48,777 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-01 19:51:48,777 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-01 19:51:48,777 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-01 19:51:48,778 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-01 19:51:48,778 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-01 19:51:48,778 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-01 19:51:48,806 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-01 19:51:48,977 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-01 19:51:48,984 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-01 19:51:49,003 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-01 19:51:49,017 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-01 19:51:49,017 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-01 19:51:49,017 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-01 19:51:49,078 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-01 19:51:49,078 INFO org.mortbay.log: jetty-6.1.26
2019-08-01 19:51:49,608 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-01 19:51:49,608 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-01 19:51:49,608 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-08-01 19:51:49,608 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-01 19:56:45,142 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-08-01 19:56:45,147 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.56.102
************************************************************/
2019-08-01 19:57:22,795 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.56.102
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-01 19:57:22,813 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-01 19:57:23,682 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-01 19:57:23,783 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-01 19:57:23,783 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-01 19:57:23,939 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-hdu/dfs/namesecondary/in_use.lock acquired by nodename 3421@um2
2019-08-01 19:57:23,941 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-01 19:57:23,945 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-01 19:57:23,975 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-01 19:57:23,975 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-01 19:57:23,976 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-01 19:57:23,977 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 01 19:57:23
2019-08-01 19:57:23,978 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-01 19:57:23,978 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-01 19:57:23,980 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2019-08-01 19:57:23,980 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-01 19:57:23,997 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-01 19:57:23,997 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-01 19:57:23,997 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-01 19:57:23,997 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-01 19:57:23,997 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-01 19:57:23,997 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-01 19:57:23,997 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-01 19:57:23,997 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-01 19:57:24,001 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-01 19:57:24,001 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-01 19:57:24,001 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-01 19:57:24,001 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-01 19:57:24,003 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-01 19:57:24,918 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-01 19:57:24,919 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-01 19:57:24,919 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2019-08-01 19:57:24,919 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-01 19:57:24,920 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-01 19:57:24,941 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-01 19:57:24,941 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-01 19:57:24,941 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2019-08-01 19:57:24,942 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-01 19:57:24,944 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-01 19:57:24,944 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-01 19:57:24,948 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-01 19:57:24,950 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-01 19:57:24,950 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-01 19:57:24,950 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-01 19:57:24,979 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-01 19:57:25,131 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-01 19:57:25,144 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-01 19:57:25,170 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-01 19:57:25,178 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-01 19:57:25,178 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-01 19:57:25,178 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-01 19:57:25,227 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-01 19:57:25,227 INFO org.mortbay.log: jetty-6.1.26
2019-08-01 19:57:25,931 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-01 19:57:25,931 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-01 19:57:25,932 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-08-01 19:57:25,932 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-01 19:59:00,438 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-08-01 19:59:00,443 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.56.102
************************************************************/
2019-08-01 20:00:35,847 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.56.102
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-01 20:00:35,869 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-01 20:00:36,829 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-01 20:00:37,007 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-01 20:00:37,008 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-01 20:00:37,194 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-hdu/dfs/namesecondary/in_use.lock acquired by nodename 4079@um2
2019-08-01 20:00:37,197 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-01 20:00:37,201 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-01 20:00:37,234 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-01 20:00:37,234 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-01 20:00:37,235 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-01 20:00:37,236 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 01 20:00:37
2019-08-01 20:00:37,237 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-01 20:00:37,237 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-01 20:00:37,239 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2019-08-01 20:00:37,240 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-01 20:00:37,261 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-01 20:00:37,261 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-01 20:00:37,261 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-01 20:00:37,261 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-01 20:00:37,261 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-01 20:00:37,261 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-01 20:00:37,261 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-01 20:00:37,261 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-01 20:00:37,263 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-01 20:00:37,263 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-01 20:00:37,263 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-01 20:00:37,264 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-01 20:00:37,265 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-01 20:00:37,761 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-01 20:00:37,761 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-01 20:00:37,762 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2019-08-01 20:00:37,762 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-01 20:00:37,762 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-01 20:00:37,767 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-01 20:00:37,767 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-01 20:00:37,767 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2019-08-01 20:00:37,771 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-01 20:00:37,772 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-01 20:00:37,772 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-01 20:00:37,772 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-01 20:00:37,773 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-01 20:00:37,773 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-01 20:00:37,773 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-01 20:00:37,787 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-01 20:00:37,860 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-01 20:00:37,866 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-01 20:00:37,880 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-01 20:00:37,889 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-01 20:00:37,889 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-01 20:00:37,889 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-01 20:00:37,900 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-01 20:00:37,900 INFO org.mortbay.log: jetty-6.1.26
2019-08-01 20:00:38,224 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-01 20:00:38,225 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-01 20:00:38,225 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-08-01 20:00:38,225 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-01 20:14:08,205 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.56.102
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-01 20:14:08,226 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-01 20:14:09,081 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-01 20:14:09,210 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-01 20:14:09,210 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-01 20:14:09,426 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-hdu/dfs/namesecondary/in_use.lock acquired by nodename 2660@um2
2019-08-01 20:14:09,430 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-01 20:14:09,436 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-01 20:14:09,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-01 20:14:09,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-01 20:14:09,475 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-01 20:14:09,479 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 01 20:14:09
2019-08-01 20:14:09,480 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-01 20:14:09,480 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-01 20:14:09,481 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2019-08-01 20:14:09,481 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-01 20:14:09,494 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-01 20:14:09,494 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-01 20:14:09,494 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-01 20:14:09,494 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-01 20:14:09,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-01 20:14:09,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-01 20:14:09,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-01 20:14:09,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-01 20:14:09,495 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-01 20:14:09,495 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-01 20:14:09,495 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-01 20:14:09,496 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-01 20:14:09,501 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-01 20:14:09,990 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-01 20:14:09,990 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-01 20:14:09,995 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2019-08-01 20:14:09,996 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-01 20:14:09,996 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-01 20:14:10,001 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-01 20:14:10,001 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-01 20:14:10,001 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2019-08-01 20:14:10,008 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-01 20:14:10,009 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-01 20:14:10,009 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-01 20:14:10,009 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-01 20:14:10,010 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-01 20:14:10,010 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-01 20:14:10,010 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-01 20:14:10,023 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-01 20:14:10,092 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-01 20:14:10,094 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-01 20:14:10,106 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-01 20:14:10,113 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-01 20:14:10,113 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-01 20:14:10,113 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-01 20:14:10,131 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-01 20:14:10,131 INFO org.mortbay.log: jetty-6.1.26
2019-08-01 20:14:10,405 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-01 20:14:10,405 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-01 20:14:10,405 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-08-01 20:14:10,406 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-01 21:08:11,286 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-08-01 21:08:11,465 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=74&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-01 21:08:11,533 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-08-01 21:08:11,774 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 20.00 KB/s
2019-08-01 21:08:11,774 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000074 size 1522 bytes.
2019-08-01 21:08:11,781 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=75&endTxId=103&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-01 21:08:11,809 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 40960.00 KB/s
2019-08-01 21:08:11,810 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000075-0000000000000000103_0000000000003629381 size 0 bytes.
2019-08-01 21:08:11,810 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=104&endTxId=188&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-01 21:08:11,833 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 51200.00 KB/s
2019-08-01 21:08:11,833 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000104-0000000000000000188_0000000000003629410 size 0 bytes.
2019-08-01 21:08:11,833 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=189&endTxId=356&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-01 21:08:11,850 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 68266.67 KB/s
2019-08-01 21:08:11,851 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000189-0000000000000000356_0000000000003629433 size 0 bytes.
2019-08-01 21:08:11,851 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=357&endTxId=488&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-01 21:08:11,863 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 7500.00 KB/s
2019-08-01 21:08:11,863 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000357-0000000000000000488_0000000000003629451 size 0 bytes.
2019-08-01 21:08:11,909 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 18 INodes.
2019-08-01 21:08:11,951 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-08-01 21:08:11,951 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 74 from /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage_0000000000000000074
2019-08-01 21:08:11,951 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-08-01 21:08:11,961 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 4 stream(s).
2019-08-01 21:08:11,965 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000075-0000000000000000103 expecting start txid #75
2019-08-01 21:08:11,965 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000075-0000000000000000103
2019-08-01 21:08:12,058 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000075-0000000000000000103 of size 1048576 edits # 29 loaded in 0 seconds
2019-08-01 21:08:12,059 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000104-0000000000000000188 expecting start txid #104
2019-08-01 21:08:12,060 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000104-0000000000000000188
2019-08-01 21:08:12,096 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000104-0000000000000000188 of size 1048576 edits # 85 loaded in 0 seconds
2019-08-01 21:08:12,096 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000189-0000000000000000356 expecting start txid #189
2019-08-01 21:08:12,096 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000189-0000000000000000356
2019-08-01 21:08:12,126 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000189-0000000000000000356 of size 1048576 edits # 168 loaded in 0 seconds
2019-08-01 21:08:12,126 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000357-0000000000000000488 expecting start txid #357
2019-08-01 21:08:12,126 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000357-0000000000000000488
2019-08-01 21:08:12,153 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000357-0000000000000000488 of size 15800 edits # 132 loaded in 0 seconds
2019-08-01 21:08:12,161 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000488 using no compression
2019-08-01 21:08:12,241 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000488 of size 6059 bytes saved in 0 seconds.
2019-08-01 21:08:12,249 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-hdu/dfs/namesecondary
2019-08-01 21:08:12,291 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 488 to namenode at http://um1:50070 in 0.027 seconds
2019-08-01 21:08:12,291 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 6059
2019-08-01 22:08:12,966 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-08-01 22:08:12,966 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=489&endTxId=579&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-01 22:08:12,971 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 5000.00 KB/s
2019-08-01 22:08:12,971 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000489-0000000000000000579_0000000000007230567 size 0 bytes.
2019-08-01 22:08:12,971 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-08-01 22:08:12,971 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000489-0000000000000000579 expecting start txid #489
2019-08-01 22:08:12,971 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000489-0000000000000000579
2019-08-01 22:08:12,995 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000489-0000000000000000579 of size 11259 edits # 91 loaded in 0 seconds
2019-08-01 22:08:12,997 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000579 using no compression
2019-08-01 22:08:13,012 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000579 of size 6776 bytes saved in 0 seconds.
2019-08-01 22:08:13,016 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 488
2019-08-01 22:08:13,017 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-hdu/dfs/namesecondary/current/fsimage_0000000000000000074, cpktTxId=0000000000000000074)
2019-08-01 22:08:13,029 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 579 to namenode at http://um1:50070 in 0.01 seconds
2019-08-01 22:08:13,029 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 6776
2019-08-02 08:18:33,431 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.56.102
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-02 08:18:33,451 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-02 08:18:34,351 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-02 08:18:34,454 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-02 08:18:34,454 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-02 08:18:34,657 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-hdu/dfs/namesecondary/in_use.lock acquired by nodename 3795@um2
2019-08-02 08:18:34,661 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-02 08:18:34,667 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-02 08:18:34,708 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-02 08:18:34,708 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-02 08:18:34,709 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-02 08:18:34,710 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 02 08:18:34
2019-08-02 08:18:34,714 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-02 08:18:34,714 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-02 08:18:34,716 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2019-08-02 08:18:34,716 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-02 08:18:34,725 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-02 08:18:34,725 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-02 08:18:34,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-02 08:18:34,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-02 08:18:34,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-02 08:18:34,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-02 08:18:34,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-02 08:18:34,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-02 08:18:34,726 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-02 08:18:34,726 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-02 08:18:34,726 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-02 08:18:34,727 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-02 08:18:34,728 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-02 08:18:35,250 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-02 08:18:35,250 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-02 08:18:35,253 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2019-08-02 08:18:35,253 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-02 08:18:35,253 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-02 08:18:35,259 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-02 08:18:35,259 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-02 08:18:35,259 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2019-08-02 08:18:35,263 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-02 08:18:35,264 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-02 08:18:35,264 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-02 08:18:35,264 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-02 08:18:35,265 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-02 08:18:35,265 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-02 08:18:35,265 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-02 08:18:35,280 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-02 08:18:35,392 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-02 08:18:35,395 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-02 08:18:35,408 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-02 08:18:35,416 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-02 08:18:35,416 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-02 08:18:35,416 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-02 08:18:35,441 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-02 08:18:35,441 INFO org.mortbay.log: jetty-6.1.26
2019-08-02 08:18:35,697 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-02 08:18:35,697 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-02 08:18:35,697 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-08-02 08:18:35,697 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-02 08:19:35,905 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-08-02 08:19:36,093 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=580&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-02 08:19:36,176 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-08-02 08:19:36,473 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.07s at 82.19 KB/s
2019-08-02 08:19:36,474 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000580 size 6776 bytes.
2019-08-02 08:19:36,485 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=581&endTxId=584&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-02 08:19:36,490 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-02 08:19:36,490 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000581-0000000000000000584_0000000000004433114 size 0 bytes.
2019-08-02 08:19:36,551 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 82 INodes.
2019-08-02 08:19:36,618 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-08-02 08:19:36,618 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 580 from /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage_0000000000000000580
2019-08-02 08:19:36,618 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-08-02 08:19:36,629 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-08-02 08:19:36,640 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000581-0000000000000000584 expecting start txid #581
2019-08-02 08:19:36,640 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000581-0000000000000000584
2019-08-02 08:19:36,688 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000581-0000000000000000584 of size 189 edits # 4 loaded in 0 seconds
2019-08-02 08:19:36,706 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000584 using no compression
2019-08-02 08:19:36,849 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000584 of size 6897 bytes saved in 0 seconds.
2019-08-02 08:19:36,863 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-hdu/dfs/namesecondary
2019-08-02 08:19:36,907 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 584 to namenode at http://um1:50070 in 0.034 seconds
2019-08-02 08:19:36,907 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 6897
2019-08-02 08:38:27,280 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-08-02 08:38:27,281 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.56.102
************************************************************/
2019-08-02 08:41:08,133 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.56.102
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-02 08:41:08,154 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-02 08:41:08,941 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-02 08:41:09,036 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-02 08:41:09,036 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-02 08:41:09,197 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-hdu/dfs/namesecondary/in_use.lock acquired by nodename 4703@um2
2019-08-02 08:41:09,314 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-02 08:41:09,326 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-02 08:41:09,380 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-02 08:41:09,380 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-02 08:41:09,382 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-02 08:41:09,383 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 02 08:41:09
2019-08-02 08:41:09,384 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-02 08:41:09,384 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-02 08:41:09,385 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2019-08-02 08:41:09,385 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-02 08:41:09,398 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-02 08:41:09,399 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-02 08:41:09,399 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-02 08:41:09,399 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-02 08:41:09,399 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-02 08:41:09,399 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-02 08:41:09,399 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-02 08:41:09,399 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-02 08:41:09,407 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-02 08:41:09,407 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-02 08:41:09,407 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-02 08:41:09,408 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-02 08:41:09,409 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-02 08:41:09,893 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-02 08:41:09,893 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-02 08:41:09,894 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2019-08-02 08:41:09,894 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-02 08:41:09,894 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-02 08:41:09,904 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-02 08:41:09,904 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-02 08:41:09,904 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2019-08-02 08:41:09,904 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-02 08:41:09,905 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-02 08:41:09,905 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-02 08:41:09,905 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-02 08:41:09,906 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-02 08:41:09,906 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-02 08:41:09,906 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-02 08:41:09,919 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-02 08:41:09,988 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-02 08:41:09,990 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-02 08:41:10,004 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-02 08:41:10,012 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-02 08:41:10,012 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-02 08:41:10,012 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-02 08:41:10,029 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-02 08:41:10,029 INFO org.mortbay.log: jetty-6.1.26
2019-08-02 08:41:10,290 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-02 08:41:10,290 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-02 08:41:10,290 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-08-02 08:41:10,291 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-02 08:42:10,488 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-08-02 08:42:10,687 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=584&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-02 08:42:10,738 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-08-02 08:42:10,905 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 500.00 KB/s
2019-08-02 08:42:10,905 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000584 size 6897 bytes.
2019-08-02 08:42:10,976 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=585&endTxId=639&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-02 08:42:11,013 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 33032.26 KB/s
2019-08-02 08:42:11,014 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000585-0000000000000000639_0000000000005787605 size 0 bytes.
2019-08-02 08:42:11,015 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=640&endTxId=662&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-02 08:42:11,028 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 200.00 KB/s
2019-08-02 08:42:11,028 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000640-0000000000000000662_0000000000005787644 size 0 bytes.
2019-08-02 08:42:11,076 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 84 INodes.
2019-08-02 08:42:11,116 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-08-02 08:42:11,118 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 584 from /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage_0000000000000000584
2019-08-02 08:42:11,118 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-08-02 08:42:11,121 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2019-08-02 08:42:11,125 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000585-0000000000000000639 expecting start txid #585
2019-08-02 08:42:11,125 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000585-0000000000000000639
2019-08-02 08:42:11,183 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000585-0000000000000000639 of size 1048576 edits # 55 loaded in 0 seconds
2019-08-02 08:42:11,183 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000640-0000000000000000662 expecting start txid #640
2019-08-02 08:42:11,183 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000640-0000000000000000662
2019-08-02 08:42:11,188 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000640-0000000000000000662 of size 2237 edits # 23 loaded in 0 seconds
2019-08-02 08:42:11,200 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000662 using no compression
2019-08-02 08:42:11,300 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000662 of size 7906 bytes saved in 0 seconds.
2019-08-02 08:42:11,327 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 584
2019-08-02 08:42:11,328 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-hdu/dfs/namesecondary/current/fsimage_0000000000000000580, cpktTxId=0000000000000000580)
2019-08-02 08:42:11,415 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 662 to namenode at http://um1:50070 in 0.07 seconds
2019-08-02 08:42:11,416 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 7906
2019-08-02 08:59:11,777 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-08-02 08:59:11,778 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.56.102
************************************************************/
2019-08-02 09:05:04,121 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.56.102
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-02 09:05:04,136 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-02 09:05:05,013 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-02 09:05:05,118 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-02 09:05:05,118 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-02 09:05:05,342 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-hdu/dfs/namesecondary/in_use.lock acquired by nodename 5824@um2
2019-08-02 09:05:05,445 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-02 09:05:05,457 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-02 09:05:05,519 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-02 09:05:05,519 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-02 09:05:05,521 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-02 09:05:05,522 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 02 09:05:05
2019-08-02 09:05:05,523 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-02 09:05:05,523 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-02 09:05:05,525 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2019-08-02 09:05:05,525 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-02 09:05:05,545 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-02 09:05:05,546 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-02 09:05:05,546 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-02 09:05:05,546 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-02 09:05:05,546 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-02 09:05:05,546 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-02 09:05:05,546 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-02 09:05:05,546 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-02 09:05:05,548 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-02 09:05:05,548 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-02 09:05:05,549 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-02 09:05:05,549 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-02 09:05:05,554 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-02 09:05:06,061 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-02 09:05:06,061 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-02 09:05:06,061 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2019-08-02 09:05:06,061 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-02 09:05:06,061 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-02 09:05:06,077 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-02 09:05:06,077 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-02 09:05:06,077 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2019-08-02 09:05:06,077 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-02 09:05:06,078 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-02 09:05:06,078 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-02 09:05:06,078 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-02 09:05:06,079 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-02 09:05:06,079 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-02 09:05:06,079 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-02 09:05:06,097 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-02 09:05:06,165 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-02 09:05:06,167 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-02 09:05:06,188 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-02 09:05:06,190 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-02 09:05:06,191 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-02 09:05:06,191 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-02 09:05:06,224 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-02 09:05:06,224 INFO org.mortbay.log: jetty-6.1.26
2019-08-02 09:05:06,601 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-02 09:05:06,602 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-02 09:05:06,602 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-08-02 09:05:06,602 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-02 09:06:06,836 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-08-02 09:06:07,049 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=662&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-02 09:06:07,128 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-08-02 09:06:07,310 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 777.78 KB/s
2019-08-02 09:06:07,310 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000662 size 7906 bytes.
2019-08-02 09:06:07,328 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=663&endTxId=697&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-02 09:06:07,359 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 36571.43 KB/s
2019-08-02 09:06:07,359 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000663-0000000000000000697_0000000000007223956 size 0 bytes.
2019-08-02 09:06:07,361 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=698&endTxId=699&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-02 09:06:07,365 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-02 09:06:07,365 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000698-0000000000000000699_0000000000007223990 size 0 bytes.
2019-08-02 09:06:07,438 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 96 INodes.
2019-08-02 09:06:07,477 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-08-02 09:06:07,479 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 662 from /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage_0000000000000000662
2019-08-02 09:06:07,479 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-08-02 09:06:07,489 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2019-08-02 09:06:07,495 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000663-0000000000000000697 expecting start txid #663
2019-08-02 09:06:07,495 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000663-0000000000000000697
2019-08-02 09:06:07,543 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000663-0000000000000000697 of size 1048576 edits # 35 loaded in 0 seconds
2019-08-02 09:06:07,543 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000698-0000000000000000699 expecting start txid #698
2019-08-02 09:06:07,543 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000698-0000000000000000699
2019-08-02 09:06:07,544 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000698-0000000000000000699 of size 42 edits # 2 loaded in 0 seconds
2019-08-02 09:06:07,547 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000699 using no compression
2019-08-02 09:06:07,595 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000699 of size 8162 bytes saved in 0 seconds.
2019-08-02 09:06:07,605 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 662
2019-08-02 09:06:07,605 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-hdu/dfs/namesecondary/current/fsimage_0000000000000000584, cpktTxId=0000000000000000584)
2019-08-02 09:06:07,639 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 699 to namenode at http://um1:50070 in 0.023 seconds
2019-08-02 09:06:07,639 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 8162
2019-08-02 09:09:27,916 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-08-02 09:09:27,917 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.56.102
************************************************************/
2019-08-02 09:10:06,835 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.56.102
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-02 09:10:06,856 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-02 09:10:07,634 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-02 09:10:07,726 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-02 09:10:07,726 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-02 09:10:07,915 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-hdu/dfs/namesecondary/in_use.lock acquired by nodename 6759@um2
2019-08-02 09:10:07,992 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-02 09:10:08,003 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-02 09:10:08,054 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-02 09:10:08,054 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-02 09:10:08,065 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-02 09:10:08,067 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 02 09:10:08
2019-08-02 09:10:08,068 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-02 09:10:08,068 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-02 09:10:08,076 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2019-08-02 09:10:08,076 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-02 09:10:08,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-02 09:10:08,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-02 09:10:08,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-02 09:10:08,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-02 09:10:08,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-02 09:10:08,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-02 09:10:08,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-02 09:10:08,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-02 09:10:08,092 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-02 09:10:08,092 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-02 09:10:08,092 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-02 09:10:08,093 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-02 09:10:08,100 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-02 09:10:08,531 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-02 09:10:08,531 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-02 09:10:08,535 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2019-08-02 09:10:08,535 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-02 09:10:08,535 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-02 09:10:08,544 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-02 09:10:08,544 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-02 09:10:08,544 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2019-08-02 09:10:08,544 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-02 09:10:08,545 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-02 09:10:08,545 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-02 09:10:08,545 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-02 09:10:08,546 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-02 09:10:08,546 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-02 09:10:08,546 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-02 09:10:08,575 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-02 09:10:08,672 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-02 09:10:08,675 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-02 09:10:08,687 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-02 09:10:08,691 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-02 09:10:08,691 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-02 09:10:08,691 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-02 09:10:08,715 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-02 09:10:08,715 INFO org.mortbay.log: jetty-6.1.26
2019-08-02 09:10:09,008 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-02 09:10:09,008 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-02 09:10:09,009 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-08-02 09:10:09,009 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-02 09:11:09,434 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-08-02 09:11:09,851 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=699&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-02 09:11:10,008 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-08-02 09:11:10,382 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 583.33 KB/s
2019-08-02 09:11:10,382 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000699 size 8162 bytes.
2019-08-02 09:11:10,411 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=700&endTxId=700&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-02 09:11:10,442 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 40960.00 KB/s
2019-08-02 09:11:10,443 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000700-0000000000000000700_0000000000007527039 size 0 bytes.
2019-08-02 09:11:10,444 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=701&endTxId=711&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-02 09:11:10,450 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-02 09:11:10,450 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000701-0000000000000000711_0000000000007527072 size 0 bytes.
2019-08-02 09:11:10,526 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 99 INodes.
2019-08-02 09:11:10,578 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-08-02 09:11:10,581 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 699 from /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage_0000000000000000699
2019-08-02 09:11:10,581 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-08-02 09:11:10,596 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2019-08-02 09:11:10,599 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000700-0000000000000000700 expecting start txid #700
2019-08-02 09:11:10,599 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000700-0000000000000000700
2019-08-02 09:11:10,621 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000700-0000000000000000700 of size 1048576 edits # 1 loaded in 0 seconds
2019-08-02 09:11:10,621 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000701-0000000000000000711 expecting start txid #701
2019-08-02 09:11:10,622 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000701-0000000000000000711
2019-08-02 09:11:10,636 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000701-0000000000000000711 of size 862 edits # 11 loaded in 0 seconds
2019-08-02 09:11:10,641 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000711 using no compression
2019-08-02 09:11:10,701 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000711 of size 8518 bytes saved in 0 seconds.
2019-08-02 09:11:10,709 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 699
2019-08-02 09:11:10,709 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-hdu/dfs/namesecondary/current/fsimage_0000000000000000662, cpktTxId=0000000000000000662)
2019-08-02 09:11:10,745 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 711 to namenode at http://um1:50070 in 0.027 seconds
2019-08-02 09:11:10,745 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 8518
2019-08-02 09:14:10,132 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-08-02 09:14:10,134 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.56.102
************************************************************/
2019-08-02 09:19:50,461 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.56.102
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-02 09:19:50,483 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-02 09:19:51,382 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-02 09:19:51,490 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-02 09:19:51,490 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-02 09:19:51,704 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-hdu/dfs/namesecondary/in_use.lock acquired by nodename 7457@um2
2019-08-02 09:19:51,813 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-02 09:19:51,823 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-02 09:19:51,864 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-02 09:19:51,864 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-02 09:19:51,866 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-02 09:19:51,868 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 02 09:19:51
2019-08-02 09:19:51,869 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-02 09:19:51,869 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-02 09:19:51,870 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2019-08-02 09:19:51,870 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-02 09:19:51,889 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-02 09:19:51,889 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-02 09:19:51,889 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-02 09:19:51,889 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-02 09:19:51,889 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-02 09:19:51,889 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-02 09:19:51,889 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-02 09:19:51,889 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-02 09:19:51,890 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-02 09:19:51,890 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-02 09:19:51,890 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-02 09:19:51,890 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-02 09:19:51,904 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-02 09:19:52,442 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-02 09:19:52,442 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-02 09:19:52,442 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2019-08-02 09:19:52,442 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-02 09:19:52,443 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-02 09:19:52,449 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-02 09:19:52,449 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-02 09:19:52,449 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2019-08-02 09:19:52,449 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-02 09:19:52,450 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-02 09:19:52,450 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-02 09:19:52,450 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-02 09:19:52,459 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-02 09:19:52,459 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-02 09:19:52,460 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-02 09:19:52,476 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-02 09:19:52,545 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-02 09:19:52,547 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-02 09:19:52,564 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-02 09:19:52,572 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-02 09:19:52,573 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-02 09:19:52,573 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-02 09:19:52,590 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-02 09:19:52,590 INFO org.mortbay.log: jetty-6.1.26
2019-08-02 09:19:52,933 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-02 09:19:52,933 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-02 09:19:52,934 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-08-02 09:19:52,934 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-02 09:20:53,148 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-08-02 09:20:53,327 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=711&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-02 09:20:53,383 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-08-02 09:20:53,549 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 888.89 KB/s
2019-08-02 09:20:53,549 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000711 size 8518 bytes.
2019-08-02 09:20:53,563 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=712&endTxId=746&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-02 09:20:53,586 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 60235.29 KB/s
2019-08-02 09:20:53,586 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000712-0000000000000000746_0000000000008110192 size 0 bytes.
2019-08-02 09:20:53,586 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=747&endTxId=791&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-02 09:20:53,592 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 2000.00 KB/s
2019-08-02 09:20:53,592 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000747-0000000000000000791_0000000000008110215 size 0 bytes.
2019-08-02 09:20:53,664 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 101 INodes.
2019-08-02 09:20:53,725 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-08-02 09:20:53,726 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 711 from /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage_0000000000000000711
2019-08-02 09:20:53,726 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-08-02 09:20:53,752 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2019-08-02 09:20:53,759 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000712-0000000000000000746 expecting start txid #712
2019-08-02 09:20:53,760 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000712-0000000000000000746
2019-08-02 09:20:53,810 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000712-0000000000000000746 of size 1048576 edits # 35 loaded in 0 seconds
2019-08-02 09:20:53,810 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000747-0000000000000000791 expecting start txid #747
2019-08-02 09:20:53,810 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000747-0000000000000000791
2019-08-02 09:20:53,819 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000747-0000000000000000791 of size 4827 edits # 45 loaded in 0 seconds
2019-08-02 09:20:53,823 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000791 using no compression
2019-08-02 09:20:53,871 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000791 of size 8854 bytes saved in 0 seconds.
2019-08-02 09:20:53,881 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 711
2019-08-02 09:20:53,882 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-hdu/dfs/namesecondary/current/fsimage_0000000000000000699, cpktTxId=0000000000000000699)
2019-08-02 09:20:53,919 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 791 to namenode at http://um1:50070 in 0.024 seconds
2019-08-02 09:20:53,919 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 8854
2019-08-02 09:26:42,565 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.56.102
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-02 09:26:42,575 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-02 09:26:43,012 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-02 09:26:43,086 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-02 09:26:43,086 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-02 09:26:43,265 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-hdu/dfs/namesecondary/in_use.lock acquired by nodename 2511@um2
2019-08-02 09:26:43,270 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-02 09:26:43,277 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-02 09:26:43,314 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-02 09:26:43,314 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-02 09:26:43,315 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-02 09:26:43,317 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 02 09:26:43
2019-08-02 09:26:43,318 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-02 09:26:43,318 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-02 09:26:43,319 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-08-02 09:26:43,319 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-02 09:26:43,336 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-02 09:26:43,336 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-02 09:26:43,336 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-02 09:26:43,336 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-02 09:26:43,336 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-02 09:26:43,336 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-02 09:26:43,336 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-02 09:26:43,336 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-02 09:26:43,337 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-02 09:26:43,337 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-02 09:26:43,337 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-02 09:26:43,337 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-02 09:26:43,338 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-02 09:26:43,602 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-02 09:26:43,602 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-02 09:26:43,602 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-08-02 09:26:43,602 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-02 09:26:43,638 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-02 09:26:43,644 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-02 09:26:43,644 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-02 09:26:43,645 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-08-02 09:26:43,645 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-02 09:26:43,646 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-02 09:26:43,646 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-02 09:26:43,646 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-02 09:26:43,647 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-02 09:26:43,647 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-02 09:26:43,647 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-02 09:26:43,655 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-02 09:26:43,688 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-02 09:26:43,690 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-02 09:26:43,697 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-02 09:26:43,698 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-02 09:26:43,699 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-02 09:26:43,699 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-02 09:26:43,712 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-02 09:26:43,712 INFO org.mortbay.log: jetty-6.1.26
2019-08-02 09:26:43,857 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-02 09:26:43,857 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-02 09:26:43,857 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-08-02 09:26:43,857 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-15 11:31:20,702 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.56.102
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-15 11:31:20,714 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-15 11:31:21,206 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-15 11:31:21,269 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-15 11:31:21,269 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-15 11:31:21,468 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-hdu/dfs/namesecondary/in_use.lock acquired by nodename 17103@um2
2019-08-15 11:31:21,473 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-15 11:31:21,480 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-15 11:31:21,528 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-15 11:31:21,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-15 11:31:21,530 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-15 11:31:21,531 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 15 11:31:21
2019-08-15 11:31:21,532 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-15 11:31:21,533 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-15 11:31:21,534 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-08-15 11:31:21,534 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-15 11:31:21,543 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-15 11:31:21,543 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-15 11:31:21,543 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-15 11:31:21,544 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-15 11:31:21,544 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-15 11:31:21,544 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-15 11:31:21,544 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-15 11:31:21,544 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-15 11:31:21,545 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-15 11:31:21,545 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-15 11:31:21,545 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-15 11:31:21,545 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-15 11:31:21,547 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-15 11:31:21,845 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-15 11:31:21,845 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-15 11:31:21,845 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-08-15 11:31:21,845 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-15 11:31:21,848 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-15 11:31:21,858 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-15 11:31:21,858 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-15 11:31:21,858 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-08-15 11:31:21,858 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-15 11:31:21,861 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-15 11:31:21,861 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-15 11:31:21,861 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-15 11:31:21,863 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-15 11:31:21,863 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-15 11:31:21,863 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-15 11:31:21,872 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-15 11:31:21,926 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-15 11:31:21,929 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-15 11:31:21,936 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-15 11:31:21,940 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-15 11:31:21,941 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-15 11:31:21,941 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-15 11:31:21,953 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-15 11:31:21,953 INFO org.mortbay.log: jetty-6.1.26
2019-08-15 11:31:22,167 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-15 11:31:22,168 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-15 11:31:22,168 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-08-15 11:31:22,168 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-15 11:32:22,371 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-08-15 11:32:22,493 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=922&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-15 11:32:22,542 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-08-15 11:32:22,771 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 209.30 KB/s
2019-08-15 11:32:22,771 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000922 size 9892 bytes.
2019-08-15 11:32:22,778 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=923&endTxId=924&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-15 11:32:22,783 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-15 11:32:22,783 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000923-0000000000000000924_0000000000006367112 size 0 bytes.
2019-08-15 11:32:22,826 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 119 INodes.
2019-08-15 11:32:22,865 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-08-15 11:32:22,865 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 922 from /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage_0000000000000000922
2019-08-15 11:32:22,866 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-08-15 11:32:22,872 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-08-15 11:32:22,876 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000923-0000000000000000924 expecting start txid #923
2019-08-15 11:32:22,877 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000923-0000000000000000924
2019-08-15 11:32:22,896 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000923-0000000000000000924 of size 42 edits # 2 loaded in 0 seconds
2019-08-15 11:32:22,903 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000924 using no compression
2019-08-15 11:32:22,970 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000924 of size 9892 bytes saved in 0 seconds.
2019-08-15 11:32:22,987 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-hdu/dfs/namesecondary
2019-08-15 11:32:23,013 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 924 to namenode at http://um1:50070 in 0.02 seconds
2019-08-15 11:32:23,013 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 9892
2019-08-15 12:32:23,725 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-08-15 12:32:23,725 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=925&endTxId=944&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-15 12:32:23,730 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 500.00 KB/s
2019-08-15 12:32:23,730 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000925-0000000000000000944_0000000000009968060 size 0 bytes.
2019-08-15 12:32:23,730 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-08-15 12:32:23,730 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000925-0000000000000000944 expecting start txid #925
2019-08-15 12:32:23,731 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000925-0000000000000000944
2019-08-15 12:32:23,751 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000925-0000000000000000944 of size 1622 edits # 20 loaded in 0 seconds
2019-08-15 12:32:23,752 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000944 using no compression
2019-08-15 12:32:23,769 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000944 of size 10104 bytes saved in 0 seconds.
2019-08-15 12:32:23,783 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 924
2019-08-15 12:32:23,783 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-hdu/dfs/namesecondary/current/fsimage_0000000000000000922, cpktTxId=0000000000000000922)
2019-08-15 12:32:23,797 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 944 to namenode at http://um1:50070 in 0.012 seconds
2019-08-15 12:32:23,798 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 10104
2019-08-15 13:32:24,548 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-08-15 13:32:24,548 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=945&endTxId=946&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-15 13:32:24,553 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-15 13:32:24,553 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000945-0000000000000000946_0000000000013568884 size 0 bytes.
2019-08-15 13:32:24,554 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-08-15 13:32:24,554 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000945-0000000000000000946 expecting start txid #945
2019-08-15 13:32:24,554 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000945-0000000000000000946
2019-08-15 13:32:24,554 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000945-0000000000000000946 of size 42 edits # 2 loaded in 0 seconds
2019-08-15 13:32:24,556 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000946 using no compression
2019-08-15 13:32:24,566 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000946 of size 10104 bytes saved in 0 seconds.
2019-08-15 13:32:24,569 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 944
2019-08-15 13:32:24,569 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-hdu/dfs/namesecondary/current/fsimage_0000000000000000924, cpktTxId=0000000000000000924)
2019-08-15 13:32:24,580 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 946 to namenode at http://um1:50070 in 0.011 seconds
2019-08-15 13:32:24,581 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 10104
2019-08-15 14:32:25,164 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-08-15 14:32:25,165 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=947&endTxId=971&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-15 14:32:25,169 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1000.00 KB/s
2019-08-15 14:32:25,169 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000947-0000000000000000971_0000000000017169500 size 0 bytes.
2019-08-15 14:32:25,169 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-08-15 14:32:25,169 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000947-0000000000000000971 expecting start txid #947
2019-08-15 14:32:25,169 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000947-0000000000000000971
2019-08-15 14:32:25,176 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000947-0000000000000000971 of size 3021 edits # 25 loaded in 0 seconds
2019-08-15 14:32:25,177 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000971 using no compression
2019-08-15 14:32:25,183 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000971 of size 10365 bytes saved in 0 seconds.
2019-08-15 14:32:25,186 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 946
2019-08-15 14:32:25,186 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-hdu/dfs/namesecondary/current/fsimage_0000000000000000944, cpktTxId=0000000000000000944)
2019-08-15 14:32:25,197 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 971 to namenode at http://um1:50070 in 0.009 seconds
2019-08-15 14:32:25,197 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 10365
2019-08-15 15:32:25,701 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-08-15 15:32:25,701 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=972&endTxId=973&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-15 15:32:25,707 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-15 15:32:25,707 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000972-0000000000000000973_0000000000020770036 size 0 bytes.
2019-08-15 15:32:25,707 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-08-15 15:32:25,707 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000972-0000000000000000973 expecting start txid #972
2019-08-15 15:32:25,708 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000972-0000000000000000973
2019-08-15 15:32:25,708 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000972-0000000000000000973 of size 42 edits # 2 loaded in 0 seconds
2019-08-15 15:32:25,709 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000973 using no compression
2019-08-15 15:32:25,720 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000973 of size 10365 bytes saved in 0 seconds.
2019-08-15 15:32:25,723 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 971
2019-08-15 15:32:25,723 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-hdu/dfs/namesecondary/current/fsimage_0000000000000000946, cpktTxId=0000000000000000946)
2019-08-15 15:32:25,734 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 973 to namenode at http://um1:50070 in 0.009 seconds
2019-08-15 15:32:25,734 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 10365
2019-08-15 16:32:26,348 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-08-15 16:32:26,348 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=974&endTxId=998&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-15 16:32:26,356 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 666.67 KB/s
2019-08-15 16:32:26,356 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000974-0000000000000000998_0000000000024370683 size 0 bytes.
2019-08-15 16:32:26,356 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-08-15 16:32:26,356 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000974-0000000000000000998 expecting start txid #974
2019-08-15 16:32:26,356 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000974-0000000000000000998
2019-08-15 16:32:26,365 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000000974-0000000000000000998 of size 3048 edits # 25 loaded in 0 seconds
2019-08-15 16:32:26,366 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000998 using no compression
2019-08-15 16:32:26,374 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000000998 of size 10630 bytes saved in 0 seconds.
2019-08-15 16:32:26,377 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 973
2019-08-15 16:32:26,378 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-hdu/dfs/namesecondary/current/fsimage_0000000000000000971, cpktTxId=0000000000000000971)
2019-08-15 16:32:26,398 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 998 to namenode at http://um1:50070 in 0.017 seconds
2019-08-15 16:32:26,398 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 10630
2019-08-16 15:09:28,415 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.56.102
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-16 15:09:28,425 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-16 15:09:28,996 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-16 15:09:29,077 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-16 15:09:29,077 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-16 15:09:29,377 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-hdu/dfs/namesecondary/in_use.lock acquired by nodename 2875@um2
2019-08-16 15:09:29,386 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-16 15:09:29,394 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-16 15:09:29,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-16 15:09:29,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-16 15:09:29,475 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-16 15:09:29,477 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 16 15:09:29
2019-08-16 15:09:29,479 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-16 15:09:29,479 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-16 15:09:29,481 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-08-16 15:09:29,482 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-16 15:09:29,501 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-16 15:09:29,501 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-16 15:09:29,501 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-16 15:09:29,501 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-16 15:09:29,501 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-16 15:09:29,501 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-16 15:09:29,501 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-16 15:09:29,501 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-16 15:09:29,502 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-16 15:09:29,502 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-16 15:09:29,502 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-16 15:09:29,502 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-16 15:09:29,504 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-16 15:09:29,888 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-16 15:09:29,888 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-16 15:09:29,888 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-08-16 15:09:29,888 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-16 15:09:29,888 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-16 15:09:29,895 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-16 15:09:29,895 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-16 15:09:29,895 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-08-16 15:09:29,895 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-16 15:09:29,896 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-16 15:09:29,896 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-16 15:09:29,896 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-16 15:09:29,898 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-16 15:09:29,898 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-16 15:09:29,898 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-16 15:09:29,910 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-16 15:09:29,996 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-16 15:09:30,001 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-16 15:09:30,012 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-16 15:09:30,014 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-16 15:09:30,015 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-16 15:09:30,015 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-16 15:09:30,031 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-16 15:09:30,032 INFO org.mortbay.log: jetty-6.1.26
2019-08-16 15:09:30,389 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-16 15:09:30,389 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-16 15:09:30,389 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-08-16 15:09:30,389 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-16 15:57:31,128 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-08-16 15:57:31,243 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=999&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-16 15:57:31,287 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-08-16 15:57:31,504 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 250.00 KB/s
2019-08-16 15:57:31,504 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000999 size 10630 bytes.
2019-08-16 15:57:31,511 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1000&endTxId=1032&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-16 15:57:31,515 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 4000.00 KB/s
2019-08-16 15:57:31,516 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001000-0000000000000001032_0000000000003629215 size 0 bytes.
2019-08-16 15:57:31,554 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 130 INodes.
2019-08-16 15:57:31,592 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-08-16 15:57:31,592 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 999 from /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage_0000000000000000999
2019-08-16 15:57:31,592 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-08-16 15:57:31,598 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-08-16 15:57:31,602 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000001000-0000000000000001032 expecting start txid #1000
2019-08-16 15:57:31,602 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000001000-0000000000000001032
2019-08-16 15:57:31,647 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000001000-0000000000000001032 of size 4955 edits # 33 loaded in 0 seconds
2019-08-16 15:57:31,651 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000001032 using no compression
2019-08-16 15:57:31,701 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000001032 of size 11088 bytes saved in 0 seconds.
2019-08-16 15:57:31,713 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-hdu/dfs/namesecondary
2019-08-16 15:57:31,744 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1032 to namenode at http://um1:50070 in 0.025 seconds
2019-08-16 15:57:31,744 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 11088
2019-08-17 19:46:30,246 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.56.102
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-17 19:46:30,258 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-17 19:46:30,797 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-17 19:46:30,865 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-17 19:46:30,865 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-17 19:46:31,069 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-hdu/dfs/namesecondary/in_use.lock acquired by nodename 3352@um2
2019-08-17 19:46:31,077 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-17 19:46:31,086 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-17 19:46:31,140 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-17 19:46:31,140 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-17 19:46:31,141 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-17 19:46:31,142 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 17 19:46:31
2019-08-17 19:46:31,144 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-17 19:46:31,144 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 19:46:31,145 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-08-17 19:46:31,145 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-17 19:46:31,156 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-17 19:46:31,156 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-17 19:46:31,156 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-17 19:46:31,156 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-17 19:46:31,156 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-17 19:46:31,156 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-17 19:46:31,157 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-17 19:46:31,157 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-17 19:46:31,157 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-17 19:46:31,157 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-17 19:46:31,157 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-17 19:46:31,157 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-17 19:46:31,159 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-17 19:46:31,450 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-17 19:46:31,450 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 19:46:31,451 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-08-17 19:46:31,451 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-17 19:46:31,451 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-17 19:46:31,460 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-17 19:46:31,460 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 19:46:31,461 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-08-17 19:46:31,461 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-17 19:46:31,462 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-17 19:46:31,462 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-17 19:46:31,462 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-17 19:46:31,463 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-17 19:46:31,463 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-17 19:46:31,463 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-17 19:46:31,474 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-17 19:46:31,512 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-17 19:46:31,515 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-17 19:46:31,527 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-17 19:46:31,528 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-17 19:46:31,528 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-17 19:46:31,529 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-17 19:46:31,542 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-17 19:46:31,542 INFO org.mortbay.log: jetty-6.1.26
2019-08-17 19:46:31,784 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-17 19:46:31,784 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-17 19:46:31,784 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-08-17 19:46:31,785 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-17 19:47:56,883 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-08-17 19:47:56,884 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.56.102
************************************************************/
2019-08-17 19:49:47,122 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.56.102
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-17 19:49:47,132 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-17 19:49:47,650 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-17 19:49:47,739 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-17 19:49:47,739 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-17 19:49:47,891 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-hdu/dfs/namesecondary/in_use.lock acquired by nodename 4099@um2
2019-08-17 19:49:47,895 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-17 19:49:47,899 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-17 19:49:47,938 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-17 19:49:47,938 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-17 19:49:47,939 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-17 19:49:47,940 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 17 19:49:47
2019-08-17 19:49:47,942 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-17 19:49:47,942 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 19:49:47,943 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-08-17 19:49:47,943 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-17 19:49:47,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-17 19:49:47,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-17 19:49:47,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-17 19:49:47,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-17 19:49:47,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-17 19:49:47,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-17 19:49:47,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-17 19:49:47,953 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-17 19:49:47,953 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-17 19:49:47,953 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-17 19:49:47,953 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-17 19:49:47,953 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-17 19:49:47,955 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-17 19:49:48,251 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-17 19:49:48,251 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 19:49:48,251 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-08-17 19:49:48,251 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-17 19:49:48,253 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-17 19:49:48,259 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-17 19:49:48,259 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 19:49:48,259 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-08-17 19:49:48,259 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-17 19:49:48,261 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-17 19:49:48,261 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-17 19:49:48,261 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-17 19:49:48,262 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-17 19:49:48,262 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-17 19:49:48,262 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-17 19:49:48,269 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-17 19:49:48,314 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-17 19:49:48,317 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-17 19:49:48,324 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-17 19:49:48,327 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-17 19:49:48,328 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-17 19:49:48,328 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-17 19:49:48,341 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-17 19:49:48,341 INFO org.mortbay.log: jetty-6.1.26
2019-08-17 19:49:48,529 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-17 19:49:48,529 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-17 19:49:48,529 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-08-17 19:49:48,529 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-17 19:50:49,574 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.56.101:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-08-17 19:50:50,579 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.56.101:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-08-17 19:50:51,580 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.56.101:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-08-17 19:50:52,610 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.56.101:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-08-17 19:50:53,814 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.56.101:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-08-17 19:50:54,823 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.56.101:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-08-17 19:50:55,824 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.56.101:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-08-17 19:50:56,831 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.56.101:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-08-17 19:50:57,848 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.56.101:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-08-17 19:50:58,854 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.56.101:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-08-17 19:50:58,874 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From um2/192.168.56.102 to um1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 18 more
2019-08-17 20:14:22,733 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.56.102
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-17 20:14:22,750 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-17 20:14:23,451 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-17 20:14:23,558 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-17 20:14:23,558 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-17 20:14:23,825 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-hdu/dfs/namesecondary/in_use.lock acquired by nodename 2595@um2
2019-08-17 20:14:23,831 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-17 20:14:23,840 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-17 20:14:23,926 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-17 20:14:23,927 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-17 20:14:23,928 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-17 20:14:23,930 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 17 20:14:23
2019-08-17 20:14:23,932 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-17 20:14:23,932 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 20:14:23,933 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-08-17 20:14:23,933 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-17 20:14:23,943 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-17 20:14:23,943 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-17 20:14:23,943 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-17 20:14:23,943 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-17 20:14:23,943 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-17 20:14:23,943 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-17 20:14:23,943 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-17 20:14:23,944 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-17 20:14:23,944 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-17 20:14:23,944 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-17 20:14:23,944 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-17 20:14:23,944 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-17 20:14:23,946 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-17 20:14:24,331 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-17 20:14:24,331 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 20:14:24,332 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-08-17 20:14:24,332 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-17 20:14:24,332 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-17 20:14:24,344 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-17 20:14:24,344 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 20:14:24,345 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-08-17 20:14:24,345 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-17 20:14:24,347 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-17 20:14:24,347 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-17 20:14:24,347 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-17 20:14:24,350 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-17 20:14:24,350 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-17 20:14:24,350 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-17 20:14:24,363 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-17 20:14:24,434 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-17 20:14:24,438 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-17 20:14:24,447 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-17 20:14:24,449 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-17 20:14:24,450 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-17 20:14:24,450 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-17 20:14:24,476 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-17 20:14:24,476 INFO org.mortbay.log: jetty-6.1.26
2019-08-17 20:14:24,756 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-17 20:14:24,756 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-17 20:14:24,756 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-08-17 20:14:24,756 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
                                                                                                                                                                                                                                                                                                                                                                                                                          2019-08-17 20:56:34,470 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.56.102
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-17 20:56:34,486 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-17 20:56:35,169 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-17 20:56:35,245 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-17 20:56:35,245 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-17 20:56:35,476 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-hdu/dfs/namesecondary/in_use.lock acquired by nodename 2676@um2
2019-08-17 20:56:35,480 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-17 20:56:35,491 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-17 20:56:35,552 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-17 20:56:35,552 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-17 20:56:35,553 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-17 20:56:35,556 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 17 20:56:35
2019-08-17 20:56:35,557 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-17 20:56:35,557 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 20:56:35,558 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-08-17 20:56:35,559 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-17 20:56:35,595 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-17 20:56:35,595 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-17 20:56:35,595 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-17 20:56:35,595 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-17 20:56:35,595 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-17 20:56:35,595 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-17 20:56:35,595 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-17 20:56:35,595 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-17 20:56:35,596 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-17 20:56:35,596 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-17 20:56:35,596 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-17 20:56:35,596 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-17 20:56:35,598 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-17 20:56:36,023 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-17 20:56:36,024 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 20:56:36,024 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-08-17 20:56:36,024 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-17 20:56:36,024 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-17 20:56:36,031 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-17 20:56:36,031 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 20:56:36,031 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-08-17 20:56:36,031 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-17 20:56:36,033 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-17 20:56:36,034 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-17 20:56:36,034 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-17 20:56:36,035 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-17 20:56:36,035 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-17 20:56:36,035 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-17 20:56:36,044 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-17 20:56:36,095 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-17 20:56:36,099 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-17 20:56:36,108 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-17 20:56:36,112 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-17 20:56:36,114 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-17 20:56:36,114 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-17 20:56:36,131 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-17 20:56:36,131 INFO org.mortbay.log: jetty-6.1.26
2019-08-17 20:56:36,340 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-17 20:56:36,340 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-17 20:56:36,341 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-08-17 20:56:36,341 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-17 21:16:11,057 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-08-17 21:16:11,059 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.56.102
************************************************************/
2019-08-17 21:19:32,467 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.56.102
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-17 21:19:32,476 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-17 21:19:32,998 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-17 21:19:33,047 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-17 21:19:33,047 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-17 21:19:33,167 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-hdu/dfs/namesecondary/in_use.lock acquired by nodename 3556@um2
2019-08-17 21:19:33,170 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-17 21:19:33,175 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-17 21:19:33,207 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-17 21:19:33,207 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-17 21:19:33,208 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-17 21:19:33,209 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 17 21:19:33
2019-08-17 21:19:33,210 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-17 21:19:33,210 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 21:19:33,211 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-08-17 21:19:33,211 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-17 21:19:33,221 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-17 21:19:33,221 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-17 21:19:33,221 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-17 21:19:33,221 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-17 21:19:33,221 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-17 21:19:33,221 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-17 21:19:33,221 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-17 21:19:33,221 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-17 21:19:33,222 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-17 21:19:33,222 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-17 21:19:33,222 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-17 21:19:33,222 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-17 21:19:33,223 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-17 21:19:33,481 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-17 21:19:33,481 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 21:19:33,481 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-08-17 21:19:33,481 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-17 21:19:33,482 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-17 21:19:33,486 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-17 21:19:33,486 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 21:19:33,487 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-08-17 21:19:33,487 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-17 21:19:33,487 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-17 21:19:33,487 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-17 21:19:33,488 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-17 21:19:33,488 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-17 21:19:33,489 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-17 21:19:33,489 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-17 21:19:33,495 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-17 21:19:33,546 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-17 21:19:33,548 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-17 21:19:33,555 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-17 21:19:33,557 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-17 21:19:33,557 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-17 21:19:33,557 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-17 21:19:33,569 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-17 21:19:33,569 INFO org.mortbay.log: jetty-6.1.26
2019-08-17 21:19:33,740 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-17 21:19:33,740 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-17 21:19:33,740 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-08-17 21:19:33,740 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-17 21:42:11,688 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-08-17 21:42:11,691 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.56.102
************************************************************/
2019-08-17 21:42:51,017 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.56.102
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-17 21:42:51,027 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-17 21:42:51,494 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-17 21:42:51,545 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-17 21:42:51,545 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-17 21:42:51,676 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-hdu/dfs/namesecondary/in_use.lock acquired by nodename 4601@um2
2019-08-17 21:42:51,679 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-17 21:42:51,684 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-17 21:42:51,720 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-17 21:42:51,720 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-17 21:42:51,721 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-17 21:42:51,722 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 17 21:42:51
2019-08-17 21:42:51,724 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-17 21:42:51,724 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 21:42:51,725 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-08-17 21:42:51,725 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-17 21:42:51,735 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-17 21:42:51,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-17 21:42:51,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-17 21:42:51,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-17 21:42:51,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-17 21:42:51,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-17 21:42:51,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-17 21:42:51,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-17 21:42:51,737 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-17 21:42:51,737 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-17 21:42:51,737 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-17 21:42:51,737 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-17 21:42:51,739 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-17 21:42:52,031 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-17 21:42:52,031 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 21:42:52,031 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-08-17 21:42:52,031 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-17 21:42:52,031 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-17 21:42:52,037 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-17 21:42:52,037 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 21:42:52,037 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-08-17 21:42:52,037 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-17 21:42:52,038 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-17 21:42:52,038 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-17 21:42:52,038 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-17 21:42:52,039 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-17 21:42:52,039 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-17 21:42:52,039 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-17 21:42:52,046 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-17 21:42:52,083 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-17 21:42:52,086 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-17 21:42:52,093 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-17 21:42:52,095 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-17 21:42:52,095 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-17 21:42:52,095 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-17 21:42:52,107 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-17 21:42:52,107 INFO org.mortbay.log: jetty-6.1.26
2019-08-17 21:42:52,289 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-17 21:42:52,289 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-17 21:42:52,289 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-08-17 21:42:52,289 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-17 21:48:52,563 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-08-17 21:48:52,667 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=2545&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-17 21:48:52,717 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-08-17 21:48:52,930 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 387.10 KB/s
2019-08-17 21:48:52,930 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000002545 size 12989 bytes.
2019-08-17 21:48:52,937 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2546&endTxId=2648&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-17 21:48:52,950 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 113777.78 KB/s
2019-08-17 21:48:52,951 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002546-0000000000000002648_0000000000003601528 size 0 bytes.
2019-08-17 21:48:52,952 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2649&endTxId=2831&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-17 21:48:52,964 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 113777.78 KB/s
2019-08-17 21:48:52,964 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002649-0000000000000002831_0000000000003601543 size 0 bytes.
2019-08-17 21:48:52,965 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2832&endTxId=2882&storageInfo=-60:558994093:0:CID-ff859e50-9fdb-4cef-ad76-3ccb2ce2e9ee
2019-08-17 21:48:52,971 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 2500.00 KB/s
2019-08-17 21:48:52,971 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002832-0000000000000002882_0000000000003601556 size 0 bytes.
2019-08-17 21:48:53,003 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 159 INodes.
2019-08-17 21:48:53,041 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-08-17 21:48:53,041 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 2545 from /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage_0000000000000002545
2019-08-17 21:48:53,041 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-08-17 21:48:53,046 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 3 stream(s).
2019-08-17 21:48:53,049 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000002546-0000000000000002648 expecting start txid #2546
2019-08-17 21:48:53,049 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000002546-0000000000000002648
2019-08-17 21:48:53,123 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000002546-0000000000000002648 of size 1048576 edits # 103 loaded in 0 seconds
2019-08-17 21:48:53,123 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000002649-0000000000000002831 expecting start txid #2649
2019-08-17 21:48:53,123 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000002649-0000000000000002831
2019-08-17 21:48:53,140 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000002649-0000000000000002831 of size 1048576 edits # 183 loaded in 0 seconds
2019-08-17 21:48:53,141 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000002832-0000000000000002882 expecting start txid #2832
2019-08-17 21:48:53,141 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000002832-0000000000000002882
2019-08-17 21:48:53,145 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-hdu/dfs/namesecondary/current/edits_0000000000000002832-0000000000000002882 of size 5448 edits # 51 loaded in 0 seconds
2019-08-17 21:48:53,149 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000002882 using no compression
2019-08-17 21:48:53,196 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-hdu/dfs/namesecondary/current/fsimage.ckpt_0000000000000002882 of size 16552 bytes saved in 0 seconds.
2019-08-17 21:48:53,198 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-hdu/dfs/namesecondary
2019-08-17 21:48:53,238 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2882 to namenode at http://um1:50070 in 0.033 seconds
2019-08-17 21:48:53,238 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 16552
2019-08-17 21:52:08,737 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-08-17 21:52:08,739 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.56.102
************************************************************/
2019-08-17 22:05:52,386 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.56.102
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-17 22:05:52,396 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-17 22:05:52,875 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-17 22:05:52,946 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-17 22:05:52,946 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-17 22:05:53,118 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-hdu/dfs/namesecondary/in_use.lock acquired by nodename 2669@um2
2019-08-17 22:05:53,122 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-17 22:05:53,128 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-17 22:05:53,166 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-17 22:05:53,166 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-17 22:05:53,167 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-17 22:05:53,169 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 17 22:05:53
2019-08-17 22:05:53,170 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-17 22:05:53,170 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 22:05:53,171 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-08-17 22:05:53,171 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-17 22:05:53,188 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-17 22:05:53,188 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-17 22:05:53,188 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-17 22:05:53,188 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-17 22:05:53,188 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-17 22:05:53,188 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-17 22:05:53,188 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-17 22:05:53,188 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-17 22:05:53,189 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-17 22:05:53,189 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-17 22:05:53,189 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-17 22:05:53,189 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-17 22:05:53,194 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-17 22:05:53,477 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-17 22:05:53,477 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 22:05:53,477 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-08-17 22:05:53,477 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-17 22:05:53,512 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-17 22:05:53,519 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-17 22:05:53,519 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 22:05:53,519 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-08-17 22:05:53,520 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-17 22:05:53,521 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-17 22:05:53,521 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-17 22:05:53,521 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-17 22:05:53,522 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-17 22:05:53,522 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-17 22:05:53,522 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-17 22:05:53,530 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-17 22:05:53,578 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-17 22:05:53,580 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-17 22:05:53,587 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-17 22:05:53,589 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-17 22:05:53,590 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-17 22:05:53,591 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-17 22:05:53,604 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-17 22:05:53,604 INFO org.mortbay.log: jetty-6.1.26
2019-08-17 22:05:53,744 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-17 22:05:53,744 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-17 22:05:53,744 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-08-17 22:05:53,744 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-17 22:20:53,770 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-08-17 22:20:53,772 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.56.102
************************************************************/
2019-08-17 22:21:30,676 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.56.102
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-17 22:21:30,686 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-17 22:21:31,180 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-17 22:21:31,236 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-17 22:21:31,236 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-17 22:21:31,360 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-hdu/dfs/namesecondary/in_use.lock acquired by nodename 3457@um2
2019-08-17 22:21:31,363 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-17 22:21:31,366 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-17 22:21:31,399 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-17 22:21:31,399 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-17 22:21:31,400 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-17 22:21:31,401 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 17 22:21:31
2019-08-17 22:21:31,403 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-17 22:21:31,403 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 22:21:31,404 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-08-17 22:21:31,404 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-17 22:21:31,411 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-17 22:21:31,411 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-17 22:21:31,411 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-17 22:21:31,411 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-17 22:21:31,411 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-17 22:21:31,411 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-17 22:21:31,411 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-17 22:21:31,411 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-17 22:21:31,412 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-17 22:21:31,412 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-17 22:21:31,412 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-17 22:21:31,412 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-17 22:21:31,413 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-17 22:21:31,682 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-17 22:21:31,682 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 22:21:31,682 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-08-17 22:21:31,682 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-17 22:21:31,695 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-17 22:21:31,700 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-17 22:21:31,700 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 22:21:31,700 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-08-17 22:21:31,701 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-17 22:21:31,701 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-17 22:21:31,702 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-17 22:21:31,702 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-17 22:21:31,703 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-17 22:21:31,703 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-17 22:21:31,703 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-17 22:21:31,709 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-17 22:21:31,745 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-17 22:21:31,748 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-17 22:21:31,754 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-17 22:21:31,756 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-17 22:21:31,757 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-17 22:21:31,757 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-17 22:21:31,769 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-17 22:21:31,769 INFO org.mortbay.log: jetty-6.1.26
2019-08-17 22:21:31,932 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-17 22:21:31,933 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-17 22:21:31,933 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-08-17 22:21:31,933 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-17 22:25:45,421 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-08-17 22:25:45,424 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.56.102
************************************************************/
2019-08-17 22:27:48,371 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.56.102
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-17 22:27:48,384 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-17 22:27:49,043 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-17 22:27:49,131 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-17 22:27:49,131 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-17 22:27:49,318 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-hdu/dfs/namesecondary/in_use.lock acquired by nodename 4111@um2
2019-08-17 22:27:49,321 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-17 22:27:49,327 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-17 22:27:49,374 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-17 22:27:49,374 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-17 22:27:49,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-17 22:27:49,377 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 17 22:27:49
2019-08-17 22:27:49,379 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-17 22:27:49,379 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 22:27:49,380 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-08-17 22:27:49,380 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-17 22:27:49,395 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-17 22:27:49,395 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-17 22:27:49,395 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-17 22:27:49,395 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-17 22:27:49,395 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-17 22:27:49,396 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-17 22:27:49,396 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-17 22:27:49,396 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-17 22:27:49,397 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-17 22:27:49,397 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-17 22:27:49,397 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-17 22:27:49,398 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-17 22:27:49,401 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-17 22:27:49,733 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-17 22:27:49,734 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 22:27:49,734 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-08-17 22:27:49,734 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-17 22:27:49,752 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-17 22:27:49,762 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-17 22:27:49,762 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 22:27:49,762 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-08-17 22:27:49,762 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-17 22:27:49,763 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-17 22:27:49,763 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-17 22:27:49,763 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-17 22:27:49,765 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-17 22:27:49,765 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-17 22:27:49,765 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-17 22:27:49,775 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-17 22:27:49,826 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-17 22:27:49,830 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-17 22:27:49,842 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-17 22:27:49,844 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-17 22:27:49,844 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-17 22:27:49,844 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-17 22:27:49,858 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-17 22:27:49,858 INFO org.mortbay.log: jetty-6.1.26
2019-08-17 22:27:50,047 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-17 22:27:50,047 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-17 22:27:50,048 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-08-17 22:27:50,048 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-17 22:35:51,237 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.56.101:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-08-17 22:35:52,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.56.101:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-08-17 22:35:53,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.56.101:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-08-17 22:35:54,243 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.56.101:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-08-17 22:35:55,244 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.56.101:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-08-17 22:35:56,247 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.56.101:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-08-17 22:35:57,251 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.56.101:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-08-17 22:35:58,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.56.101:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-08-17 22:35:59,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.56.101:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-08-17 22:35:59,377 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-08-17 22:35:59,380 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.56.102
************************************************************/
2019-08-17 22:37:55,270 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.56.102
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-17 22:37:55,279 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-17 22:37:55,748 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-17 22:37:55,816 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-17 22:37:55,816 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-17 22:37:55,942 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-hdu/dfs/namesecondary/in_use.lock acquired by nodename 4961@um2
2019-08-17 22:37:55,945 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-17 22:37:55,949 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-17 22:37:55,986 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-17 22:37:55,986 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-17 22:37:55,987 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-17 22:37:55,990 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 17 22:37:55
2019-08-17 22:37:55,991 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-17 22:37:55,992 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 22:37:55,993 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-08-17 22:37:55,993 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-17 22:37:56,004 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-17 22:37:56,004 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-17 22:37:56,004 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-17 22:37:56,004 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-17 22:37:56,004 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-17 22:37:56,004 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-17 22:37:56,004 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-17 22:37:56,004 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-17 22:37:56,008 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-17 22:37:56,008 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-17 22:37:56,008 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-17 22:37:56,009 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-17 22:37:56,010 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-17 22:37:56,287 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-17 22:37:56,287 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 22:37:56,287 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-08-17 22:37:56,287 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-17 22:37:56,304 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-17 22:37:56,310 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-17 22:37:56,310 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-17 22:37:56,310 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-08-17 22:37:56,310 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-17 22:37:56,311 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-17 22:37:56,311 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-17 22:37:56,311 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-17 22:37:56,313 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-17 22:37:56,313 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-17 22:37:56,313 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-17 22:37:56,320 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-17 22:37:56,369 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-17 22:37:56,373 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-17 22:37:56,380 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-17 22:37:56,381 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-17 22:37:56,383 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-17 22:37:56,383 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-17 22:37:56,395 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-17 22:37:56,396 INFO org.mortbay.log: jetty-6.1.26
2019-08-17 22:37:56,571 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-17 22:37:56,571 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-17 22:37:56,571 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-08-17 22:37:56,571 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-18 20:11:38,267 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.1.107
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-18 20:11:38,283 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-18 20:11:38,845 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-18 20:11:38,943 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-18 20:11:38,943 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-18 20:11:39,061 WARN org.apache.hadoop.hdfs.server.common.Util: Path /abc/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-08-18 20:11:39,061 WARN org.apache.hadoop.hdfs.server.common.Util: Path /abc/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-08-18 20:11:39,128 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /abc/snnfsi/in_use.lock acquired by nodename 3719@um2
2019-08-18 20:11:39,132 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /abc/snnedits/in_use.lock acquired by nodename 3719@um2
2019-08-18 20:11:39,135 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-18 20:11:39,142 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-18 20:11:39,181 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-18 20:11:39,181 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-18 20:11:39,182 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-18 20:11:39,183 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 18 20:11:39
2019-08-18 20:11:39,185 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-18 20:11:39,185 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-18 20:11:39,187 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-08-18 20:11:39,187 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-18 20:11:39,218 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-18 20:11:39,218 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-18 20:11:39,218 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-18 20:11:39,218 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-18 20:11:39,218 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-18 20:11:39,218 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-18 20:11:39,219 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-18 20:11:39,219 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-18 20:11:39,219 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-18 20:11:39,219 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-18 20:11:39,219 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-18 20:11:39,219 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-18 20:11:39,221 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-18 20:11:39,556 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-18 20:11:39,556 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-18 20:11:39,557 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-08-18 20:11:39,557 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-18 20:11:39,614 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-18 20:11:39,624 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-18 20:11:39,624 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-18 20:11:39,625 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-08-18 20:11:39,625 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-18 20:11:39,626 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-18 20:11:39,626 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-18 20:11:39,626 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-18 20:11:39,635 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-18 20:11:39,636 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-18 20:11:39,636 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-18 20:11:39,646 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-18 20:11:39,683 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-18 20:11:39,686 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-18 20:11:39,696 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-18 20:11:39,698 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-18 20:11:39,699 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-18 20:11:39,699 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-18 20:11:39,716 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-18 20:11:39,717 INFO org.mortbay.log: jetty-6.1.26
2019-08-18 20:11:39,884 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-18 20:11:39,884 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-18 20:11:39,885 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-08-18 20:11:39,885 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-18 20:12:40,586 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-08-18 20:12:40,986 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=0&storageInfo=-60:99967847:0:CID-53e8f40d-f196-4cd0-b9c3-5682684adae4
2019-08-18 20:12:41,096 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-08-18 20:12:41,585 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.07s at 0.00 KB/s
2019-08-18 20:12:41,589 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 319 bytes.
2019-08-18 20:12:41,603 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1&endTxId=2&storageInfo=-60:99967847:0:CID-53e8f40d-f196-4cd0-b9c3-5682684adae4
2019-08-18 20:12:41,609 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-18 20:12:41,609 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000002_0000000000000739189 size 0 bytes.
2019-08-18 20:12:41,696 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-08-18 20:12:41,731 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-08-18 20:12:41,732 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /abc/snnfsi/current/fsimage_0000000000000000000
2019-08-18 20:12:41,732 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-08-18 20:12:41,750 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-08-18 20:12:41,753 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000001-0000000000000000002 expecting start txid #1
2019-08-18 20:12:41,753 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000001-0000000000000000002
2019-08-18 20:12:41,785 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000001-0000000000000000002 of size 42 edits # 2 loaded in 0 seconds
2019-08-18 20:12:41,792 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000002 using no compression
2019-08-18 20:12:41,871 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000002 of size 319 bytes saved in 0 seconds.
2019-08-18 20:12:41,884 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /abc/snnfsi
2019-08-18 20:12:41,885 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /abc/snnedits
2019-08-18 20:12:41,940 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2 to namenode at http://um1:50070 in 0.031 seconds
2019-08-18 20:12:41,941 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 319
2019-08-18 20:22:42,073 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-08-18 20:22:42,074 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3&endTxId=4&storageInfo=-60:99967847:0:CID-53e8f40d-f196-4cd0-b9c3-5682684adae4
2019-08-18 20:22:42,079 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-18 20:22:42,079 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000003-0000000000000000004_0000000000001339660 size 0 bytes.
2019-08-18 20:22:42,079 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-08-18 20:22:42,079 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000003-0000000000000000004 expecting start txid #3
2019-08-18 20:22:42,079 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000003-0000000000000000004
2019-08-18 20:22:42,079 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000003-0000000000000000004 of size 42 edits # 2 loaded in 0 seconds
2019-08-18 20:22:42,081 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000004 using no compression
2019-08-18 20:22:42,082 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000004 of size 319 bytes saved in 0 seconds.
2019-08-18 20:22:42,088 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2
2019-08-18 20:22:42,088 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-08-18 20:22:42,109 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 4 to namenode at http://um1:50070 in 0.015 seconds
2019-08-18 20:22:42,109 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 319
2019-08-24 15:45:17,975 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.0.162
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-24 15:45:17,989 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-24 15:45:18,509 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-24 15:45:18,593 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-24 15:45:18,593 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-24 15:45:18,748 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-hdu/dfs/namesecondary/in_use.lock acquired by nodename 6494@um2
2019-08-24 15:45:18,754 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-24 15:45:18,760 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-24 15:45:18,795 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-24 15:45:18,795 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-24 15:45:18,796 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-24 15:45:18,797 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 24 15:45:18
2019-08-24 15:45:18,798 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-24 15:45:18,798 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-24 15:45:18,799 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-08-24 15:45:18,799 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-24 15:45:18,814 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-24 15:45:18,814 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-24 15:45:18,814 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-24 15:45:18,814 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-24 15:45:18,814 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-24 15:45:18,814 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-24 15:45:18,814 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-24 15:45:18,814 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-24 15:45:18,815 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-24 15:45:18,815 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-24 15:45:18,815 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-24 15:45:18,815 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-24 15:45:18,816 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-24 15:45:19,117 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-24 15:45:19,117 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-24 15:45:19,117 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-08-24 15:45:19,117 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-24 15:45:19,149 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-24 15:45:19,156 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-24 15:45:19,156 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-24 15:45:19,156 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-08-24 15:45:19,156 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-24 15:45:19,157 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-24 15:45:19,157 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-24 15:45:19,157 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-24 15:45:19,158 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-24 15:45:19,159 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-24 15:45:19,159 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-24 15:45:19,167 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-24 15:45:19,202 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-24 15:45:19,205 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-24 15:45:19,212 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-24 15:45:19,213 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-24 15:45:19,215 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-24 15:45:19,215 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-24 15:45:19,231 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-24 15:45:19,231 INFO org.mortbay.log: jetty-6.1.26
2019-08-24 15:45:19,390 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-24 15:45:19,390 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-24 15:45:19,391 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2019-08-24 15:45:19,391 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-24 16:44:28,262 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.0.162
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-24 16:44:28,273 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-24 16:44:28,904 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-24 16:44:29,001 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-24 16:44:29,001 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-24 16:44:29,123 WARN org.apache.hadoop.hdfs.server.common.Util: Path /abc/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-08-24 16:44:29,123 WARN org.apache.hadoop.hdfs.server.common.Util: Path /abc/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-08-24 16:44:29,196 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /abc/snnfsi/in_use.lock acquired by nodename 2448@um2
2019-08-24 16:44:29,200 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /abc/snnedits/in_use.lock acquired by nodename 2448@um2
2019-08-24 16:44:29,203 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-24 16:44:29,212 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-24 16:44:29,259 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-24 16:44:29,259 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-24 16:44:29,260 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-24 16:44:29,262 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 24 16:44:29
2019-08-24 16:44:29,263 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-24 16:44:29,263 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-24 16:44:29,265 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-08-24 16:44:29,265 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-24 16:44:29,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-24 16:44:29,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-24 16:44:29,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-24 16:44:29,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-24 16:44:29,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-24 16:44:29,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-24 16:44:29,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-24 16:44:29,293 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-24 16:44:29,294 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-24 16:44:29,294 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-24 16:44:29,294 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-24 16:44:29,295 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-24 16:44:29,297 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-24 16:44:29,632 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-24 16:44:29,632 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-24 16:44:29,633 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-08-24 16:44:29,633 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-24 16:44:29,698 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-24 16:44:29,704 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-24 16:44:29,704 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-24 16:44:29,704 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-08-24 16:44:29,704 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-24 16:44:29,705 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-24 16:44:29,705 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-24 16:44:29,712 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-24 16:44:29,714 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-24 16:44:29,715 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-24 16:44:29,715 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-24 16:44:29,725 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-24 16:44:29,772 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-24 16:44:29,775 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-24 16:44:29,784 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-24 16:44:29,786 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-24 16:44:29,787 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-24 16:44:29,787 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-24 16:44:29,800 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-24 16:44:29,800 INFO org.mortbay.log: jetty-6.1.26
2019-08-24 16:44:29,997 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-24 16:44:29,997 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-24 16:44:29,997 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-08-24 16:44:29,997 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-24 16:45:30,414 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-08-24 16:45:30,695 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=0&storageInfo=-60:804391968:0:CID-e25e4270-427a-4520-a8b7-59f8b1595f90
2019-08-24 16:45:30,803 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-08-24 16:45:31,185 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.12s at 0.00 KB/s
2019-08-24 16:45:31,186 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 320 bytes.
2019-08-24 16:45:31,196 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1&endTxId=2&storageInfo=-60:804391968:0:CID-e25e4270-427a-4520-a8b7-59f8b1595f90
2019-08-24 16:45:31,216 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 16:45:31,216 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000002_0000000000000706429 size 0 bytes.
2019-08-24 16:45:31,326 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-08-24 16:45:31,352 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-08-24 16:45:31,353 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /abc/snnfsi/current/fsimage_0000000000000000000
2019-08-24 16:45:31,353 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-08-24 16:45:31,362 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-08-24 16:45:31,368 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000001-0000000000000000002 expecting start txid #1
2019-08-24 16:45:31,368 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000001-0000000000000000002
2019-08-24 16:45:31,396 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000001-0000000000000000002 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 16:45:31,403 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000002 using no compression
2019-08-24 16:45:31,454 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000002 of size 320 bytes saved in 0 seconds.
2019-08-24 16:45:31,461 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /abc/snnfsi
2019-08-24 16:45:31,461 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /abc/snnedits
2019-08-24 16:45:31,535 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2 to namenode at http://um1:50070 in 0.046 seconds
2019-08-24 16:45:31,535 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 320
2019-08-24 16:55:31,700 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-08-24 16:55:31,700 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3&endTxId=11&storageInfo=-60:804391968:0:CID-e25e4270-427a-4520-a8b7-59f8b1595f90
2019-08-24 16:55:31,706 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 16:55:31,706 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000003-0000000000000000011_0000000000001306935 size 0 bytes.
2019-08-24 16:55:31,707 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-08-24 16:55:31,707 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000003-0000000000000000011 expecting start txid #3
2019-08-24 16:55:31,707 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000003-0000000000000000011
2019-08-24 16:55:31,723 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000003-0000000000000000011 of size 666 edits # 9 loaded in 0 seconds
2019-08-24 16:55:31,724 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000011 using no compression
2019-08-24 16:55:31,730 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000011 of size 729 bytes saved in 0 seconds.
2019-08-24 16:55:31,735 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2
2019-08-24 16:55:31,736 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-08-24 16:55:31,750 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 11 to namenode at http://um1:50070 in 0.011 seconds
2019-08-24 16:55:31,750 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 729
2019-08-24 17:00:46,798 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-08-24 17:00:46,799 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.0.162
************************************************************/
2019-08-24 17:02:15,235 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.0.162
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-24 17:02:15,283 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-24 17:02:17,083 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-24 17:02:17,319 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-24 17:02:17,319 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-24 17:02:17,613 WARN org.apache.hadoop.hdfs.server.common.Util: Path /abc/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-08-24 17:02:17,613 WARN org.apache.hadoop.hdfs.server.common.Util: Path /abc/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-08-24 17:02:17,764 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /abc/snnfsi/in_use.lock acquired by nodename 3985@um2
2019-08-24 17:02:17,941 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /abc/snnedits/in_use.lock acquired by nodename 3985@um2
2019-08-24 17:02:17,950 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-24 17:02:17,970 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-24 17:02:18,083 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-24 17:02:18,083 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-24 17:02:18,086 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-24 17:02:18,089 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 24 17:02:18
2019-08-24 17:02:18,091 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-24 17:02:18,092 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-24 17:02:18,094 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-08-24 17:02:18,094 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-24 17:02:18,126 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-24 17:02:18,129 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-24 17:02:18,129 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-24 17:02:18,129 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-24 17:02:18,129 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-24 17:02:18,129 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-24 17:02:18,138 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-24 17:02:18,138 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-24 17:02:18,139 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-24 17:02:18,139 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-24 17:02:18,139 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-24 17:02:18,140 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-24 17:02:18,142 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-24 17:02:19,091 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-24 17:02:19,091 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-24 17:02:19,092 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-08-24 17:02:19,092 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-24 17:02:19,093 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-24 17:02:19,107 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-24 17:02:19,107 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-24 17:02:19,107 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-08-24 17:02:19,107 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-24 17:02:19,109 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-24 17:02:19,109 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-24 17:02:19,109 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-24 17:02:19,111 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-24 17:02:19,117 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-24 17:02:19,117 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-24 17:02:19,136 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-24 17:02:19,248 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-24 17:02:19,253 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-24 17:02:19,268 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-24 17:02:19,271 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-24 17:02:19,273 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-24 17:02:19,274 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-24 17:02:19,297 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-24 17:02:19,298 INFO org.mortbay.log: jetty-6.1.26
2019-08-24 17:02:19,637 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-24 17:02:19,637 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-24 17:02:19,638 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-08-24 17:02:19,638 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-24 17:03:19,853 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 322677011 cTime = 0 ; clusterId = CID-403a0251-1604-44a0-b205-ccebae382a38 ; blockpoolId = BP-8011334-192.168.0.240-1566658908132.
Expecting respectively: -60; 804391968; 0; CID-e25e4270-427a-4520-a8b7-59f8b1595f90; BP-161396067-192.168.0.240-1566657744364.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-08-24 17:04:19,885 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 322677011 cTime = 0 ; clusterId = CID-403a0251-1604-44a0-b205-ccebae382a38 ; blockpoolId = BP-8011334-192.168.0.240-1566658908132.
Expecting respectively: -60; 804391968; 0; CID-e25e4270-427a-4520-a8b7-59f8b1595f90; BP-161396067-192.168.0.240-1566657744364.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-08-24 17:05:19,917 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 322677011 cTime = 0 ; clusterId = CID-403a0251-1604-44a0-b205-ccebae382a38 ; blockpoolId = BP-8011334-192.168.0.240-1566658908132.
Expecting respectively: -60; 804391968; 0; CID-e25e4270-427a-4520-a8b7-59f8b1595f90; BP-161396067-192.168.0.240-1566657744364.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-08-24 17:06:19,949 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 322677011 cTime = 0 ; clusterId = CID-403a0251-1604-44a0-b205-ccebae382a38 ; blockpoolId = BP-8011334-192.168.0.240-1566658908132.
Expecting respectively: -60; 804391968; 0; CID-e25e4270-427a-4520-a8b7-59f8b1595f90; BP-161396067-192.168.0.240-1566657744364.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-08-24 17:07:20,041 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 322677011 cTime = 0 ; clusterId = CID-403a0251-1604-44a0-b205-ccebae382a38 ; blockpoolId = BP-8011334-192.168.0.240-1566658908132.
Expecting respectively: -60; 804391968; 0; CID-e25e4270-427a-4520-a8b7-59f8b1595f90; BP-161396067-192.168.0.240-1566657744364.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-08-24 17:08:20,102 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 322677011 cTime = 0 ; clusterId = CID-403a0251-1604-44a0-b205-ccebae382a38 ; blockpoolId = BP-8011334-192.168.0.240-1566658908132.
Expecting respectively: -60; 804391968; 0; CID-e25e4270-427a-4520-a8b7-59f8b1595f90; BP-161396067-192.168.0.240-1566657744364.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-08-24 17:09:20,136 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 322677011 cTime = 0 ; clusterId = CID-403a0251-1604-44a0-b205-ccebae382a38 ; blockpoolId = BP-8011334-192.168.0.240-1566658908132.
Expecting respectively: -60; 804391968; 0; CID-e25e4270-427a-4520-a8b7-59f8b1595f90; BP-161396067-192.168.0.240-1566657744364.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-08-24 17:10:20,171 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 322677011 cTime = 0 ; clusterId = CID-403a0251-1604-44a0-b205-ccebae382a38 ; blockpoolId = BP-8011334-192.168.0.240-1566658908132.
Expecting respectively: -60; 804391968; 0; CID-e25e4270-427a-4520-a8b7-59f8b1595f90; BP-161396067-192.168.0.240-1566657744364.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-08-24 17:11:20,254 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 322677011 cTime = 0 ; clusterId = CID-403a0251-1604-44a0-b205-ccebae382a38 ; blockpoolId = BP-8011334-192.168.0.240-1566658908132.
Expecting respectively: -60; 804391968; 0; CID-e25e4270-427a-4520-a8b7-59f8b1595f90; BP-161396067-192.168.0.240-1566657744364.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-08-24 17:12:20,292 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 322677011 cTime = 0 ; clusterId = CID-403a0251-1604-44a0-b205-ccebae382a38 ; blockpoolId = BP-8011334-192.168.0.240-1566658908132.
Expecting respectively: -60; 804391968; 0; CID-e25e4270-427a-4520-a8b7-59f8b1595f90; BP-161396067-192.168.0.240-1566657744364.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-08-24 17:13:20,321 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 322677011 cTime = 0 ; clusterId = CID-403a0251-1604-44a0-b205-ccebae382a38 ; blockpoolId = BP-8011334-192.168.0.240-1566658908132.
Expecting respectively: -60; 804391968; 0; CID-e25e4270-427a-4520-a8b7-59f8b1595f90; BP-161396067-192.168.0.240-1566657744364.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-08-24 17:14:20,351 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 322677011 cTime = 0 ; clusterId = CID-403a0251-1604-44a0-b205-ccebae382a38 ; blockpoolId = BP-8011334-192.168.0.240-1566658908132.
Expecting respectively: -60; 804391968; 0; CID-e25e4270-427a-4520-a8b7-59f8b1595f90; BP-161396067-192.168.0.240-1566657744364.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-08-24 17:15:20,379 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 322677011 cTime = 0 ; clusterId = CID-403a0251-1604-44a0-b205-ccebae382a38 ; blockpoolId = BP-8011334-192.168.0.240-1566658908132.
Expecting respectively: -60; 804391968; 0; CID-e25e4270-427a-4520-a8b7-59f8b1595f90; BP-161396067-192.168.0.240-1566657744364.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-08-24 17:16:20,427 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 322677011 cTime = 0 ; clusterId = CID-403a0251-1604-44a0-b205-ccebae382a38 ; blockpoolId = BP-8011334-192.168.0.240-1566658908132.
Expecting respectively: -60; 804391968; 0; CID-e25e4270-427a-4520-a8b7-59f8b1595f90; BP-161396067-192.168.0.240-1566657744364.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-08-24 17:17:20,466 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 322677011 cTime = 0 ; clusterId = CID-403a0251-1604-44a0-b205-ccebae382a38 ; blockpoolId = BP-8011334-192.168.0.240-1566658908132.
Expecting respectively: -60; 804391968; 0; CID-e25e4270-427a-4520-a8b7-59f8b1595f90; BP-161396067-192.168.0.240-1566657744364.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-08-24 17:18:20,498 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 322677011 cTime = 0 ; clusterId = CID-403a0251-1604-44a0-b205-ccebae382a38 ; blockpoolId = BP-8011334-192.168.0.240-1566658908132.
Expecting respectively: -60; 804391968; 0; CID-e25e4270-427a-4520-a8b7-59f8b1595f90; BP-161396067-192.168.0.240-1566657744364.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-08-24 17:19:20,531 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 322677011 cTime = 0 ; clusterId = CID-403a0251-1604-44a0-b205-ccebae382a38 ; blockpoolId = BP-8011334-192.168.0.240-1566658908132.
Expecting respectively: -60; 804391968; 0; CID-e25e4270-427a-4520-a8b7-59f8b1595f90; BP-161396067-192.168.0.240-1566657744364.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-08-24 17:20:20,565 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 322677011 cTime = 0 ; clusterId = CID-403a0251-1604-44a0-b205-ccebae382a38 ; blockpoolId = BP-8011334-192.168.0.240-1566658908132.
Expecting respectively: -60; 804391968; 0; CID-e25e4270-427a-4520-a8b7-59f8b1595f90; BP-161396067-192.168.0.240-1566657744364.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-08-24 17:21:20,647 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 322677011 cTime = 0 ; clusterId = CID-403a0251-1604-44a0-b205-ccebae382a38 ; blockpoolId = BP-8011334-192.168.0.240-1566658908132.
Expecting respectively: -60; 804391968; 0; CID-e25e4270-427a-4520-a8b7-59f8b1595f90; BP-161396067-192.168.0.240-1566657744364.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-08-24 17:22:20,668 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 322677011 cTime = 0 ; clusterId = CID-403a0251-1604-44a0-b205-ccebae382a38 ; blockpoolId = BP-8011334-192.168.0.240-1566658908132.
Expecting respectively: -60; 804391968; 0; CID-e25e4270-427a-4520-a8b7-59f8b1595f90; BP-161396067-192.168.0.240-1566657744364.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-08-24 17:23:18,634 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-08-24 17:23:18,635 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.0.162
************************************************************/
2019-08-24 17:23:44,016 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.0.162
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-24 17:23:44,028 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-24 17:23:44,583 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-24 17:23:44,694 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-24 17:23:44,695 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-24 17:23:44,803 WARN org.apache.hadoop.hdfs.server.common.Util: Path /abc/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-08-24 17:23:44,803 WARN org.apache.hadoop.hdfs.server.common.Util: Path /abc/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-08-24 17:23:44,847 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /abc/snnfsi/in_use.lock acquired by nodename 4806@um2
2019-08-24 17:23:44,849 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /abc/snnedits/in_use.lock acquired by nodename 4806@um2
2019-08-24 17:23:44,851 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-24 17:23:44,855 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-24 17:23:44,889 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-24 17:23:44,889 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-24 17:23:44,890 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-24 17:23:44,892 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 24 17:23:44
2019-08-24 17:23:44,893 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-24 17:23:44,893 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-24 17:23:44,894 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-08-24 17:23:44,894 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-24 17:23:44,904 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-24 17:23:44,904 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-24 17:23:44,904 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-24 17:23:44,904 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-24 17:23:44,904 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-24 17:23:44,904 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-24 17:23:44,904 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-24 17:23:44,904 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-24 17:23:44,905 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-24 17:23:44,905 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-24 17:23:44,906 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-24 17:23:44,906 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-24 17:23:44,908 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-24 17:23:45,308 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-24 17:23:45,308 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-24 17:23:45,309 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-08-24 17:23:45,309 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-24 17:23:45,330 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-24 17:23:45,336 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-24 17:23:45,336 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-24 17:23:45,337 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-08-24 17:23:45,337 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-24 17:23:45,338 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-24 17:23:45,338 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-24 17:23:45,340 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-24 17:23:45,342 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-24 17:23:45,342 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-24 17:23:45,343 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-24 17:23:45,351 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-24 17:23:45,397 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-24 17:23:45,401 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-24 17:23:45,411 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-24 17:23:45,412 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-24 17:23:45,414 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-24 17:23:45,414 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-24 17:23:45,428 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-24 17:23:45,428 INFO org.mortbay.log: jetty-6.1.26
2019-08-24 17:23:45,627 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-24 17:23:45,627 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-24 17:23:45,627 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-08-24 17:23:45,627 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-24 17:24:45,906 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-08-24 17:24:46,021 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=0&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 17:24:46,066 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-08-24 17:24:46,324 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 0.00 KB/s
2019-08-24 17:24:46,324 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 320 bytes.
2019-08-24 17:24:46,329 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1&endTxId=2&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 17:24:46,334 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 17:24:46,334 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000002_0000000000003061564 size 0 bytes.
2019-08-24 17:24:46,334 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3&endTxId=4&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 17:24:46,339 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 17:24:46,339 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000003-0000000000000000004_0000000000003061569 size 0 bytes.
2019-08-24 17:24:46,339 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=5&endTxId=6&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 17:24:46,344 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 17:24:46,344 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000005-0000000000000000006_0000000000003061574 size 0 bytes.
2019-08-24 17:24:46,345 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=7&endTxId=8&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 17:24:46,350 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 17:24:46,350 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000007-0000000000000000008_0000000000003061579 size 0 bytes.
2019-08-24 17:24:46,351 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=9&endTxId=10&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 17:24:46,355 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 17:24:46,355 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000009-0000000000000000010_0000000000003061585 size 0 bytes.
2019-08-24 17:24:46,355 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=11&endTxId=12&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 17:24:46,362 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 17:24:46,362 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000011-0000000000000000012_0000000000003061589 size 0 bytes.
2019-08-24 17:24:46,362 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=13&endTxId=14&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 17:24:46,366 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 17:24:46,366 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000013-0000000000000000014_0000000000003061597 size 0 bytes.
2019-08-24 17:24:46,366 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=15&endTxId=16&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 17:24:46,369 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 17:24:46,369 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000015-0000000000000000016_0000000000003061601 size 0 bytes.
2019-08-24 17:24:46,370 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=17&endTxId=18&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 17:24:46,374 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 17:24:46,374 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000017-0000000000000000018_0000000000003061604 size 0 bytes.
2019-08-24 17:24:46,375 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=19&endTxId=20&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 17:24:46,381 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 17:24:46,381 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000019-0000000000000000020_0000000000003061609 size 0 bytes.
2019-08-24 17:24:46,381 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=21&endTxId=22&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 17:24:46,385 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 17:24:46,385 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000021-0000000000000000022_0000000000003061616 size 0 bytes.
2019-08-24 17:24:46,385 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=23&endTxId=24&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 17:24:46,389 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 17:24:46,389 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000023-0000000000000000024_0000000000003061620 size 0 bytes.
2019-08-24 17:24:46,390 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=25&endTxId=26&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 17:24:46,394 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 17:24:46,394 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000025-0000000000000000026_0000000000003061624 size 0 bytes.
2019-08-24 17:24:46,394 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=27&endTxId=28&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 17:24:46,398 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 17:24:46,399 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000027-0000000000000000028_0000000000003061629 size 0 bytes.
2019-08-24 17:24:46,399 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=29&endTxId=30&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 17:24:46,403 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 17:24:46,403 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000029-0000000000000000030_0000000000003061633 size 0 bytes.
2019-08-24 17:24:46,405 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=31&endTxId=32&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 17:24:46,410 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 17:24:46,410 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000031-0000000000000000032_0000000000003061640 size 0 bytes.
2019-08-24 17:24:46,410 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=33&endTxId=34&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 17:24:46,423 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-08-24 17:24:46,423 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000033-0000000000000000034_0000000000003061645 size 0 bytes.
2019-08-24 17:24:46,424 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=35&endTxId=36&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 17:24:46,428 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 17:24:46,429 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000035-0000000000000000036_0000000000003061658 size 0 bytes.
2019-08-24 17:24:46,429 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=37&endTxId=38&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 17:24:46,438 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 17:24:46,438 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000037-0000000000000000038_0000000000003061663 size 0 bytes.
2019-08-24 17:24:46,439 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=39&endTxId=41&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 17:24:46,450 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 17:24:46,450 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000039-0000000000000000041_0000000000003061673 size 0 bytes.
2019-08-24 17:24:46,456 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=42&endTxId=43&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 17:24:46,461 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 17:24:46,461 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000042-0000000000000000043_0000000000003061690 size 0 bytes.
2019-08-24 17:24:46,498 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-08-24 17:24:46,518 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-08-24 17:24:46,518 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /abc/snnfsi/current/fsimage_0000000000000000000
2019-08-24 17:24:46,518 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-08-24 17:24:46,523 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 21 stream(s).
2019-08-24 17:24:46,530 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000001-0000000000000000002 expecting start txid #1
2019-08-24 17:24:46,530 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000001-0000000000000000002
2019-08-24 17:24:46,550 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000001-0000000000000000002 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 17:24:46,550 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000003-0000000000000000004 expecting start txid #3
2019-08-24 17:24:46,550 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000003-0000000000000000004
2019-08-24 17:24:46,550 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000003-0000000000000000004 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 17:24:46,551 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000005-0000000000000000006 expecting start txid #5
2019-08-24 17:24:46,551 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000005-0000000000000000006
2019-08-24 17:24:46,551 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000005-0000000000000000006 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 17:24:46,551 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000007-0000000000000000008 expecting start txid #7
2019-08-24 17:24:46,551 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000007-0000000000000000008
2019-08-24 17:24:46,552 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000007-0000000000000000008 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 17:24:46,552 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000009-0000000000000000010 expecting start txid #9
2019-08-24 17:24:46,552 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000009-0000000000000000010
2019-08-24 17:24:46,552 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000009-0000000000000000010 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 17:24:46,552 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000011-0000000000000000012 expecting start txid #11
2019-08-24 17:24:46,552 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000011-0000000000000000012
2019-08-24 17:24:46,554 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000011-0000000000000000012 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 17:24:46,554 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000013-0000000000000000014 expecting start txid #13
2019-08-24 17:24:46,554 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000013-0000000000000000014
2019-08-24 17:24:46,554 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000013-0000000000000000014 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 17:24:46,554 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000015-0000000000000000016 expecting start txid #15
2019-08-24 17:24:46,554 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000015-0000000000000000016
2019-08-24 17:24:46,555 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000015-0000000000000000016 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 17:24:46,555 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000017-0000000000000000018 expecting start txid #17
2019-08-24 17:24:46,555 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000017-0000000000000000018
2019-08-24 17:24:46,557 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000017-0000000000000000018 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 17:24:46,557 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000019-0000000000000000020 expecting start txid #19
2019-08-24 17:24:46,557 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000019-0000000000000000020
2019-08-24 17:24:46,559 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000019-0000000000000000020 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 17:24:46,559 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000021-0000000000000000022 expecting start txid #21
2019-08-24 17:24:46,559 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000021-0000000000000000022
2019-08-24 17:24:46,559 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000021-0000000000000000022 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 17:24:46,559 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000023-0000000000000000024 expecting start txid #23
2019-08-24 17:24:46,559 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000023-0000000000000000024
2019-08-24 17:24:46,560 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000023-0000000000000000024 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 17:24:46,560 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000025-0000000000000000026 expecting start txid #25
2019-08-24 17:24:46,560 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000025-0000000000000000026
2019-08-24 17:24:46,561 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000025-0000000000000000026 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 17:24:46,561 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000027-0000000000000000028 expecting start txid #27
2019-08-24 17:24:46,561 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000027-0000000000000000028
2019-08-24 17:24:46,561 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000027-0000000000000000028 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 17:24:46,561 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000029-0000000000000000030 expecting start txid #29
2019-08-24 17:24:46,561 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000029-0000000000000000030
2019-08-24 17:24:46,562 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000029-0000000000000000030 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 17:24:46,562 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000031-0000000000000000032 expecting start txid #31
2019-08-24 17:24:46,562 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000031-0000000000000000032
2019-08-24 17:24:46,562 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000031-0000000000000000032 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 17:24:46,562 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000033-0000000000000000034 expecting start txid #33
2019-08-24 17:24:46,562 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000033-0000000000000000034
2019-08-24 17:24:46,562 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000033-0000000000000000034 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 17:24:46,562 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000035-0000000000000000036 expecting start txid #35
2019-08-24 17:24:46,565 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000035-0000000000000000036
2019-08-24 17:24:46,566 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000035-0000000000000000036 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 17:24:46,566 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000037-0000000000000000038 expecting start txid #37
2019-08-24 17:24:46,566 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000037-0000000000000000038
2019-08-24 17:24:46,566 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000037-0000000000000000038 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 17:24:46,566 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000039-0000000000000000041 expecting start txid #39
2019-08-24 17:24:46,566 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000039-0000000000000000041
2019-08-24 17:24:46,593 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000039-0000000000000000041 of size 114 edits # 3 loaded in 0 seconds
2019-08-24 17:24:46,593 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000042-0000000000000000043 expecting start txid #42
2019-08-24 17:24:46,593 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000042-0000000000000000043
2019-08-24 17:24:46,594 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000042-0000000000000000043 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 17:24:46,599 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000043 using no compression
2019-08-24 17:24:46,644 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000043 of size 397 bytes saved in 0 seconds.
2019-08-24 17:24:46,647 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /abc/snnfsi
2019-08-24 17:24:46,648 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /abc/snnedits
2019-08-24 17:24:46,692 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 43 to namenode at http://um1:50070 in 0.033 seconds
2019-08-24 17:24:46,692 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 397
2019-08-24 17:34:46,821 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-08-24 17:34:46,821 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=44&endTxId=57&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 17:34:46,826 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 500.00 KB/s
2019-08-24 17:34:46,826 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000044-0000000000000000057_0000000000003662056 size 0 bytes.
2019-08-24 17:34:46,827 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-08-24 17:34:46,827 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000044-0000000000000000057 expecting start txid #44
2019-08-24 17:34:46,827 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000044-0000000000000000057
2019-08-24 17:34:46,838 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000044-0000000000000000057 of size 1062 edits # 14 loaded in 0 seconds
2019-08-24 17:34:46,839 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000057 using no compression
2019-08-24 17:34:46,848 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000057 of size 539 bytes saved in 0 seconds.
2019-08-24 17:34:46,857 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 43
2019-08-24 17:34:46,858 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-08-24 17:34:46,892 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 57 to namenode at http://um1:50070 in 0.025 seconds
2019-08-24 17:34:46,892 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 539
2019-08-24 17:44:47,083 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-08-24 17:44:47,083 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=58&endTxId=59&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 17:44:47,088 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 17:44:47,088 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000058-0000000000000000059_0000000000004262318 size 0 bytes.
2019-08-24 17:44:47,089 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-08-24 17:44:47,089 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000058-0000000000000000059 expecting start txid #58
2019-08-24 17:44:47,089 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000058-0000000000000000059
2019-08-24 17:44:47,089 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000058-0000000000000000059 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 17:44:47,090 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000059 using no compression
2019-08-24 17:44:47,095 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000059 of size 539 bytes saved in 0 seconds.
2019-08-24 17:44:47,098 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 57
2019-08-24 17:44:47,099 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000043, cpktTxId=0000000000000000043)
2019-08-24 17:44:47,115 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 59 to namenode at http://um1:50070 in 0.011 seconds
2019-08-24 17:44:47,115 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 539
2019-08-24 17:54:47,218 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-08-24 17:54:47,219 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=60&endTxId=141&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 17:54:47,225 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 3500.00 KB/s
2019-08-24 17:54:47,225 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000060-0000000000000000141_0000000000004862453 size 0 bytes.
2019-08-24 17:54:47,226 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-08-24 17:54:47,226 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000060-0000000000000000141 expecting start txid #60
2019-08-24 17:54:47,226 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000060-0000000000000000141
2019-08-24 17:54:47,240 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000060-0000000000000000141 of size 7941 edits # 82 loaded in 0 seconds
2019-08-24 17:54:47,240 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000141 using no compression
2019-08-24 17:54:47,244 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000141 of size 1608 bytes saved in 0 seconds.
2019-08-24 17:54:47,247 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 59
2019-08-24 17:54:47,247 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000057, cpktTxId=0000000000000000057)
2019-08-24 17:54:47,266 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 141 to namenode at http://um1:50070 in 0.014 seconds
2019-08-24 17:54:47,266 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1608
2019-08-24 18:04:47,409 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-08-24 18:04:47,409 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=142&endTxId=143&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 18:04:47,418 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 18:04:47,418 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000142-0000000000000000143_0000000000005462644 size 0 bytes.
2019-08-24 18:04:47,418 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-08-24 18:04:47,418 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000142-0000000000000000143 expecting start txid #142
2019-08-24 18:04:47,418 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000142-0000000000000000143
2019-08-24 18:04:47,419 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000142-0000000000000000143 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 18:04:47,421 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000143 using no compression
2019-08-24 18:04:47,430 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000143 of size 1608 bytes saved in 0 seconds.
2019-08-24 18:04:47,435 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 141
2019-08-24 18:04:47,435 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000059, cpktTxId=0000000000000000059)
2019-08-24 18:04:47,454 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 143 to namenode at http://um1:50070 in 0.015 seconds
2019-08-24 18:04:47,455 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1608
2019-08-24 18:14:47,551 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-08-24 18:14:47,551 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=144&endTxId=145&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 18:14:47,556 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 18:14:47,556 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000144-0000000000000000145_0000000000006062785 size 0 bytes.
2019-08-24 18:14:47,556 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-08-24 18:14:47,556 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000144-0000000000000000145 expecting start txid #144
2019-08-24 18:14:47,556 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000144-0000000000000000145
2019-08-24 18:14:47,556 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000144-0000000000000000145 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 18:14:47,557 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000145 using no compression
2019-08-24 18:14:47,562 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000145 of size 1608 bytes saved in 0 seconds.
2019-08-24 18:14:47,564 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 143
2019-08-24 18:14:47,564 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000141, cpktTxId=0000000000000000141)
2019-08-24 18:14:47,577 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 145 to namenode at http://um1:50070 in 0.008 seconds
2019-08-24 18:14:47,577 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1608
2019-08-24 18:24:47,698 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-08-24 18:24:47,698 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=146&endTxId=147&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 18:24:47,706 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 18:24:47,706 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000146-0000000000000000147_0000000000006662933 size 0 bytes.
2019-08-24 18:24:47,712 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-08-24 18:24:47,712 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000146-0000000000000000147 expecting start txid #146
2019-08-24 18:24:47,713 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000146-0000000000000000147
2019-08-24 18:24:47,713 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000146-0000000000000000147 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 18:24:47,714 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000147 using no compression
2019-08-24 18:24:47,718 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000147 of size 1608 bytes saved in 0 seconds.
2019-08-24 18:24:47,721 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 145
2019-08-24 18:24:47,721 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000143, cpktTxId=0000000000000000143)
2019-08-24 18:24:47,732 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 147 to namenode at http://um1:50070 in 0.008 seconds
2019-08-24 18:24:47,732 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1608
2019-08-24 18:34:47,873 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-08-24 18:34:47,873 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=148&endTxId=172&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 18:34:47,879 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 500.00 KB/s
2019-08-24 18:34:47,880 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000148-0000000000000000172_0000000000007263108 size 0 bytes.
2019-08-24 18:34:47,880 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-08-24 18:34:47,880 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000148-0000000000000000172 expecting start txid #148
2019-08-24 18:34:47,880 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000148-0000000000000000172
2019-08-24 18:34:47,889 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000148-0000000000000000172 of size 1954 edits # 25 loaded in 0 seconds
2019-08-24 18:34:47,889 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000172 using no compression
2019-08-24 18:34:47,896 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000172 of size 1862 bytes saved in 0 seconds.
2019-08-24 18:34:47,899 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 147
2019-08-24 18:34:47,899 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000145, cpktTxId=0000000000000000145)
2019-08-24 18:34:47,912 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 172 to namenode at http://um1:50070 in 0.009 seconds
2019-08-24 18:34:47,912 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1862
2019-08-24 18:44:48,027 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-08-24 18:44:48,028 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=173&endTxId=365&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 18:44:48,033 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 5666.67 KB/s
2019-08-24 18:44:48,033 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000173-0000000000000000365_0000000000007863262 size 0 bytes.
2019-08-24 18:44:48,034 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-08-24 18:44:48,034 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000173-0000000000000000365 expecting start txid #173
2019-08-24 18:44:48,034 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000173-0000000000000000365
2019-08-24 18:44:48,058 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000173-0000000000000000365 of size 18413 edits # 193 loaded in 0 seconds
2019-08-24 18:44:48,058 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000365 using no compression
2019-08-24 18:44:48,062 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000365 of size 2975 bytes saved in 0 seconds.
2019-08-24 18:44:48,065 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 172
2019-08-24 18:44:48,065 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000147, cpktTxId=0000000000000000147)
2019-08-24 18:44:48,078 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 365 to namenode at http://um1:50070 in 0.01 seconds
2019-08-24 18:44:48,078 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2975
2019-08-24 18:54:48,293 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-08-24 18:54:48,294 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=366&endTxId=367&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 18:54:48,645 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 29257.14 KB/s
2019-08-24 18:54:48,645 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000366-0000000000000000367_0000000000008463528 size 0 bytes.
2019-08-24 18:54:48,645 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=368&endTxId=369&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 18:54:48,650 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 18:54:48,650 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000368-0000000000000000369_0000000000008463879 size 0 bytes.
2019-08-24 18:54:48,651 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2019-08-24 18:54:48,651 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000366-0000000000000000367 expecting start txid #366
2019-08-24 18:54:48,651 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000366-0000000000000000367
2019-08-24 18:54:48,653 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000366-0000000000000000367 of size 1048576 edits # 2 loaded in 0 seconds
2019-08-24 18:54:48,653 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000368-0000000000000000369 expecting start txid #368
2019-08-24 18:54:48,653 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000368-0000000000000000369
2019-08-24 18:54:48,653 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000368-0000000000000000369 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 18:54:48,658 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000369 using no compression
2019-08-24 18:54:48,669 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000369 of size 1906 bytes saved in 0 seconds.
2019-08-24 18:54:48,675 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 365
2019-08-24 18:54:48,675 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000172, cpktTxId=0000000000000000172)
2019-08-24 18:54:48,706 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 369 to namenode at http://um1:50070 in 0.028 seconds
2019-08-24 18:54:48,706 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1906
2019-08-24 18:59:05,388 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-08-24 18:59:05,390 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.0.162
************************************************************/
2019-08-24 19:00:41,935 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.0.162
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-08-24 19:00:41,946 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-08-24 19:00:42,502 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-08-24 19:00:42,568 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-08-24 19:00:42,568 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-08-24 19:00:42,671 WARN org.apache.hadoop.hdfs.server.common.Util: Path /abc/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-08-24 19:00:42,672 WARN org.apache.hadoop.hdfs.server.common.Util: Path /abc/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-08-24 19:00:42,724 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /abc/snnfsi/in_use.lock acquired by nodename 6396@um2
2019-08-24 19:00:42,785 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /abc/snnedits/in_use.lock acquired by nodename 6396@um2
2019-08-24 19:00:42,795 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-08-24 19:00:42,801 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-08-24 19:00:42,836 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-08-24 19:00:42,836 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-08-24 19:00:42,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-08-24 19:00:42,839 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Aug 24 19:00:42
2019-08-24 19:00:42,840 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-08-24 19:00:42,840 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-24 19:00:42,842 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-08-24 19:00:42,842 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-08-24 19:00:42,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-08-24 19:00:42,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-08-24 19:00:42,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-08-24 19:00:42,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-08-24 19:00:42,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-08-24 19:00:42,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-08-24 19:00:42,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-08-24 19:00:42,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-08-24 19:00:42,854 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-08-24 19:00:42,854 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-08-24 19:00:42,854 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-08-24 19:00:42,854 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-08-24 19:00:42,855 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-08-24 19:00:43,219 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-08-24 19:00:43,219 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-24 19:00:43,219 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-08-24 19:00:43,219 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-08-24 19:00:43,220 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-08-24 19:00:43,225 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-08-24 19:00:43,225 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-08-24 19:00:43,225 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-08-24 19:00:43,225 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-08-24 19:00:43,227 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-08-24 19:00:43,227 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-08-24 19:00:43,227 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-08-24 19:00:43,230 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-08-24 19:00:43,231 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-08-24 19:00:43,231 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-08-24 19:00:43,241 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-08-24 19:00:43,286 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-08-24 19:00:43,290 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-08-24 19:00:43,302 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-08-24 19:00:43,304 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-08-24 19:00:43,306 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-08-24 19:00:43,306 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-08-24 19:00:43,322 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-08-24 19:00:43,322 INFO org.mortbay.log: jetty-6.1.26
2019-08-24 19:00:43,543 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-08-24 19:00:43,543 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-08-24 19:00:43,543 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-08-24 19:00:43,543 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-08-24 19:01:43,715 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-08-24 19:01:43,872 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=595&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 19:01:43,916 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-08-24 19:01:43,936 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 833.33 KB/s
2019-08-24 19:01:43,936 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000595 size 5460 bytes.
2019-08-24 19:01:43,946 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=596&endTxId=597&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-08-24 19:01:43,955 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-08-24 19:01:43,955 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000596-0000000000000000597_0000000000008879180 size 0 bytes.
2019-08-24 19:01:44,012 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 64 INodes.
2019-08-24 19:01:44,059 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-08-24 19:01:44,059 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 595 from /abc/snnfsi/current/fsimage_0000000000000000595
2019-08-24 19:01:44,059 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-08-24 19:01:44,063 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-08-24 19:01:44,068 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000596-0000000000000000597 expecting start txid #596
2019-08-24 19:01:44,069 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000596-0000000000000000597
2019-08-24 19:01:44,090 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000596-0000000000000000597 of size 42 edits # 2 loaded in 0 seconds
2019-08-24 19:01:44,095 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000597 using no compression
2019-08-24 19:01:44,178 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000597 of size 5460 bytes saved in 0 seconds.
2019-08-24 19:01:44,189 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 595
2019-08-24 19:01:44,189 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000369, cpktTxId=0000000000000000369)
2019-08-24 19:01:44,240 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 597 to namenode at http://um1:50070 in 0.023 seconds
2019-08-24 19:01:44,240 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5460
2019-09-08 06:37:58,289 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.0.163
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-09-08 06:37:58,303 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-08 06:37:58,860 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-08 06:37:58,929 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-09-08 06:37:58,929 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-08 06:37:59,045 WARN org.apache.hadoop.hdfs.server.common.Util: Path /abc/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-08 06:37:59,046 WARN org.apache.hadoop.hdfs.server.common.Util: Path /abc/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-08 06:37:59,128 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /abc/snnfsi/in_use.lock acquired by nodename 17391@um2
2019-09-08 06:37:59,214 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /abc/snnedits/in_use.lock acquired by nodename 17391@um2
2019-09-08 06:37:59,221 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-09-08 06:37:59,236 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-09-08 06:37:59,289 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-09-08 06:37:59,289 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-08 06:37:59,291 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-08 06:37:59,292 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Sep 08 06:37:59
2019-09-08 06:37:59,294 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-09-08 06:37:59,294 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-08 06:37:59,295 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-09-08 06:37:59,295 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-09-08 06:37:59,305 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-09-08 06:37:59,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-09-08 06:37:59,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-09-08 06:37:59,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-09-08 06:37:59,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-09-08 06:37:59,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-09-08 06:37:59,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-09-08 06:37:59,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-09-08 06:37:59,307 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-09-08 06:37:59,307 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-09-08 06:37:59,307 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-09-08 06:37:59,307 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-09-08 06:37:59,310 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-09-08 06:37:59,668 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-09-08 06:37:59,668 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-08 06:37:59,668 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-09-08 06:37:59,668 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-09-08 06:37:59,669 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-09-08 06:37:59,676 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-09-08 06:37:59,676 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-08 06:37:59,676 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-09-08 06:37:59,676 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-09-08 06:37:59,677 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-08 06:37:59,678 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-09-08 06:37:59,678 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-09-08 06:37:59,679 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-09-08 06:37:59,679 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-09-08 06:37:59,679 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-09-08 06:37:59,688 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-09-08 06:37:59,726 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-08 06:37:59,729 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-09-08 06:37:59,736 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-08 06:37:59,738 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-09-08 06:37:59,738 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-08 06:37:59,738 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-08 06:37:59,750 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-09-08 06:37:59,750 INFO org.mortbay.log: jetty-6.1.26
2019-09-08 06:37:59,928 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-09-08 06:37:59,928 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-09-08 06:37:59,928 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-09-08 06:37:59,929 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-09-08 06:39:00,185 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-09-08 06:39:00,414 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=610&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-08 06:39:00,465 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-09-08 06:39:00,668 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 833.33 KB/s
2019-09-08 06:39:00,670 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000610 size 5626 bytes.
2019-09-08 06:39:00,677 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=611&endTxId=618&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-08 06:39:00,685 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-08 06:39:00,685 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000611-0000000000000000618_0000000000003790253 size 0 bytes.
2019-09-08 06:39:00,732 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 66 INodes.
2019-09-08 06:39:00,775 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-09-08 06:39:00,775 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 610 from /abc/snnfsi/current/fsimage_0000000000000000610
2019-09-08 06:39:00,775 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-09-08 06:39:00,784 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-08 06:39:00,790 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000611-0000000000000000618 expecting start txid #611
2019-09-08 06:39:00,790 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000611-0000000000000000618
2019-09-08 06:39:00,834 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000611-0000000000000000618 of size 606 edits # 8 loaded in 0 seconds
2019-09-08 06:39:00,842 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000618 using no compression
2019-09-08 06:39:00,917 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000618 of size 5806 bytes saved in 0 seconds.
2019-09-08 06:39:00,936 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 610
2019-09-08 06:39:00,936 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000597, cpktTxId=0000000000000000597)
2019-09-08 06:39:00,937 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000595, cpktTxId=0000000000000000595)
2019-09-08 06:39:01,029 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 618 to namenode at http://um1:50070 in 0.067 seconds
2019-09-08 06:39:01,029 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5806
2019-09-08 06:49:01,139 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-08 06:49:01,140 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=619&endTxId=621&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-08 06:49:01,146 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-08 06:49:01,146 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000619-0000000000000000621_0000000000004390717 size 0 bytes.
2019-09-08 06:49:01,146 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-08 06:49:01,146 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000619-0000000000000000621 expecting start txid #619
2019-09-08 06:49:01,146 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000619-0000000000000000621
2019-09-08 06:49:01,150 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000619-0000000000000000621 of size 120 edits # 3 loaded in 0 seconds
2019-09-08 06:49:01,151 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000621 using no compression
2019-09-08 06:49:01,156 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000621 of size 2175 bytes saved in 0 seconds.
2019-09-08 06:49:01,158 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 618
2019-09-08 06:49:01,159 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000610, cpktTxId=0000000000000000610)
2019-09-08 06:49:01,186 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 621 to namenode at http://um1:50070 in 0.01 seconds
2019-09-08 06:49:01,186 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2175
2019-09-08 06:59:01,317 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-08 06:59:01,317 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=622&endTxId=623&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-08 06:59:01,323 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-08 06:59:01,323 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000622-0000000000000000623_0000000000004990894 size 0 bytes.
2019-09-08 06:59:01,323 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-08 06:59:01,323 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000622-0000000000000000623 expecting start txid #622
2019-09-08 06:59:01,323 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000622-0000000000000000623
2019-09-08 06:59:01,324 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000622-0000000000000000623 of size 42 edits # 2 loaded in 0 seconds
2019-09-08 06:59:01,325 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000623 using no compression
2019-09-08 06:59:01,330 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000623 of size 2175 bytes saved in 0 seconds.
2019-09-08 06:59:01,333 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 621
2019-09-08 06:59:01,333 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000618, cpktTxId=0000000000000000618)
2019-09-08 06:59:01,357 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 623 to namenode at http://um1:50070 in 0.018 seconds
2019-09-08 06:59:01,362 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2175
2019-09-08 07:09:01,477 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-08 07:09:01,477 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=624&endTxId=625&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-08 07:09:01,482 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-08 07:09:01,482 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000624-0000000000000000625_0000000000005591054 size 0 bytes.
2019-09-08 07:09:01,482 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-08 07:09:01,482 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000624-0000000000000000625 expecting start txid #624
2019-09-08 07:09:01,482 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000624-0000000000000000625
2019-09-08 07:09:01,483 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000624-0000000000000000625 of size 42 edits # 2 loaded in 0 seconds
2019-09-08 07:09:01,483 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000625 using no compression
2019-09-08 07:09:01,494 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000625 of size 2175 bytes saved in 0 seconds.
2019-09-08 07:09:01,498 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 623
2019-09-08 07:09:01,498 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000621, cpktTxId=0000000000000000621)
2019-09-08 07:09:01,514 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 625 to namenode at http://um1:50070 in 0.011 seconds
2019-09-08 07:09:01,514 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2175
2019-09-08 07:19:01,647 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-08 07:19:01,647 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=626&endTxId=627&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-08 07:19:01,652 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-08 07:19:01,652 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000626-0000000000000000627_0000000000006191224 size 0 bytes.
2019-09-08 07:19:01,652 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-08 07:19:01,652 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000626-0000000000000000627 expecting start txid #626
2019-09-08 07:19:01,652 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000626-0000000000000000627
2019-09-08 07:19:01,653 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000626-0000000000000000627 of size 42 edits # 2 loaded in 0 seconds
2019-09-08 07:19:01,655 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000627 using no compression
2019-09-08 07:19:01,658 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000627 of size 2175 bytes saved in 0 seconds.
2019-09-08 07:19:01,662 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 625
2019-09-08 07:19:01,662 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000623, cpktTxId=0000000000000000623)
2019-09-08 07:19:01,686 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 627 to namenode at http://um1:50070 in 0.013 seconds
2019-09-08 07:19:01,686 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2175
2019-09-13 22:19:27,046 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.0.19
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-09-13 22:19:27,056 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-13 22:19:27,575 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-13 22:19:27,658 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-09-13 22:19:27,658 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-13 22:19:27,794 WARN org.apache.hadoop.hdfs.server.common.Util: Path /abc/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-13 22:19:27,795 WARN org.apache.hadoop.hdfs.server.common.Util: Path /abc/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-13 22:19:27,900 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /abc/snnfsi/in_use.lock acquired by nodename 17378@um2
2019-09-13 22:19:27,967 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /abc/snnedits/in_use.lock acquired by nodename 17378@um2
2019-09-13 22:19:27,983 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-09-13 22:19:27,990 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-09-13 22:19:28,041 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-09-13 22:19:28,041 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-13 22:19:28,042 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-13 22:19:28,043 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Sep 13 22:19:28
2019-09-13 22:19:28,044 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-09-13 22:19:28,045 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-13 22:19:28,046 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-09-13 22:19:28,046 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-09-13 22:19:28,089 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-09-13 22:19:28,089 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-09-13 22:19:28,089 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-09-13 22:19:28,089 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-09-13 22:19:28,089 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-09-13 22:19:28,089 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-09-13 22:19:28,089 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-09-13 22:19:28,090 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-09-13 22:19:28,090 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-09-13 22:19:28,090 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-09-13 22:19:28,090 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-09-13 22:19:28,090 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-09-13 22:19:28,092 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-09-13 22:19:28,465 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-09-13 22:19:28,465 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-13 22:19:28,465 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-09-13 22:19:28,465 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-09-13 22:19:28,465 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-09-13 22:19:28,478 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-09-13 22:19:28,478 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-13 22:19:28,478 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-09-13 22:19:28,478 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-09-13 22:19:28,479 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-13 22:19:28,479 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-09-13 22:19:28,487 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-09-13 22:19:28,488 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-09-13 22:19:28,488 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-09-13 22:19:28,488 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-09-13 22:19:28,496 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-09-13 22:19:28,527 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-13 22:19:28,529 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-09-13 22:19:28,536 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-13 22:19:28,537 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-09-13 22:19:28,537 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-13 22:19:28,537 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-13 22:19:28,555 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-09-13 22:19:28,555 INFO org.mortbay.log: jetty-6.1.26
2019-09-13 22:19:28,708 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-09-13 22:19:28,708 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-09-13 22:19:28,708 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-09-13 22:19:28,709 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-09-13 22:25:29,144 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-09-13 22:25:29,293 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=628&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-13 22:25:29,334 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-09-13 22:25:29,540 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 400.00 KB/s
2019-09-13 22:25:29,542 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000628 size 2175 bytes.
2019-09-13 22:25:29,549 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=629&endTxId=630&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-13 22:25:29,554 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-13 22:25:29,554 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000629-0000000000000000630_0000000000000658423 size 0 bytes.
2019-09-13 22:25:29,592 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 28 INodes.
2019-09-13 22:25:29,621 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-09-13 22:25:29,621 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 628 from /abc/snnfsi/current/fsimage_0000000000000000628
2019-09-13 22:25:29,621 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-09-13 22:25:29,630 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-13 22:25:29,632 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000629-0000000000000000630 expecting start txid #629
2019-09-13 22:25:29,632 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000629-0000000000000000630
2019-09-13 22:25:29,647 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000629-0000000000000000630 of size 42 edits # 2 loaded in 0 seconds
2019-09-13 22:25:29,651 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000630 using no compression
2019-09-13 22:25:29,704 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000630 of size 2175 bytes saved in 0 seconds.
2019-09-13 22:25:29,718 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 628
2019-09-13 22:25:29,718 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000627, cpktTxId=0000000000000000627)
2019-09-13 22:25:29,719 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000625, cpktTxId=0000000000000000625)
2019-09-13 22:25:29,777 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 630 to namenode at http://um1:50070 in 0.038 seconds
2019-09-13 22:25:29,777 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2175
2019-09-13 22:35:30,014 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-13 22:35:30,016 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=631&endTxId=632&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-13 22:35:30,033 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-09-13 22:35:30,033 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000631-0000000000000000632_0000000000001258890 size 0 bytes.
2019-09-13 22:35:30,034 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-13 22:35:30,039 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000631-0000000000000000632 expecting start txid #631
2019-09-13 22:35:30,039 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000631-0000000000000000632
2019-09-13 22:35:30,040 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000631-0000000000000000632 of size 42 edits # 2 loaded in 0 seconds
2019-09-13 22:35:30,043 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000632 using no compression
2019-09-13 22:35:30,062 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000632 of size 2175 bytes saved in 0 seconds.
2019-09-13 22:35:30,066 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 630
2019-09-13 22:35:30,067 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000628, cpktTxId=0000000000000000628)
2019-09-13 22:35:30,097 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 632 to namenode at http://um1:50070 in 0.01 seconds
2019-09-13 22:35:30,097 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2175
2019-09-13 22:45:30,326 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-13 22:45:30,326 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=633&endTxId=634&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-13 22:45:30,334 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-13 22:45:30,334 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000633-0000000000000000634_0000000000001859201 size 0 bytes.
2019-09-13 22:45:30,334 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-13 22:45:30,334 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000633-0000000000000000634 expecting start txid #633
2019-09-13 22:45:30,334 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000633-0000000000000000634
2019-09-13 22:45:30,335 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000633-0000000000000000634 of size 42 edits # 2 loaded in 0 seconds
2019-09-13 22:45:30,335 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000634 using no compression
2019-09-13 22:45:30,344 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000634 of size 2175 bytes saved in 0 seconds.
2019-09-13 22:45:30,347 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 632
2019-09-13 22:45:30,347 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000630, cpktTxId=0000000000000000630)
2019-09-13 22:45:30,373 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 634 to namenode at http://um1:50070 in 0.02 seconds
2019-09-13 22:45:30,377 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2175
2019-09-13 22:55:30,642 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-13 22:55:30,642 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=635&endTxId=636&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-13 22:55:30,651 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-13 22:55:30,651 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000635-0000000000000000636_0000000000002459517 size 0 bytes.
2019-09-13 22:55:30,651 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-13 22:55:30,651 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000635-0000000000000000636 expecting start txid #635
2019-09-13 22:55:30,651 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000635-0000000000000000636
2019-09-13 22:55:30,652 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000635-0000000000000000636 of size 42 edits # 2 loaded in 0 seconds
2019-09-13 22:55:30,653 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000636 using no compression
2019-09-13 22:55:30,657 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000636 of size 2175 bytes saved in 0 seconds.
2019-09-13 22:55:30,666 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 634
2019-09-13 22:55:30,666 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000632, cpktTxId=0000000000000000632)
2019-09-13 22:55:30,681 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 636 to namenode at http://um1:50070 in 0.01 seconds
2019-09-13 22:55:30,681 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2175
2019-09-13 23:05:30,870 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-13 23:05:30,870 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=637&endTxId=638&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-13 23:05:30,875 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-13 23:05:30,875 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000637-0000000000000000638_0000000000003059744 size 0 bytes.
2019-09-13 23:05:30,875 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-13 23:05:30,875 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000637-0000000000000000638 expecting start txid #637
2019-09-13 23:05:30,875 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000637-0000000000000000638
2019-09-13 23:05:30,875 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000637-0000000000000000638 of size 42 edits # 2 loaded in 0 seconds
2019-09-13 23:05:30,877 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000638 using no compression
2019-09-13 23:05:30,889 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000638 of size 2175 bytes saved in 0 seconds.
2019-09-13 23:05:30,897 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 636
2019-09-13 23:05:30,897 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000634, cpktTxId=0000000000000000634)
2019-09-13 23:05:30,912 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 638 to namenode at http://um1:50070 in 0.009 seconds
2019-09-13 23:05:30,912 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2175
2019-09-13 23:15:31,139 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-13 23:15:31,139 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=639&endTxId=640&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-13 23:15:31,150 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-09-13 23:15:31,150 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000639-0000000000000000640_0000000000003660014 size 0 bytes.
2019-09-13 23:15:31,150 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-13 23:15:31,150 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000639-0000000000000000640 expecting start txid #639
2019-09-13 23:15:31,150 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000639-0000000000000000640
2019-09-13 23:15:31,151 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000639-0000000000000000640 of size 42 edits # 2 loaded in 0 seconds
2019-09-13 23:15:31,153 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000640 using no compression
2019-09-13 23:15:31,159 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000640 of size 2175 bytes saved in 0 seconds.
2019-09-13 23:15:31,164 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 638
2019-09-13 23:15:31,164 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000636, cpktTxId=0000000000000000636)
2019-09-13 23:15:31,194 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 640 to namenode at http://um1:50070 in 0.01 seconds
2019-09-13 23:15:31,194 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2175
2019-09-13 23:25:31,392 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-13 23:25:31,392 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=641&endTxId=642&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-13 23:25:31,397 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-13 23:25:31,397 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000641-0000000000000000642_0000000000004260267 size 0 bytes.
2019-09-13 23:25:31,399 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-13 23:25:31,399 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000641-0000000000000000642 expecting start txid #641
2019-09-13 23:25:31,399 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000641-0000000000000000642
2019-09-13 23:25:31,400 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000641-0000000000000000642 of size 42 edits # 2 loaded in 0 seconds
2019-09-13 23:25:31,400 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000642 using no compression
2019-09-13 23:25:31,406 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000642 of size 2175 bytes saved in 0 seconds.
2019-09-13 23:25:31,411 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 640
2019-09-13 23:25:31,411 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000638, cpktTxId=0000000000000000638)
2019-09-13 23:25:31,430 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 642 to namenode at http://um1:50070 in 0.008 seconds
2019-09-13 23:25:31,430 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2175
2019-09-13 23:35:31,639 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-13 23:35:31,639 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=643&endTxId=644&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-13 23:35:31,660 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 0.00 KB/s
2019-09-13 23:35:31,660 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000643-0000000000000000644_0000000000004860514 size 0 bytes.
2019-09-13 23:35:31,665 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-13 23:35:31,665 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000643-0000000000000000644 expecting start txid #643
2019-09-13 23:35:31,665 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000643-0000000000000000644
2019-09-13 23:35:31,666 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000643-0000000000000000644 of size 42 edits # 2 loaded in 0 seconds
2019-09-13 23:35:31,669 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000644 using no compression
2019-09-13 23:35:31,679 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000644 of size 2175 bytes saved in 0 seconds.
2019-09-13 23:35:31,682 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 642
2019-09-13 23:35:31,682 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000640, cpktTxId=0000000000000000640)
2019-09-13 23:35:31,697 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 644 to namenode at http://um1:50070 in 0.011 seconds
2019-09-13 23:35:31,697 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2175
2019-09-13 23:45:31,968 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-13 23:45:31,968 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=645&endTxId=655&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-13 23:45:31,972 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-13 23:45:31,972 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000645-0000000000000000655_0000000000005460842 size 0 bytes.
2019-09-13 23:45:31,973 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-13 23:45:31,973 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000645-0000000000000000655 expecting start txid #645
2019-09-13 23:45:31,973 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000645-0000000000000000655
2019-09-13 23:45:31,992 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000645-0000000000000000655 of size 763 edits # 11 loaded in 0 seconds
2019-09-13 23:45:31,992 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000655 using no compression
2019-09-13 23:45:31,994 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000655 of size 2367 bytes saved in 0 seconds.
2019-09-13 23:45:31,998 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 644
2019-09-13 23:45:31,998 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000642, cpktTxId=0000000000000000642)
2019-09-13 23:45:32,009 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 655 to namenode at http://um1:50070 in 0.008 seconds
2019-09-13 23:45:32,010 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2367
2019-09-13 23:55:32,192 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-13 23:55:32,192 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=656&endTxId=665&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-13 23:55:32,198 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-13 23:55:32,199 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000656-0000000000000000665_0000000000006061067 size 0 bytes.
2019-09-13 23:55:32,199 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-13 23:55:32,199 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000656-0000000000000000665 expecting start txid #656
2019-09-13 23:55:32,199 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000656-0000000000000000665
2019-09-13 23:55:32,200 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000656-0000000000000000665 of size 890 edits # 10 loaded in 0 seconds
2019-09-13 23:55:32,201 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000665 using no compression
2019-09-13 23:55:32,203 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000665 of size 2433 bytes saved in 0 seconds.
2019-09-13 23:55:32,208 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 655
2019-09-13 23:55:32,208 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000644, cpktTxId=0000000000000000644)
2019-09-13 23:55:32,219 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 665 to namenode at http://um1:50070 in 0.008 seconds
2019-09-13 23:55:32,219 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2433
2019-09-14 00:05:32,349 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-14 00:05:32,349 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=666&endTxId=667&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-14 00:05:32,353 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-14 00:05:32,353 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000666-0000000000000000667_0000000000006661224 size 0 bytes.
2019-09-14 00:05:32,353 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-14 00:05:32,353 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000666-0000000000000000667 expecting start txid #666
2019-09-14 00:05:32,353 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000666-0000000000000000667
2019-09-14 00:05:32,354 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000666-0000000000000000667 of size 42 edits # 2 loaded in 0 seconds
2019-09-14 00:05:32,354 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000667 using no compression
2019-09-14 00:05:32,357 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000667 of size 2433 bytes saved in 0 seconds.
2019-09-14 00:05:32,359 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 665
2019-09-14 00:05:32,359 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000655, cpktTxId=0000000000000000655)
2019-09-14 00:05:32,377 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 667 to namenode at http://um1:50070 in 0.013 seconds
2019-09-14 00:05:32,377 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2433
2019-09-14 00:15:32,489 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-14 00:15:32,489 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=668&endTxId=669&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-14 00:15:32,494 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-14 00:15:32,495 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000668-0000000000000000669_0000000000007261364 size 0 bytes.
2019-09-14 00:15:32,495 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-14 00:15:32,495 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000668-0000000000000000669 expecting start txid #668
2019-09-14 00:15:32,495 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000668-0000000000000000669
2019-09-14 00:15:32,495 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000668-0000000000000000669 of size 42 edits # 2 loaded in 0 seconds
2019-09-14 00:15:32,495 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000669 using no compression
2019-09-14 00:15:32,498 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000669 of size 2433 bytes saved in 0 seconds.
2019-09-14 00:15:32,500 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 667
2019-09-14 00:15:32,500 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000665, cpktTxId=0000000000000000665)
2019-09-14 00:15:32,513 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 669 to namenode at http://um1:50070 in 0.007 seconds
2019-09-14 00:15:32,514 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2433
2019-09-14 00:25:32,679 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-14 00:25:32,679 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=670&endTxId=674&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-14 00:25:32,683 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-14 00:25:32,683 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000670-0000000000000000674_0000000000007861554 size 0 bytes.
2019-09-14 00:25:32,683 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-14 00:25:32,684 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000670-0000000000000000674 expecting start txid #670
2019-09-14 00:25:32,684 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000670-0000000000000000674
2019-09-14 00:25:32,684 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000670-0000000000000000674 of size 385 edits # 5 loaded in 0 seconds
2019-09-14 00:25:32,685 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000674 using no compression
2019-09-14 00:25:32,687 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000674 of size 2433 bytes saved in 0 seconds.
2019-09-14 00:25:32,690 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 669
2019-09-14 00:25:32,690 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000667, cpktTxId=0000000000000000667)
2019-09-14 00:25:32,700 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 674 to namenode at http://um1:50070 in 0.008 seconds
2019-09-14 00:25:32,700 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2433
2019-09-14 00:35:32,885 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-14 00:35:32,886 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=675&endTxId=678&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-14 00:35:32,892 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-14 00:35:32,892 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000675-0000000000000000678_0000000000008461760 size 0 bytes.
2019-09-14 00:35:32,892 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-14 00:35:32,892 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000675-0000000000000000678 expecting start txid #675
2019-09-14 00:35:32,892 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000675-0000000000000000678
2019-09-14 00:35:32,893 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000675-0000000000000000678 of size 286 edits # 4 loaded in 0 seconds
2019-09-14 00:35:32,894 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000678 using no compression
2019-09-14 00:35:32,897 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000678 of size 2600 bytes saved in 0 seconds.
2019-09-14 00:35:32,900 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 674
2019-09-14 00:35:32,900 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000669, cpktTxId=0000000000000000669)
2019-09-14 00:35:32,913 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 678 to namenode at http://um1:50070 in 0.01 seconds
2019-09-14 00:35:32,913 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2600
2019-09-14 00:38:33,946 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.0.18:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-14 00:38:34,947 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.0.18:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-14 00:38:35,950 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.0.18:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-14 00:38:36,951 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.0.18:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-14 00:38:37,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.0.18:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-14 00:38:38,951 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-09-14 00:38:38,954 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.0.19
************************************************************/
2019-09-14 00:39:50,736 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.0.19
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-09-14 00:39:50,747 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-14 00:39:51,250 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-14 00:39:51,354 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-09-14 00:39:51,354 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-14 00:39:51,438 WARN org.apache.hadoop.hdfs.server.common.Util: Path /abc/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-14 00:39:51,439 WARN org.apache.hadoop.hdfs.server.common.Util: Path /abc/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-14 00:39:51,480 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /abc/snnfsi/in_use.lock acquired by nodename 20477@um2
2019-09-14 00:39:51,535 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /abc/snnedits/in_use.lock acquired by nodename 20477@um2
2019-09-14 00:39:51,546 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-09-14 00:39:51,551 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-09-14 00:39:51,590 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-09-14 00:39:51,591 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-14 00:39:51,592 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-14 00:39:51,593 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Sep 14 00:39:51
2019-09-14 00:39:51,594 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-09-14 00:39:51,594 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-14 00:39:51,595 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-09-14 00:39:51,595 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-09-14 00:39:51,604 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-09-14 00:39:51,604 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-09-14 00:39:51,604 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-09-14 00:39:51,604 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-09-14 00:39:51,604 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-09-14 00:39:51,604 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-09-14 00:39:51,604 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-09-14 00:39:51,605 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-09-14 00:39:51,605 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-09-14 00:39:51,605 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-09-14 00:39:51,605 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-09-14 00:39:51,605 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-09-14 00:39:51,607 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-09-14 00:39:51,889 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-09-14 00:39:51,889 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-14 00:39:51,889 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-09-14 00:39:51,889 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-09-14 00:39:51,890 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-09-14 00:39:51,895 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-09-14 00:39:51,895 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-14 00:39:51,895 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-09-14 00:39:51,895 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-09-14 00:39:51,896 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-14 00:39:51,896 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-09-14 00:39:51,896 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-09-14 00:39:51,897 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-09-14 00:39:51,897 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-09-14 00:39:51,898 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-09-14 00:39:51,904 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-09-14 00:39:51,940 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-14 00:39:51,943 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-09-14 00:39:51,952 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-14 00:39:51,954 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-09-14 00:39:51,955 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-14 00:39:51,956 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-14 00:39:51,968 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-09-14 00:39:51,968 INFO org.mortbay.log: jetty-6.1.26
2019-09-14 00:39:52,138 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-09-14 00:39:52,138 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-09-14 00:39:52,138 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-09-14 00:39:52,138 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-09-14 00:40:52,348 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-09-14 00:40:52,451 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=678&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-14 00:40:52,487 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-09-14 00:40:52,622 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 500.00 KB/s
2019-09-14 00:40:52,623 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000678 size 2600 bytes.
2019-09-14 00:40:52,629 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=679&endTxId=679&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-14 00:40:52,652 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 56888.89 KB/s
2019-09-14 00:40:52,652 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000679-0000000000000000679_0000000000008781502 size 0 bytes.
2019-09-14 00:40:52,653 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=680&endTxId=681&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-14 00:40:52,662 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-14 00:40:52,662 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000680-0000000000000000681_0000000000008781527 size 0 bytes.
2019-09-14 00:40:52,690 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 34 INodes.
2019-09-14 00:40:52,713 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-09-14 00:40:52,713 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 678 from /abc/snnfsi/current/fsimage_0000000000000000678
2019-09-14 00:40:52,713 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-09-14 00:40:52,716 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2019-09-14 00:40:52,719 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000679-0000000000000000679 expecting start txid #679
2019-09-14 00:40:52,719 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000679-0000000000000000679
2019-09-14 00:40:52,732 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000679-0000000000000000679 of size 1048576 edits # 1 loaded in 0 seconds
2019-09-14 00:40:52,732 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000680-0000000000000000681 expecting start txid #680
2019-09-14 00:40:52,732 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000680-0000000000000000681
2019-09-14 00:40:52,733 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000680-0000000000000000681 of size 42 edits # 2 loaded in 0 seconds
2019-09-14 00:40:52,740 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000681 using no compression
2019-09-14 00:40:52,779 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000681 of size 2600 bytes saved in 0 seconds.
2019-09-14 00:40:52,785 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 678
2019-09-14 00:40:52,785 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000674, cpktTxId=0000000000000000674)
2019-09-14 00:40:52,820 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 681 to namenode at http://um1:50070 in 0.023 seconds
2019-09-14 00:40:52,820 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2600
2019-09-14 00:50:52,955 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-14 00:50:52,956 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=682&endTxId=684&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-14 00:50:52,960 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-14 00:50:52,960 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000682-0000000000000000684_0000000000009381830 size 0 bytes.
2019-09-14 00:50:52,960 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-14 00:50:52,960 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000682-0000000000000000684 expecting start txid #682
2019-09-14 00:50:52,960 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000682-0000000000000000684
2019-09-14 00:50:52,970 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000682-0000000000000000684 of size 141 edits # 3 loaded in 0 seconds
2019-09-14 00:50:52,972 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000684 using no compression
2019-09-14 00:50:52,979 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000684 of size 2433 bytes saved in 0 seconds.
2019-09-14 00:50:52,982 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 681
2019-09-14 00:50:52,982 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000678, cpktTxId=0000000000000000678)
2019-09-14 00:50:53,011 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 684 to namenode at http://um1:50070 in 0.016 seconds
2019-09-14 00:50:53,012 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2433
2019-09-14 01:00:53,168 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-14 01:00:53,169 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=685&endTxId=712&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-14 01:00:53,173 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1500.00 KB/s
2019-09-14 01:00:53,173 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000685-0000000000000000712_0000000000009982043 size 0 bytes.
2019-09-14 01:00:53,173 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-14 01:00:53,173 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000685-0000000000000000712 expecting start txid #685
2019-09-14 01:00:53,173 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000685-0000000000000000712
2019-09-14 01:00:53,188 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000685-0000000000000000712 of size 3131 edits # 28 loaded in 0 seconds
2019-09-14 01:00:53,190 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000712 using no compression
2019-09-14 01:00:53,195 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000712 of size 2805 bytes saved in 0 seconds.
2019-09-14 01:00:53,199 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 684
2019-09-14 01:00:53,199 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000681, cpktTxId=0000000000000000681)
2019-09-14 01:00:53,214 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 712 to namenode at http://um1:50070 in 0.01 seconds
2019-09-14 01:00:53,214 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2805
2019-09-14 01:10:53,451 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-14 01:10:53,451 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=713&endTxId=715&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-14 01:10:53,457 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-14 01:10:53,458 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000713-0000000000000000715_0000000000010582326 size 0 bytes.
2019-09-14 01:10:53,458 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-14 01:10:53,458 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000713-0000000000000000715 expecting start txid #713
2019-09-14 01:10:53,458 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000713-0000000000000000715
2019-09-14 01:10:53,459 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000713-0000000000000000715 of size 141 edits # 3 loaded in 0 seconds
2019-09-14 01:10:53,459 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000715 using no compression
2019-09-14 01:10:53,463 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000715 of size 2638 bytes saved in 0 seconds.
2019-09-14 01:10:53,467 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 712
2019-09-14 01:10:53,468 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000684, cpktTxId=0000000000000000684)
2019-09-14 01:10:53,484 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 715 to namenode at http://um1:50070 in 0.01 seconds
2019-09-14 01:10:53,484 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2638
2019-09-14 01:20:53,622 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-14 01:20:53,622 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=716&endTxId=717&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-14 01:20:53,627 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-14 01:20:53,627 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000716-0000000000000000717_0000000000011182497 size 0 bytes.
2019-09-14 01:20:53,627 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-14 01:20:53,627 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000716-0000000000000000717 expecting start txid #716
2019-09-14 01:20:53,627 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000716-0000000000000000717
2019-09-14 01:20:53,627 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000716-0000000000000000717 of size 42 edits # 2 loaded in 0 seconds
2019-09-14 01:20:53,628 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000717 using no compression
2019-09-14 01:20:53,634 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000717 of size 2638 bytes saved in 0 seconds.
2019-09-14 01:20:53,637 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 715
2019-09-14 01:20:53,637 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000712, cpktTxId=0000000000000000712)
2019-09-14 01:20:53,656 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 717 to namenode at http://um1:50070 in 0.014 seconds
2019-09-14 01:20:53,656 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2638
2019-09-14 05:47:19,701 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.0.19
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-09-14 05:47:19,714 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-14 05:47:20,309 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-14 05:47:20,395 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-09-14 05:47:20,395 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-14 05:47:20,527 WARN org.apache.hadoop.hdfs.server.common.Util: Path /abc/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-14 05:47:20,527 WARN org.apache.hadoop.hdfs.server.common.Util: Path /abc/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-14 05:47:20,621 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /abc/snnfsi/in_use.lock acquired by nodename 2427@um2
2019-09-14 05:47:20,688 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /abc/snnedits/in_use.lock acquired by nodename 2427@um2
2019-09-14 05:47:20,710 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-09-14 05:47:20,719 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-09-14 05:47:20,762 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-09-14 05:47:20,762 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-14 05:47:20,764 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-14 05:47:20,765 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Sep 14 05:47:20
2019-09-14 05:47:20,772 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-09-14 05:47:20,772 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-14 05:47:20,774 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-09-14 05:47:20,774 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-09-14 05:47:20,802 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-09-14 05:47:20,803 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-09-14 05:47:20,803 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-09-14 05:47:20,803 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-09-14 05:47:20,803 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-09-14 05:47:20,803 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-09-14 05:47:20,803 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-09-14 05:47:20,803 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-09-14 05:47:20,808 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-09-14 05:47:20,808 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-09-14 05:47:20,808 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-09-14 05:47:20,809 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-09-14 05:47:20,811 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-09-14 05:47:21,234 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-09-14 05:47:21,234 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-14 05:47:21,235 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-09-14 05:47:21,235 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-09-14 05:47:21,235 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-09-14 05:47:21,242 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-09-14 05:47:21,242 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-14 05:47:21,242 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-09-14 05:47:21,242 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-09-14 05:47:21,243 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-14 05:47:21,243 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-09-14 05:47:21,250 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-09-14 05:47:21,252 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-09-14 05:47:21,252 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-09-14 05:47:21,253 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-09-14 05:47:21,263 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-09-14 05:47:21,304 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-14 05:47:21,307 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-09-14 05:47:21,316 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-14 05:47:21,318 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-09-14 05:47:21,318 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-14 05:47:21,318 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-14 05:47:21,330 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-09-14 05:47:21,330 INFO org.mortbay.log: jetty-6.1.26
2019-09-14 05:47:21,524 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-09-14 05:47:21,524 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-09-14 05:47:21,524 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-09-14 05:47:21,524 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-09-14 05:54:21,796 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-09-14 05:54:21,998 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=718&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-14 05:54:22,053 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-09-14 05:54:22,284 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 285.71 KB/s
2019-09-14 05:54:22,286 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000718 size 2638 bytes.
2019-09-14 05:54:22,296 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=719&endTxId=720&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-14 05:54:22,307 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-14 05:54:22,307 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000719-0000000000000000720_0000000000000633155 size 0 bytes.
2019-09-14 05:54:22,341 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 35 INodes.
2019-09-14 05:54:22,370 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-09-14 05:54:22,370 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 718 from /abc/snnfsi/current/fsimage_0000000000000000718
2019-09-14 05:54:22,370 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-09-14 05:54:22,375 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-14 05:54:22,383 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000719-0000000000000000720 expecting start txid #719
2019-09-14 05:54:22,383 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000719-0000000000000000720
2019-09-14 05:54:22,402 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000719-0000000000000000720 of size 42 edits # 2 loaded in 0 seconds
2019-09-14 05:54:22,407 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000720 using no compression
2019-09-14 05:54:22,472 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000720 of size 2638 bytes saved in 0 seconds.
2019-09-14 05:54:22,488 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 718
2019-09-14 05:54:22,488 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000717, cpktTxId=0000000000000000717)
2019-09-14 05:54:22,489 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000715, cpktTxId=0000000000000000715)
2019-09-14 05:54:22,549 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 720 to namenode at http://um1:50070 in 0.038 seconds
2019-09-14 05:54:22,550 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2638
2019-09-14 06:04:22,670 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-14 06:04:22,670 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=721&endTxId=740&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-14 06:04:22,682 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 250.00 KB/s
2019-09-14 06:04:22,682 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000721-0000000000000000740_0000000000001233529 size 0 bytes.
2019-09-14 06:04:22,683 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-14 06:04:22,683 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000721-0000000000000000740 expecting start txid #721
2019-09-14 06:04:22,683 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000721-0000000000000000740
2019-09-14 06:04:22,721 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000721-0000000000000000740 of size 2315 edits # 20 loaded in 0 seconds
2019-09-14 06:04:22,725 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000740 using no compression
2019-09-14 06:04:22,734 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000740 of size 2770 bytes saved in 0 seconds.
2019-09-14 06:04:22,736 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 720
2019-09-14 06:04:22,736 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000718, cpktTxId=0000000000000000718)
2019-09-14 06:04:22,766 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 740 to namenode at http://um1:50070 in 0.012 seconds
2019-09-14 06:04:22,766 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2770
2019-09-14 06:14:22,869 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-14 06:14:22,869 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=741&endTxId=742&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-14 06:14:22,885 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-14 06:14:22,886 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000741-0000000000000000742_0000000000001833728 size 0 bytes.
2019-09-14 06:14:22,887 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-14 06:14:22,887 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000741-0000000000000000742 expecting start txid #741
2019-09-14 06:14:22,887 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000741-0000000000000000742
2019-09-14 06:14:22,888 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000741-0000000000000000742 of size 42 edits # 2 loaded in 0 seconds
2019-09-14 06:14:22,893 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000742 using no compression
2019-09-14 06:14:22,904 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000742 of size 2770 bytes saved in 0 seconds.
2019-09-14 06:14:22,916 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 740
2019-09-14 06:14:22,917 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000720, cpktTxId=0000000000000000720)
2019-09-14 06:14:22,960 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 742 to namenode at http://um1:50070 in 0.013 seconds
2019-09-14 06:14:22,960 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2770
2019-09-14 06:24:23,088 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-14 06:24:23,088 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=743&endTxId=762&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-14 06:24:23,094 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1000.00 KB/s
2019-09-14 06:24:23,094 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000743-0000000000000000762_0000000000002433947 size 0 bytes.
2019-09-14 06:24:23,094 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-14 06:24:23,094 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000743-0000000000000000762 expecting start txid #743
2019-09-14 06:24:23,094 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000743-0000000000000000762
2019-09-14 06:24:23,098 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000743-0000000000000000762 of size 2319 edits # 20 loaded in 0 seconds
2019-09-14 06:24:23,099 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000762 using no compression
2019-09-14 06:24:23,104 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000762 of size 2903 bytes saved in 0 seconds.
2019-09-14 06:24:23,106 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 742
2019-09-14 06:24:23,106 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000740, cpktTxId=0000000000000000740)
2019-09-14 06:24:23,126 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 762 to namenode at http://um1:50070 in 0.014 seconds
2019-09-14 06:24:23,126 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2903
2019-09-14 06:34:23,209 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-14 06:34:23,209 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=763&endTxId=764&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-14 06:34:23,213 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-14 06:34:23,213 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000763-0000000000000000764_0000000000003034068 size 0 bytes.
2019-09-14 06:34:23,214 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-14 06:34:23,214 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000763-0000000000000000764 expecting start txid #763
2019-09-14 06:34:23,214 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000763-0000000000000000764
2019-09-14 06:34:23,214 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000763-0000000000000000764 of size 42 edits # 2 loaded in 0 seconds
2019-09-14 06:34:23,216 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000764 using no compression
2019-09-14 06:34:23,220 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000764 of size 2903 bytes saved in 0 seconds.
2019-09-14 06:34:23,231 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 762
2019-09-14 06:34:23,231 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000742, cpktTxId=0000000000000000742)
2019-09-14 06:34:23,258 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 764 to namenode at http://um1:50070 in 0.015 seconds
2019-09-14 06:34:23,258 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2903
2019-09-14 06:44:23,380 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-14 06:44:23,381 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=765&endTxId=766&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-14 06:44:23,386 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-14 06:44:23,386 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000765-0000000000000000766_0000000000003634240 size 0 bytes.
2019-09-14 06:44:23,386 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-14 06:44:23,386 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000765-0000000000000000766 expecting start txid #765
2019-09-14 06:44:23,386 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000765-0000000000000000766
2019-09-14 06:44:23,386 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000765-0000000000000000766 of size 42 edits # 2 loaded in 0 seconds
2019-09-14 06:44:23,387 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000766 using no compression
2019-09-14 06:44:23,391 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000766 of size 2903 bytes saved in 0 seconds.
2019-09-14 06:44:23,394 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 764
2019-09-14 06:44:23,394 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000762, cpktTxId=0000000000000000762)
2019-09-14 06:44:23,418 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 766 to namenode at http://um1:50070 in 0.013 seconds
2019-09-14 06:44:23,418 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2903
2019-09-14 06:54:23,529 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-14 06:54:23,529 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=767&endTxId=768&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-14 06:54:23,534 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-14 06:54:23,534 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000767-0000000000000000768_0000000000004234388 size 0 bytes.
2019-09-14 06:54:23,534 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-14 06:54:23,534 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000767-0000000000000000768 expecting start txid #767
2019-09-14 06:54:23,534 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000767-0000000000000000768
2019-09-14 06:54:23,534 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000767-0000000000000000768 of size 42 edits # 2 loaded in 0 seconds
2019-09-14 06:54:23,535 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000768 using no compression
2019-09-14 06:54:23,539 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000768 of size 2903 bytes saved in 0 seconds.
2019-09-14 06:54:23,542 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 766
2019-09-14 06:54:23,543 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000764, cpktTxId=0000000000000000764)
2019-09-14 06:54:23,559 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 768 to namenode at http://um1:50070 in 0.009 seconds
2019-09-14 06:54:23,559 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2903
2019-09-14 07:04:23,692 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-14 07:04:23,692 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=769&endTxId=770&storageInfo=-60:322677011:0:CID-403a0251-1604-44a0-b205-ccebae382a38
2019-09-14 07:04:23,696 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-14 07:04:23,696 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000769-0000000000000000770_0000000000004834551 size 0 bytes.
2019-09-14 07:04:23,696 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-14 07:04:23,696 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /abc/snnedits/current/edits_0000000000000000769-0000000000000000770 expecting start txid #769
2019-09-14 07:04:23,697 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /abc/snnedits/current/edits_0000000000000000769-0000000000000000770
2019-09-14 07:04:23,697 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /abc/snnedits/current/edits_0000000000000000769-0000000000000000770 of size 42 edits # 2 loaded in 0 seconds
2019-09-14 07:04:23,698 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000770 using no compression
2019-09-14 07:04:23,702 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /abc/snnfsi/current/fsimage.ckpt_0000000000000000770 of size 2903 bytes saved in 0 seconds.
2019-09-14 07:04:23,706 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 768
2019-09-14 07:04:23,706 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/abc/snnfsi/current/fsimage_0000000000000000766, cpktTxId=0000000000000000766)
2019-09-14 07:04:23,721 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 770 to namenode at http://um1:50070 in 0.01 seconds
2019-09-14 07:04:23,722 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2903
2019-09-22 17:00:43,118 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.0.19
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-09-22 17:00:43,137 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-22 17:00:43,760 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-22 17:00:43,848 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-09-22 17:00:43,848 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-22 17:00:43,988 WARN org.apache.hadoop.hdfs.server.common.Util: Path /org/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-22 17:00:43,989 WARN org.apache.hadoop.hdfs.server.common.Util: Path /org/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-22 17:00:44,069 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /org/snnfsi/in_use.lock acquired by nodename 2562@um2
2019-09-22 17:00:44,072 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /org/snnedits/in_use.lock acquired by nodename 2562@um2
2019-09-22 17:00:44,074 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-09-22 17:00:44,082 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-09-22 17:00:44,124 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-09-22 17:00:44,124 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-22 17:00:44,125 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-22 17:00:44,127 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Sep 22 17:00:44
2019-09-22 17:00:44,128 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-09-22 17:00:44,128 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-22 17:00:44,130 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-09-22 17:00:44,130 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-09-22 17:00:44,164 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-09-22 17:00:44,164 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-09-22 17:00:44,164 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-09-22 17:00:44,164 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-09-22 17:00:44,164 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-09-22 17:00:44,164 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-09-22 17:00:44,164 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-09-22 17:00:44,164 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-09-22 17:00:44,165 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-09-22 17:00:44,165 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-09-22 17:00:44,165 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-09-22 17:00:44,165 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-09-22 17:00:44,166 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-09-22 17:00:44,535 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-09-22 17:00:44,535 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-22 17:00:44,536 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-09-22 17:00:44,536 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-09-22 17:00:44,593 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-09-22 17:00:44,601 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-09-22 17:00:44,601 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-22 17:00:44,601 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-09-22 17:00:44,601 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-09-22 17:00:44,602 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-22 17:00:44,602 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-09-22 17:00:44,602 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-09-22 17:00:44,603 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-09-22 17:00:44,603 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-09-22 17:00:44,603 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-09-22 17:00:44,622 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-09-22 17:00:44,674 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-22 17:00:44,678 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-09-22 17:00:44,686 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-22 17:00:44,690 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-09-22 17:00:44,690 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-22 17:00:44,690 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-22 17:00:44,707 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-09-22 17:00:44,707 INFO org.mortbay.log: jetty-6.1.26
2019-09-22 17:00:44,907 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-09-22 17:00:44,907 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-09-22 17:00:44,908 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-09-22 17:00:44,908 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-09-22 17:01:45,184 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-09-22 17:01:45,342 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=0&storageInfo=-60:1637254800:0:CID-8a4da663-132b-4526-a234-04cd4d0a14a2
2019-09-22 17:01:45,403 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-09-22 17:01:45,692 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 0.00 KB/s
2019-09-22 17:01:45,693 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 320 bytes.
2019-09-22 17:01:45,706 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1&endTxId=2&storageInfo=-60:1637254800:0:CID-8a4da663-132b-4526-a234-04cd4d0a14a2
2019-09-22 17:01:45,712 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-22 17:01:45,712 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000002_0000000000002767521 size 0 bytes.
2019-09-22 17:01:45,751 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-09-22 17:01:45,778 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-09-22 17:01:45,778 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /org/snnfsi/current/fsimage_0000000000000000000
2019-09-22 17:01:45,778 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-09-22 17:01:45,781 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-22 17:01:45,794 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /org/snnedits/current/edits_0000000000000000001-0000000000000000002 expecting start txid #1
2019-09-22 17:01:45,794 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /org/snnedits/current/edits_0000000000000000001-0000000000000000002
2019-09-22 17:01:45,822 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /org/snnedits/current/edits_0000000000000000001-0000000000000000002 of size 42 edits # 2 loaded in 0 seconds
2019-09-22 17:01:45,843 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /org/snnfsi/current/fsimage.ckpt_0000000000000000002 using no compression
2019-09-22 17:01:45,890 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /org/snnfsi/current/fsimage.ckpt_0000000000000000002 of size 320 bytes saved in 0 seconds.
2019-09-22 17:01:45,903 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /org/snnfsi
2019-09-22 17:01:45,903 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /org/snnedits
2019-09-22 17:01:45,955 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2 to namenode at http://um1:50070 in 0.041 seconds
2019-09-22 17:01:45,956 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 320
2019-09-22 17:08:06,022 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.0.242:9000. Already tried 0 time(s); maxRetries=45
2019-09-22 17:08:09,746 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.0.242:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-22 17:08:12,818 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.0.242:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-22 17:08:15,889 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.0.242:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-22 17:08:18,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.0.242:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-22 17:08:22,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.0.242:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-22 17:08:25,106 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.0.242:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-22 17:08:28,195 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.0.242:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-22 17:08:31,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.0.242:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-22 17:08:34,321 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.0.242:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-22 17:08:37,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.0.242:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-22 17:08:39,468 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.0.19 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 18 more
2019-09-22 17:08:39,709 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-09-22 17:08:39,712 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.0.19
************************************************************/
2019-09-28 17:58:36,644 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.182.5
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-09-28 17:58:36,660 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-28 17:58:37,602 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-28 17:58:37,773 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-09-28 17:58:37,773 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-28 17:58:37,949 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-28 17:58:37,949 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-28 17:58:38,091 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 5305@um2
2019-09-28 17:58:38,096 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 5305@um2
2019-09-28 17:58:38,099 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-09-28 17:58:38,108 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-09-28 17:58:38,168 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-09-28 17:58:38,168 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-28 17:58:38,169 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-28 17:58:38,171 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Sep 28 17:58:38
2019-09-28 17:58:38,174 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-09-28 17:58:38,174 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-28 17:58:38,177 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-09-28 17:58:38,177 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-09-28 17:58:38,242 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-09-28 17:58:38,242 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-09-28 17:58:38,242 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-09-28 17:58:38,242 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-09-28 17:58:38,243 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-09-28 17:58:38,243 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-09-28 17:58:38,243 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-09-28 17:58:38,243 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-09-28 17:58:38,246 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-09-28 17:58:38,246 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-09-28 17:58:38,246 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-09-28 17:58:38,246 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-09-28 17:58:38,255 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-09-28 17:58:38,723 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-09-28 17:58:38,723 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-28 17:58:38,724 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-09-28 17:58:38,724 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-09-28 17:58:38,871 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-09-28 17:58:38,880 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-09-28 17:58:38,880 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-28 17:58:38,880 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-09-28 17:58:38,880 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-09-28 17:58:38,881 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-28 17:58:38,882 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-09-28 17:58:38,882 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-09-28 17:58:38,884 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-09-28 17:58:38,884 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-09-28 17:58:38,884 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-09-28 17:58:38,896 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-09-28 17:58:38,958 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-28 17:58:38,961 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-09-28 17:58:38,969 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 17:58:38,971 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-09-28 17:58:38,971 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 17:58:38,971 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 17:58:38,986 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-09-28 17:58:38,986 INFO org.mortbay.log: jetty-6.1.26
2019-09-28 17:58:39,213 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-09-28 17:58:39,213 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-09-28 17:58:39,213 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-09-28 17:58:39,214 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-09-28 17:59:40,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 17:59:41,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 17:59:42,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 17:59:43,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 17:59:44,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 17:59:45,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 17:59:46,271 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 17:59:47,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 17:59:48,276 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 17:59:49,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 17:59:49,286 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From um2/192.168.182.5 to um1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 18 more
2019-09-28 18:00:50,295 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 18:00:51,295 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 18:00:52,297 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 18:00:53,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 18:00:54,299 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 18:00:55,301 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 18:00:56,306 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 18:00:57,307 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 18:00:58,318 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 18:00:59,319 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 18:00:59,320 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From um2/192.168.182.5 to um1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 18 more
2019-09-28 18:02:00,328 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 18:02:01,331 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 18:02:02,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 18:02:03,334 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 18:02:04,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 18:02:05,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 18:02:06,343 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 18:02:07,345 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 18:02:08,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 18:02:09,347 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 18:02:09,348 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From um2/192.168.182.5 to um1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 18 more
2019-09-28 18:02:49,508 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-09-28 18:02:49,511 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.182.5
************************************************************/
2019-09-28 18:05:34,914 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.182.5
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-09-28 18:05:34,924 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-28 18:05:35,510 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-28 18:05:35,601 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-09-28 18:05:35,601 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-28 18:05:35,711 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-28 18:05:35,712 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-28 18:05:35,761 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 6544@um2
2019-09-28 18:05:35,765 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 6544@um2
2019-09-28 18:05:35,766 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-09-28 18:05:35,771 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-09-28 18:05:35,805 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-09-28 18:05:35,805 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-28 18:05:35,806 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-28 18:05:35,807 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Sep 28 18:05:35
2019-09-28 18:05:35,809 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-09-28 18:05:35,809 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-28 18:05:35,810 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-09-28 18:05:35,810 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-09-28 18:05:35,820 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-09-28 18:05:35,821 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-09-28 18:05:35,821 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-09-28 18:05:35,821 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-09-28 18:05:35,821 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-09-28 18:05:35,821 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-09-28 18:05:35,821 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-09-28 18:05:35,821 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-09-28 18:05:35,821 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-09-28 18:05:35,821 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-09-28 18:05:35,822 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-09-28 18:05:35,822 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-09-28 18:05:35,824 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-09-28 18:05:36,172 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-09-28 18:05:36,172 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-28 18:05:36,173 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-09-28 18:05:36,173 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-09-28 18:05:36,186 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-09-28 18:05:36,192 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-09-28 18:05:36,192 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-28 18:05:36,192 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-09-28 18:05:36,193 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-09-28 18:05:36,194 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-28 18:05:36,194 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-09-28 18:05:36,194 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-09-28 18:05:36,195 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-09-28 18:05:36,196 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-09-28 18:05:36,196 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-09-28 18:05:36,205 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-09-28 18:05:36,247 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-28 18:05:36,250 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-09-28 18:05:36,259 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 18:05:36,261 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-09-28 18:05:36,261 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 18:05:36,261 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 18:05:36,275 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-09-28 18:05:36,275 INFO org.mortbay.log: jetty-6.1.26
2019-09-28 18:05:36,483 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-09-28 18:05:36,483 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-09-28 18:05:36,483 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-09-28 18:05:36,484 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-09-28 18:06:36,698 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-09-28 18:06:36,920 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=0&storageInfo=-60:991233186:0:CID-754a4d87-2b19-4139-88e6-04e15df49eae
2019-09-28 18:06:36,990 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-09-28 18:06:37,312 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 0.00 KB/s
2019-09-28 18:06:37,312 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 320 bytes.
2019-09-28 18:06:37,319 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1&endTxId=2&storageInfo=-60:991233186:0:CID-754a4d87-2b19-4139-88e6-04e15df49eae
2019-09-28 18:06:37,333 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 18:06:37,333 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000002_0000000000002810496 size 0 bytes.
2019-09-28 18:06:37,384 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-09-28 18:06:37,411 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-09-28 18:06:37,411 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /orgz/snnfsi/current/fsimage_0000000000000000000
2019-09-28 18:06:37,411 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-09-28 18:06:37,416 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-28 18:06:37,420 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000001-0000000000000000002 expecting start txid #1
2019-09-28 18:06:37,420 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000001-0000000000000000002
2019-09-28 18:06:37,442 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000001-0000000000000000002 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 18:06:37,447 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000002 using no compression
2019-09-28 18:06:37,495 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000002 of size 320 bytes saved in 0 seconds.
2019-09-28 18:06:37,508 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /orgz/snnfsi
2019-09-28 18:06:37,508 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /orgz/snnedits
2019-09-28 18:06:37,562 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2 to namenode at http://um1:50070 in 0.045 seconds
2019-09-28 18:06:37,562 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 320
2019-09-28 18:10:07,851 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-09-28 18:10:07,856 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.182.5
************************************************************/
2019-09-28 18:11:17,145 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.182.5
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-09-28 18:11:17,158 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-28 18:11:17,799 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-28 18:11:17,925 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-09-28 18:11:17,925 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-28 18:11:18,042 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-28 18:11:18,043 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-28 18:11:18,094 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 7744@um2
2019-09-28 18:11:18,168 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 7744@um2
2019-09-28 18:11:18,171 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-09-28 18:11:18,176 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-09-28 18:11:18,218 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-09-28 18:11:18,218 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-28 18:11:18,219 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-28 18:11:18,221 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Sep 28 18:11:18
2019-09-28 18:11:18,224 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-09-28 18:11:18,224 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-28 18:11:18,226 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-09-28 18:11:18,226 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-09-28 18:11:18,242 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-09-28 18:11:18,243 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-09-28 18:11:18,244 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-09-28 18:11:18,244 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-09-28 18:11:18,244 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-09-28 18:11:18,244 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-09-28 18:11:18,244 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-09-28 18:11:18,244 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-09-28 18:11:18,245 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-09-28 18:11:18,245 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-09-28 18:11:18,246 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-09-28 18:11:18,246 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-09-28 18:11:18,249 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-09-28 18:11:18,683 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-09-28 18:11:18,683 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-28 18:11:18,683 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-09-28 18:11:18,683 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-09-28 18:11:18,684 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-09-28 18:11:18,693 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-09-28 18:11:18,694 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-28 18:11:18,694 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-09-28 18:11:18,694 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-09-28 18:11:18,696 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-28 18:11:18,696 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-09-28 18:11:18,699 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-09-28 18:11:18,702 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-09-28 18:11:18,702 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-09-28 18:11:18,702 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-09-28 18:11:18,712 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-09-28 18:11:18,770 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-28 18:11:18,775 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-09-28 18:11:18,788 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 18:11:18,791 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-09-28 18:11:18,793 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 18:11:18,793 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 18:11:18,814 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-09-28 18:11:18,814 INFO org.mortbay.log: jetty-6.1.26
2019-09-28 18:11:19,057 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-09-28 18:11:19,058 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-09-28 18:11:19,058 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-09-28 18:11:19,058 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-09-28 18:12:19,297 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-09-28 18:12:19,299 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.182.5
************************************************************/
2019-09-28 18:42:24,322 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.182.5
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-09-28 18:42:24,333 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-28 18:42:24,916 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-28 18:42:24,992 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-09-28 18:42:24,992 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-28 18:42:25,099 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-28 18:42:25,099 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-28 18:42:25,143 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 8476@um2
2019-09-28 18:42:25,187 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 8476@um2
2019-09-28 18:42:25,190 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-09-28 18:42:25,195 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-09-28 18:42:25,231 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-09-28 18:42:25,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-28 18:42:25,233 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-28 18:42:25,235 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Sep 28 18:42:25
2019-09-28 18:42:25,236 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-09-28 18:42:25,236 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-28 18:42:25,238 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-09-28 18:42:25,238 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-09-28 18:42:25,251 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-09-28 18:42:25,252 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-09-28 18:42:25,252 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-09-28 18:42:25,252 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-09-28 18:42:25,252 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-09-28 18:42:25,252 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-09-28 18:42:25,252 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-09-28 18:42:25,252 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-09-28 18:42:25,253 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-09-28 18:42:25,253 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-09-28 18:42:25,253 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-09-28 18:42:25,253 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-09-28 18:42:25,255 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-09-28 18:42:25,580 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-09-28 18:42:25,580 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-28 18:42:25,580 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-09-28 18:42:25,580 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-09-28 18:42:25,581 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-09-28 18:42:25,586 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-09-28 18:42:25,586 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-28 18:42:25,587 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-09-28 18:42:25,587 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-09-28 18:42:25,588 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-28 18:42:25,588 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-09-28 18:42:25,588 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-09-28 18:42:25,589 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-09-28 18:42:25,590 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-09-28 18:42:25,590 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-09-28 18:42:25,597 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-09-28 18:42:25,665 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-28 18:42:25,668 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-09-28 18:42:25,680 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 18:42:25,682 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-09-28 18:42:25,683 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 18:42:25,683 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 18:42:25,696 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-09-28 18:42:25,696 INFO org.mortbay.log: jetty-6.1.26
2019-09-28 18:42:25,877 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-09-28 18:42:25,877 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-09-28 18:42:25,877 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-09-28 18:42:25,877 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-09-28 18:43:26,076 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 18:44:26,117 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 18:45:26,153 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 18:46:26,258 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 18:47:26,302 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 18:48:26,336 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 18:49:26,366 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 18:50:26,410 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 18:51:26,442 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 18:52:26,483 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 18:53:26,512 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 18:54:26,539 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 18:55:26,568 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 18:56:26,635 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 18:57:26,665 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 18:58:26,729 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 18:59:26,754 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:00:26,787 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:01:26,832 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:02:26,860 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:03:26,884 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:04:26,973 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:05:27,025 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:06:27,053 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:07:27,077 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:08:27,112 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:09:27,139 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:10:27,165 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:11:27,263 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:12:27,292 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:13:27,431 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:14:27,460 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:15:27,522 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:16:27,553 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:17:27,645 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:18:27,669 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:19:27,702 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:20:27,732 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:21:27,761 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:22:27,793 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:23:27,821 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:24:27,902 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:25:27,933 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:26:27,961 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:27:27,991 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:28:28,019 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:29:28,099 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:30:28,126 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:31:28,158 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:32:28,190 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:33:28,216 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:34:28,241 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:35:28,265 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:36:28,344 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:37:28,370 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:38:28,400 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:39:28,433 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:40:28,453 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:41:28,483 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -60 namespaceID = 811552738 cTime = 0 ; clusterId = CID-52b20ea5-265a-4894-9ae4-b6de307aaed4 ; blockpoolId = BP-278062902-192.168.182.3-1569688905540.
Expecting respectively: -60; 991233186; 0; CID-754a4d87-2b19-4139-88e6-04e15df49eae; BP-1953541993-192.168.182.3-1569686638162.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:531)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:395)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
2019-09-28 19:42:15,979 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-09-28 19:42:15,981 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.182.5
************************************************************/
2019-09-28 19:42:28,937 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.182.5
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-09-28 19:42:28,964 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-28 19:42:29,589 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-28 19:42:29,666 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-09-28 19:42:29,666 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-28 19:42:29,791 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-28 19:42:29,791 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-28 19:42:29,842 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 9902@um2
2019-09-28 19:42:29,896 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 9902@um2
2019-09-28 19:42:29,899 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-09-28 19:42:29,904 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-09-28 19:42:29,940 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-09-28 19:42:29,940 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-28 19:42:29,941 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-28 19:42:29,943 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Sep 28 19:42:29
2019-09-28 19:42:29,944 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-09-28 19:42:29,944 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-28 19:42:29,945 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-09-28 19:42:29,945 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-09-28 19:42:29,964 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-09-28 19:42:29,966 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-09-28 19:42:29,966 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-09-28 19:42:29,966 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-09-28 19:42:29,966 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-09-28 19:42:29,966 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-09-28 19:42:29,966 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-09-28 19:42:29,966 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-09-28 19:42:29,967 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-09-28 19:42:29,967 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-09-28 19:42:29,967 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-09-28 19:42:29,967 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-09-28 19:42:29,969 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-09-28 19:42:30,335 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-09-28 19:42:30,335 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-28 19:42:30,335 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-09-28 19:42:30,335 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-09-28 19:42:30,336 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-09-28 19:42:30,341 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-09-28 19:42:30,341 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-28 19:42:30,341 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-09-28 19:42:30,341 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-09-28 19:42:30,342 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-28 19:42:30,342 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-09-28 19:42:30,343 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-09-28 19:42:30,344 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-09-28 19:42:30,344 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-09-28 19:42:30,344 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-09-28 19:42:30,351 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-09-28 19:42:30,392 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-28 19:42:30,395 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-09-28 19:42:30,403 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 19:42:30,406 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-09-28 19:42:30,406 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 19:42:30,406 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 19:42:30,421 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-09-28 19:42:30,421 INFO org.mortbay.log: jetty-6.1.26
2019-09-28 19:42:30,601 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-09-28 19:42:30,601 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-09-28 19:42:30,601 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-09-28 19:42:30,601 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-09-28 19:42:35,846 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-09-28 19:42:35,848 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.182.5
************************************************************/
2019-09-28 19:42:53,797 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.182.5
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-09-28 19:42:53,808 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-28 19:42:54,459 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-28 19:42:54,537 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-09-28 19:42:54,537 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-28 19:42:54,641 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-28 19:42:54,641 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-28 19:42:54,692 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 9982@um2
2019-09-28 19:42:54,694 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 9982@um2
2019-09-28 19:42:54,696 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-09-28 19:42:54,701 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-09-28 19:42:54,739 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-09-28 19:42:54,739 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-28 19:42:54,740 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-28 19:42:54,741 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Sep 28 19:42:54
2019-09-28 19:42:54,743 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-09-28 19:42:54,743 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-28 19:42:54,744 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-09-28 19:42:54,744 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-09-28 19:42:54,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-09-28 19:42:54,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-09-28 19:42:54,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-09-28 19:42:54,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-09-28 19:42:54,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-09-28 19:42:54,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-09-28 19:42:54,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-09-28 19:42:54,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-09-28 19:42:54,756 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-09-28 19:42:54,757 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-09-28 19:42:54,757 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-09-28 19:42:54,757 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-09-28 19:42:54,758 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-09-28 19:42:55,056 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-09-28 19:42:55,057 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-28 19:42:55,057 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-09-28 19:42:55,057 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-09-28 19:42:55,071 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-09-28 19:42:55,081 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-09-28 19:42:55,081 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-28 19:42:55,081 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-09-28 19:42:55,081 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-09-28 19:42:55,083 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-28 19:42:55,083 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-09-28 19:42:55,083 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-09-28 19:42:55,085 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-09-28 19:42:55,085 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-09-28 19:42:55,085 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-09-28 19:42:55,092 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-09-28 19:42:55,169 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-28 19:42:55,179 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-09-28 19:42:55,189 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-28 19:42:55,190 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-09-28 19:42:55,191 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-28 19:42:55,191 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-28 19:42:55,204 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-09-28 19:42:55,204 INFO org.mortbay.log: jetty-6.1.26
2019-09-28 19:42:55,369 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-09-28 19:42:55,369 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-09-28 19:42:55,369 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-09-28 19:42:55,369 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-09-28 19:43:55,585 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-09-28 19:43:55,702 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=0&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:55,767 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-09-28 19:43:56,005 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 0.00 KB/s
2019-09-28 19:43:56,005 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 320 bytes.
2019-09-28 19:43:56,014 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1&endTxId=2&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,019 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,019 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000002_0000000000008649190 size 0 bytes.
2019-09-28 19:43:56,020 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3&endTxId=4&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,028 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,028 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000003-0000000000000000004_0000000000008649197 size 0 bytes.
2019-09-28 19:43:56,029 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=5&endTxId=6&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,033 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,033 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000005-0000000000000000006_0000000000008649206 size 0 bytes.
2019-09-28 19:43:56,033 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=7&endTxId=8&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,037 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,037 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000007-0000000000000000008_0000000000008649210 size 0 bytes.
2019-09-28 19:43:56,037 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=9&endTxId=10&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,041 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,041 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000009-0000000000000000010_0000000000008649215 size 0 bytes.
2019-09-28 19:43:56,042 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=11&endTxId=12&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,046 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,046 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000011-0000000000000000012_0000000000008649219 size 0 bytes.
2019-09-28 19:43:56,047 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=13&endTxId=14&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,051 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,051 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000013-0000000000000000014_0000000000008649224 size 0 bytes.
2019-09-28 19:43:56,052 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=15&endTxId=16&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,056 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,056 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000015-0000000000000000016_0000000000008649229 size 0 bytes.
2019-09-28 19:43:56,056 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=17&endTxId=18&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,062 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,063 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000017-0000000000000000018_0000000000008649234 size 0 bytes.
2019-09-28 19:43:56,063 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=19&endTxId=20&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,067 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,067 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000019-0000000000000000020_0000000000008649241 size 0 bytes.
2019-09-28 19:43:56,067 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=21&endTxId=22&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,070 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,070 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000021-0000000000000000022_0000000000008649244 size 0 bytes.
2019-09-28 19:43:56,071 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=23&endTxId=24&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,075 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,075 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000023-0000000000000000024_0000000000008649248 size 0 bytes.
2019-09-28 19:43:56,076 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=25&endTxId=26&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,080 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,080 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000025-0000000000000000026_0000000000008649252 size 0 bytes.
2019-09-28 19:43:56,081 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=27&endTxId=28&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,090 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,090 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000027-0000000000000000028_0000000000008649258 size 0 bytes.
2019-09-28 19:43:56,091 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=29&endTxId=30&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,094 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,094 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000029-0000000000000000030_0000000000008649268 size 0 bytes.
2019-09-28 19:43:56,095 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=31&endTxId=32&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,099 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,099 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000031-0000000000000000032_0000000000008649272 size 0 bytes.
2019-09-28 19:43:56,099 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=33&endTxId=34&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,103 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,103 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000033-0000000000000000034_0000000000008649277 size 0 bytes.
2019-09-28 19:43:56,103 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=35&endTxId=36&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,108 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,108 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000035-0000000000000000036_0000000000008649281 size 0 bytes.
2019-09-28 19:43:56,108 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=37&endTxId=38&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,112 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,112 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000037-0000000000000000038_0000000000008649286 size 0 bytes.
2019-09-28 19:43:56,114 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=39&endTxId=40&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,117 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,117 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000039-0000000000000000040_0000000000008649291 size 0 bytes.
2019-09-28 19:43:56,117 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=41&endTxId=42&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,121 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,121 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000041-0000000000000000042_0000000000008649295 size 0 bytes.
2019-09-28 19:43:56,122 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=43&endTxId=45&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,125 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,125 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000043-0000000000000000045_0000000000008649299 size 0 bytes.
2019-09-28 19:43:56,126 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=46&endTxId=57&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,131 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,131 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000046-0000000000000000057_0000000000008649303 size 0 bytes.
2019-09-28 19:43:56,131 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=58&endTxId=59&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,136 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,137 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000058-0000000000000000059_0000000000008649309 size 0 bytes.
2019-09-28 19:43:56,137 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=60&endTxId=71&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,140 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,140 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000060-0000000000000000071_0000000000008649314 size 0 bytes.
2019-09-28 19:43:56,140 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=72&endTxId=73&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,144 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,144 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000072-0000000000000000073_0000000000008649318 size 0 bytes.
2019-09-28 19:43:56,144 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=74&endTxId=75&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,147 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,147 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000074-0000000000000000075_0000000000008649321 size 0 bytes.
2019-09-28 19:43:56,148 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=76&endTxId=77&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,160 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-09-28 19:43:56,160 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000076-0000000000000000077_0000000000008649325 size 0 bytes.
2019-09-28 19:43:56,161 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=78&endTxId=79&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,166 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,166 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000078-0000000000000000079_0000000000008649338 size 0 bytes.
2019-09-28 19:43:56,166 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=80&endTxId=81&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,169 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,169 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000080-0000000000000000081_0000000000008649344 size 0 bytes.
2019-09-28 19:43:56,170 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=82&endTxId=83&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,173 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,173 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000082-0000000000000000083_0000000000008649347 size 0 bytes.
2019-09-28 19:43:56,174 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=84&endTxId=85&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,181 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,181 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000084-0000000000000000085_0000000000008649351 size 0 bytes.
2019-09-28 19:43:56,181 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=86&endTxId=87&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,185 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,185 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000086-0000000000000000087_0000000000008649359 size 0 bytes.
2019-09-28 19:43:56,185 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=88&endTxId=89&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,188 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,188 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000088-0000000000000000089_0000000000008649363 size 0 bytes.
2019-09-28 19:43:56,188 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=90&endTxId=91&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,192 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,192 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000090-0000000000000000091_0000000000008649366 size 0 bytes.
2019-09-28 19:43:56,192 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=92&endTxId=93&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,195 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,195 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000092-0000000000000000093_0000000000008649369 size 0 bytes.
2019-09-28 19:43:56,195 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=94&endTxId=95&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,198 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,198 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000094-0000000000000000095_0000000000008649373 size 0 bytes.
2019-09-28 19:43:56,199 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=96&endTxId=97&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,203 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,203 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000096-0000000000000000097_0000000000008649376 size 0 bytes.
2019-09-28 19:43:56,203 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=98&endTxId=99&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,207 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,207 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000098-0000000000000000099_0000000000008649380 size 0 bytes.
2019-09-28 19:43:56,207 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=100&endTxId=101&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,214 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-09-28 19:43:56,214 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000100-0000000000000000101_0000000000008649385 size 0 bytes.
2019-09-28 19:43:56,215 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=102&endTxId=103&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,223 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,223 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000102-0000000000000000103_0000000000008649392 size 0 bytes.
2019-09-28 19:43:56,224 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=104&endTxId=105&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,227 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,227 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000104-0000000000000000105_0000000000008649401 size 0 bytes.
2019-09-28 19:43:56,228 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=106&endTxId=107&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,231 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,231 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000106-0000000000000000107_0000000000008649405 size 0 bytes.
2019-09-28 19:43:56,232 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=108&endTxId=109&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,235 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,235 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000108-0000000000000000109_0000000000008649409 size 0 bytes.
2019-09-28 19:43:56,235 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=110&endTxId=111&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,239 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,239 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000110-0000000000000000111_0000000000008649413 size 0 bytes.
2019-09-28 19:43:56,239 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=112&endTxId=113&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,242 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,242 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000112-0000000000000000113_0000000000008649416 size 0 bytes.
2019-09-28 19:43:56,242 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=114&endTxId=115&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,245 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,245 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000114-0000000000000000115_0000000000008649419 size 0 bytes.
2019-09-28 19:43:56,245 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=116&endTxId=117&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,248 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,248 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000116-0000000000000000117_0000000000008649422 size 0 bytes.
2019-09-28 19:43:56,248 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=118&endTxId=119&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,251 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,251 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000118-0000000000000000119_0000000000008649425 size 0 bytes.
2019-09-28 19:43:56,251 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=120&endTxId=122&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,254 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,254 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000120-0000000000000000122_0000000000008649428 size 0 bytes.
2019-09-28 19:43:56,254 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=123&endTxId=124&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,257 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,257 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000123-0000000000000000124_0000000000008649431 size 0 bytes.
2019-09-28 19:43:56,257 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=125&endTxId=217&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,260 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 8000.00 KB/s
2019-09-28 19:43:56,260 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000125-0000000000000000217_0000000000008649435 size 0 bytes.
2019-09-28 19:43:56,260 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=218&endTxId=219&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,264 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,264 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000218-0000000000000000219_0000000000008649438 size 0 bytes.
2019-09-28 19:43:56,264 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=220&endTxId=221&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,267 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,267 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000220-0000000000000000221_0000000000008649441 size 0 bytes.
2019-09-28 19:43:56,267 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=222&endTxId=223&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,270 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,270 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000222-0000000000000000223_0000000000008649445 size 0 bytes.
2019-09-28 19:43:56,270 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=224&endTxId=225&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,273 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,273 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000224-0000000000000000225_0000000000008649448 size 0 bytes.
2019-09-28 19:43:56,273 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=226&endTxId=227&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,276 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,276 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000226-0000000000000000227_0000000000008649451 size 0 bytes.
2019-09-28 19:43:56,276 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=228&endTxId=229&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,278 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,278 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000228-0000000000000000229_0000000000008649453 size 0 bytes.
2019-09-28 19:43:56,279 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=230&endTxId=231&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,282 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,282 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000230-0000000000000000231_0000000000008649456 size 0 bytes.
2019-09-28 19:43:56,282 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=232&endTxId=233&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:43:56,285 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:43:56,285 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000232-0000000000000000233_0000000000008649460 size 0 bytes.
2019-09-28 19:43:56,319 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-09-28 19:43:56,337 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-09-28 19:43:56,337 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /orgz/snnfsi/current/fsimage_0000000000000000000
2019-09-28 19:43:56,337 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-09-28 19:43:56,342 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 60 stream(s).
2019-09-28 19:43:56,345 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000001-0000000000000000002 expecting start txid #1
2019-09-28 19:43:56,345 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000001-0000000000000000002
2019-09-28 19:43:56,359 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000001-0000000000000000002 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,359 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000003-0000000000000000004 expecting start txid #3
2019-09-28 19:43:56,359 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000003-0000000000000000004
2019-09-28 19:43:56,360 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000003-0000000000000000004 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,360 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000005-0000000000000000006 expecting start txid #5
2019-09-28 19:43:56,360 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000005-0000000000000000006
2019-09-28 19:43:56,360 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000005-0000000000000000006 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,360 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000007-0000000000000000008 expecting start txid #7
2019-09-28 19:43:56,360 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000007-0000000000000000008
2019-09-28 19:43:56,360 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000007-0000000000000000008 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,360 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000009-0000000000000000010 expecting start txid #9
2019-09-28 19:43:56,360 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000009-0000000000000000010
2019-09-28 19:43:56,360 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000009-0000000000000000010 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,361 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000011-0000000000000000012 expecting start txid #11
2019-09-28 19:43:56,361 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000011-0000000000000000012
2019-09-28 19:43:56,361 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000011-0000000000000000012 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,361 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000013-0000000000000000014 expecting start txid #13
2019-09-28 19:43:56,361 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000013-0000000000000000014
2019-09-28 19:43:56,361 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000013-0000000000000000014 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,361 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000015-0000000000000000016 expecting start txid #15
2019-09-28 19:43:56,361 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000015-0000000000000000016
2019-09-28 19:43:56,361 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000015-0000000000000000016 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,361 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000017-0000000000000000018 expecting start txid #17
2019-09-28 19:43:56,361 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000017-0000000000000000018
2019-09-28 19:43:56,362 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000017-0000000000000000018 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,362 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000019-0000000000000000020 expecting start txid #19
2019-09-28 19:43:56,362 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000019-0000000000000000020
2019-09-28 19:43:56,362 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000019-0000000000000000020 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,362 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000021-0000000000000000022 expecting start txid #21
2019-09-28 19:43:56,362 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000021-0000000000000000022
2019-09-28 19:43:56,362 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000021-0000000000000000022 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,362 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000023-0000000000000000024 expecting start txid #23
2019-09-28 19:43:56,362 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000023-0000000000000000024
2019-09-28 19:43:56,363 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000023-0000000000000000024 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,363 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000025-0000000000000000026 expecting start txid #25
2019-09-28 19:43:56,363 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000025-0000000000000000026
2019-09-28 19:43:56,363 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000025-0000000000000000026 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,363 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000027-0000000000000000028 expecting start txid #27
2019-09-28 19:43:56,363 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000027-0000000000000000028
2019-09-28 19:43:56,363 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000027-0000000000000000028 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,363 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000029-0000000000000000030 expecting start txid #29
2019-09-28 19:43:56,363 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000029-0000000000000000030
2019-09-28 19:43:56,363 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000029-0000000000000000030 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,364 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000031-0000000000000000032 expecting start txid #31
2019-09-28 19:43:56,364 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000031-0000000000000000032
2019-09-28 19:43:56,364 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000031-0000000000000000032 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,364 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000033-0000000000000000034 expecting start txid #33
2019-09-28 19:43:56,364 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000033-0000000000000000034
2019-09-28 19:43:56,364 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000033-0000000000000000034 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,364 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000035-0000000000000000036 expecting start txid #35
2019-09-28 19:43:56,364 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000035-0000000000000000036
2019-09-28 19:43:56,364 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000035-0000000000000000036 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,364 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000037-0000000000000000038 expecting start txid #37
2019-09-28 19:43:56,364 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000037-0000000000000000038
2019-09-28 19:43:56,364 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000037-0000000000000000038 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,364 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000039-0000000000000000040 expecting start txid #39
2019-09-28 19:43:56,364 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000039-0000000000000000040
2019-09-28 19:43:56,365 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000039-0000000000000000040 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,365 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000041-0000000000000000042 expecting start txid #41
2019-09-28 19:43:56,365 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000041-0000000000000000042
2019-09-28 19:43:56,365 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000041-0000000000000000042 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,365 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000043-0000000000000000045 expecting start txid #43
2019-09-28 19:43:56,365 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000043-0000000000000000045
2019-09-28 19:43:56,377 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000043-0000000000000000045 of size 114 edits # 3 loaded in 0 seconds
2019-09-28 19:43:56,377 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000046-0000000000000000057 expecting start txid #46
2019-09-28 19:43:56,377 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000046-0000000000000000057
2019-09-28 19:43:56,386 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000046-0000000000000000057 of size 720 edits # 12 loaded in 0 seconds
2019-09-28 19:43:56,386 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000058-0000000000000000059 expecting start txid #58
2019-09-28 19:43:56,387 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000058-0000000000000000059
2019-09-28 19:43:56,387 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000058-0000000000000000059 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,387 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000060-0000000000000000071 expecting start txid #60
2019-09-28 19:43:56,387 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000060-0000000000000000071
2019-09-28 19:43:56,388 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000060-0000000000000000071 of size 756 edits # 12 loaded in 0 seconds
2019-09-28 19:43:56,388 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000072-0000000000000000073 expecting start txid #72
2019-09-28 19:43:56,388 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000072-0000000000000000073
2019-09-28 19:43:56,388 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000072-0000000000000000073 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,388 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000074-0000000000000000075 expecting start txid #74
2019-09-28 19:43:56,388 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000074-0000000000000000075
2019-09-28 19:43:56,389 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000074-0000000000000000075 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,389 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000076-0000000000000000077 expecting start txid #76
2019-09-28 19:43:56,389 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000076-0000000000000000077
2019-09-28 19:43:56,389 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000076-0000000000000000077 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,389 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000078-0000000000000000079 expecting start txid #78
2019-09-28 19:43:56,389 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000078-0000000000000000079
2019-09-28 19:43:56,389 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000078-0000000000000000079 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,389 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000080-0000000000000000081 expecting start txid #80
2019-09-28 19:43:56,389 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000080-0000000000000000081
2019-09-28 19:43:56,389 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000080-0000000000000000081 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,389 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000082-0000000000000000083 expecting start txid #82
2019-09-28 19:43:56,389 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000082-0000000000000000083
2019-09-28 19:43:56,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000082-0000000000000000083 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000084-0000000000000000085 expecting start txid #84
2019-09-28 19:43:56,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000084-0000000000000000085
2019-09-28 19:43:56,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000084-0000000000000000085 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000086-0000000000000000087 expecting start txid #86
2019-09-28 19:43:56,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000086-0000000000000000087
2019-09-28 19:43:56,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000086-0000000000000000087 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000088-0000000000000000089 expecting start txid #88
2019-09-28 19:43:56,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000088-0000000000000000089
2019-09-28 19:43:56,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000088-0000000000000000089 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000090-0000000000000000091 expecting start txid #90
2019-09-28 19:43:56,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000090-0000000000000000091
2019-09-28 19:43:56,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000090-0000000000000000091 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,391 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000092-0000000000000000093 expecting start txid #92
2019-09-28 19:43:56,391 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000092-0000000000000000093
2019-09-28 19:43:56,391 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000092-0000000000000000093 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,391 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000094-0000000000000000095 expecting start txid #94
2019-09-28 19:43:56,391 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000094-0000000000000000095
2019-09-28 19:43:56,391 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000094-0000000000000000095 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,391 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000096-0000000000000000097 expecting start txid #96
2019-09-28 19:43:56,391 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000096-0000000000000000097
2019-09-28 19:43:56,391 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000096-0000000000000000097 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,391 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000098-0000000000000000099 expecting start txid #98
2019-09-28 19:43:56,391 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000098-0000000000000000099
2019-09-28 19:43:56,391 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000098-0000000000000000099 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,391 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000100-0000000000000000101 expecting start txid #100
2019-09-28 19:43:56,391 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000100-0000000000000000101
2019-09-28 19:43:56,392 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000100-0000000000000000101 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,392 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000102-0000000000000000103 expecting start txid #102
2019-09-28 19:43:56,392 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000102-0000000000000000103
2019-09-28 19:43:56,392 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000102-0000000000000000103 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,392 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000104-0000000000000000105 expecting start txid #104
2019-09-28 19:43:56,392 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000104-0000000000000000105
2019-09-28 19:43:56,392 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000104-0000000000000000105 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,392 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000106-0000000000000000107 expecting start txid #106
2019-09-28 19:43:56,392 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000106-0000000000000000107
2019-09-28 19:43:56,392 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000106-0000000000000000107 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,392 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000108-0000000000000000109 expecting start txid #108
2019-09-28 19:43:56,392 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000108-0000000000000000109
2019-09-28 19:43:56,392 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000108-0000000000000000109 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,392 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000110-0000000000000000111 expecting start txid #110
2019-09-28 19:43:56,392 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000110-0000000000000000111
2019-09-28 19:43:56,392 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000110-0000000000000000111 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,392 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000112-0000000000000000113 expecting start txid #112
2019-09-28 19:43:56,393 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000112-0000000000000000113
2019-09-28 19:43:56,393 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000112-0000000000000000113 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,393 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000114-0000000000000000115 expecting start txid #114
2019-09-28 19:43:56,393 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000114-0000000000000000115
2019-09-28 19:43:56,393 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000114-0000000000000000115 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,393 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000116-0000000000000000117 expecting start txid #116
2019-09-28 19:43:56,393 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000116-0000000000000000117
2019-09-28 19:43:56,393 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000116-0000000000000000117 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,393 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000118-0000000000000000119 expecting start txid #118
2019-09-28 19:43:56,393 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000118-0000000000000000119
2019-09-28 19:43:56,393 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000118-0000000000000000119 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,393 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000120-0000000000000000122 expecting start txid #120
2019-09-28 19:43:56,393 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000120-0000000000000000122
2019-09-28 19:43:56,394 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000120-0000000000000000122 of size 84 edits # 3 loaded in 0 seconds
2019-09-28 19:43:56,394 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000123-0000000000000000124 expecting start txid #123
2019-09-28 19:43:56,394 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000123-0000000000000000124
2019-09-28 19:43:56,394 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000123-0000000000000000124 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,394 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000125-0000000000000000217 expecting start txid #125
2019-09-28 19:43:56,394 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000125-0000000000000000217
2019-09-28 19:43:56,405 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000125-0000000000000000217 of size 8704 edits # 93 loaded in 0 seconds
2019-09-28 19:43:56,405 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000218-0000000000000000219 expecting start txid #218
2019-09-28 19:43:56,405 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000218-0000000000000000219
2019-09-28 19:43:56,405 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000218-0000000000000000219 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,405 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000220-0000000000000000221 expecting start txid #220
2019-09-28 19:43:56,405 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000220-0000000000000000221
2019-09-28 19:43:56,406 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000220-0000000000000000221 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,406 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000222-0000000000000000223 expecting start txid #222
2019-09-28 19:43:56,406 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000222-0000000000000000223
2019-09-28 19:43:56,406 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000222-0000000000000000223 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,406 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000224-0000000000000000225 expecting start txid #224
2019-09-28 19:43:56,406 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000224-0000000000000000225
2019-09-28 19:43:56,406 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000224-0000000000000000225 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,406 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000226-0000000000000000227 expecting start txid #226
2019-09-28 19:43:56,406 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000226-0000000000000000227
2019-09-28 19:43:56,406 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000226-0000000000000000227 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,406 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000228-0000000000000000229 expecting start txid #228
2019-09-28 19:43:56,406 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000228-0000000000000000229
2019-09-28 19:43:56,406 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000228-0000000000000000229 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,406 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000230-0000000000000000231 expecting start txid #230
2019-09-28 19:43:56,406 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000230-0000000000000000231
2019-09-28 19:43:56,406 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000230-0000000000000000231 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,406 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000232-0000000000000000233 expecting start txid #232
2019-09-28 19:43:56,406 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000232-0000000000000000233
2019-09-28 19:43:56,407 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000232-0000000000000000233 of size 42 edits # 2 loaded in 0 seconds
2019-09-28 19:43:56,410 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000233 using no compression
2019-09-28 19:43:56,462 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000233 of size 1731 bytes saved in 0 seconds.
2019-09-28 19:43:56,465 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /orgz/snnfsi
2019-09-28 19:43:56,465 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /orgz/snnedits
2019-09-28 19:43:56,519 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 233 to namenode at http://um1:50070 in 0.036 seconds
2019-09-28 19:43:56,521 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1731
2019-09-28 19:48:57,567 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 19:48:58,569 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 19:48:59,576 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 19:49:00,579 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 19:54:00,728 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-28 19:54:00,728 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=234&endTxId=240&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:54:00,976 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 34133.33 KB/s
2019-09-28 19:54:00,976 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000234-0000000000000000240_0000000000009253906 size 0 bytes.
2019-09-28 19:54:00,976 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=241&endTxId=243&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-28 19:54:00,981 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-28 19:54:00,981 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000241-0000000000000000243_0000000000009254154 size 0 bytes.
2019-09-28 19:54:00,982 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2019-09-28 19:54:00,982 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000234-0000000000000000240 expecting start txid #234
2019-09-28 19:54:00,982 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000234-0000000000000000240
2019-09-28 19:54:00,989 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000234-0000000000000000240 of size 1048576 edits # 7 loaded in 0 seconds
2019-09-28 19:54:00,989 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000241-0000000000000000243 expecting start txid #241
2019-09-28 19:54:00,989 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000241-0000000000000000243
2019-09-28 19:54:00,991 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000241-0000000000000000243 of size 151 edits # 3 loaded in 0 seconds
2019-09-28 19:54:00,992 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000243 using no compression
2019-09-28 19:54:00,999 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000243 of size 1785 bytes saved in 0 seconds.
2019-09-28 19:54:01,003 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 233
2019-09-28 19:54:01,003 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-09-28 19:54:01,048 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 243 to namenode at http://um1:50070 in 0.04 seconds
2019-09-28 19:54:01,049 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1785
2019-09-28 20:00:21,123 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 0 time(s); maxRetries=45
2019-09-28 20:00:41,150 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 1 time(s); maxRetries=45
2019-09-28 20:00:50,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 20:00:54,319 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 20:00:57,468 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 20:01:00,496 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 20:01:03,568 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 20:01:06,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 20:01:09,712 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 20:01:12,794 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 20:01:15,890 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 20:01:18,964 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-28 20:01:21,041 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.182.5 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details se2019-09-29 16:05:18,346 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.182.5
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-09-29 16:05:18,363 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-29 16:05:19,317 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-29 16:05:19,461 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-09-29 16:05:19,462 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-29 16:05:19,629 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-29 16:05:19,630 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-29 16:05:19,757 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 3051@um2
2019-09-29 16:05:19,830 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 3051@um2
2019-09-29 16:05:19,861 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-09-29 16:05:19,870 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-09-29 16:05:19,934 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-09-29 16:05:19,934 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-29 16:05:19,935 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-29 16:05:19,937 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Sep 29 16:05:19
2019-09-29 16:05:19,940 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-09-29 16:05:19,940 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-29 16:05:19,942 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-09-29 16:05:19,943 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-09-29 16:05:20,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-09-29 16:05:20,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-09-29 16:05:20,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-09-29 16:05:20,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-09-29 16:05:20,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-09-29 16:05:20,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-09-29 16:05:20,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-09-29 16:05:20,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-09-29 16:05:20,011 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-09-29 16:05:20,011 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-09-29 16:05:20,011 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-09-29 16:05:20,011 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-09-29 16:05:20,013 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-09-29 16:05:20,532 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-09-29 16:05:20,532 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-29 16:05:20,533 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-09-29 16:05:20,533 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-09-29 16:05:20,533 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-09-29 16:05:20,543 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-09-29 16:05:20,543 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-29 16:05:20,543 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-09-29 16:05:20,543 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-09-29 16:05:20,545 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-29 16:05:20,545 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-09-29 16:05:20,545 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-09-29 16:05:20,559 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-09-29 16:05:20,559 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-09-29 16:05:20,559 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-09-29 16:05:20,572 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-09-29 16:05:20,632 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-29 16:05:20,636 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-09-29 16:05:20,650 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-29 16:05:20,652 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-09-29 16:05:20,654 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-29 16:05:20,654 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-29 16:05:20,739 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-09-29 16:05:20,739 INFO org.mortbay.log: jetty-6.1.26
2019-09-29 16:05:21,271 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-09-29 16:05:21,271 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-09-29 16:05:21,271 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-09-29 16:05:21,271 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-09-29 16:12:21,558 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-09-29 16:12:21,750 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=244&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-29 16:12:21,796 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-09-29 16:12:21,986 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 333.33 KB/s
2019-09-29 16:12:21,986 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000244 size 1785 bytes.
2019-09-29 16:12:22,002 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=245&endTxId=338&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-29 16:12:22,012 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 4000.00 KB/s
2019-09-29 16:12:22,013 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000245-0000000000000000338_0000000000000608390 size 0 bytes.
2019-09-29 16:12:22,053 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 22 INodes.
2019-09-29 16:12:22,089 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-09-29 16:12:22,089 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 244 from /orgz/snnfsi/current/fsimage_0000000000000000244
2019-09-29 16:12:22,089 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-09-29 16:12:22,093 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-29 16:12:22,097 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000245-0000000000000000338 expecting start txid #245
2019-09-29 16:12:22,097 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000245-0000000000000000338
2019-09-29 16:12:22,179 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000245-0000000000000000338 of size 8766 edits # 94 loaded in 0 seconds
2019-09-29 16:12:22,183 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000338 using no compression
2019-09-29 16:12:22,244 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000338 of size 1707 bytes saved in 0 seconds.
2019-09-29 16:12:22,260 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 244
2019-09-29 16:12:22,260 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000233, cpktTxId=0000000000000000233)
2019-09-29 16:12:22,261 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000243, cpktTxId=0000000000000000243)
2019-09-29 16:12:22,306 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 338 to namenode at http://um1:50070 in 0.029 seconds
2019-09-29 16:12:22,307 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1707
2019-09-29 16:21:53,347 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-09-29 16:21:53,349 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.182.5
************************************************************/
2019-09-29 16:23:26,833 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.182.5
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-09-29 16:23:26,847 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-29 16:23:27,424 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-29 16:23:27,516 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-09-29 16:23:27,516 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-29 16:23:27,631 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-29 16:23:27,631 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-29 16:23:27,684 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 4306@um2
2019-09-29 16:23:27,752 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 4306@um2
2019-09-29 16:23:27,770 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-09-29 16:23:27,778 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-09-29 16:23:27,812 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-09-29 16:23:27,812 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-29 16:23:27,813 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-29 16:23:27,815 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Sep 29 16:23:27
2019-09-29 16:23:27,816 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-09-29 16:23:27,816 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-29 16:23:27,818 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-09-29 16:23:27,818 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-09-29 16:23:27,832 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-09-29 16:23:27,832 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-09-29 16:23:27,832 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-09-29 16:23:27,832 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-09-29 16:23:27,832 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-09-29 16:23:27,832 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-09-29 16:23:27,832 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-09-29 16:23:27,832 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-09-29 16:23:27,833 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-09-29 16:23:27,833 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-09-29 16:23:27,833 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-09-29 16:23:27,833 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-09-29 16:23:27,834 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-09-29 16:23:28,169 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-09-29 16:23:28,169 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-29 16:23:28,170 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-09-29 16:23:28,170 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-09-29 16:23:28,170 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-09-29 16:23:28,176 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-09-29 16:23:28,176 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-29 16:23:28,176 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-09-29 16:23:28,176 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-09-29 16:23:28,177 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-29 16:23:28,177 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-09-29 16:23:28,177 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-09-29 16:23:28,178 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-09-29 16:23:28,178 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-09-29 16:23:28,178 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-09-29 16:23:28,188 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-09-29 16:23:28,238 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-29 16:23:28,242 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-09-29 16:23:28,253 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-29 16:23:28,254 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-09-29 16:23:28,254 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-29 16:23:28,255 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-29 16:23:28,270 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-09-29 16:23:28,270 INFO org.mortbay.log: jetty-6.1.26
2019-09-29 16:23:28,484 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-09-29 16:23:28,484 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-09-29 16:23:28,484 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-09-29 16:23:28,485 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-09-29 16:24:28,670 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-09-29 16:24:28,796 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=343&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-29 16:24:28,825 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-09-29 16:24:28,838 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 250.00 KB/s
2019-09-29 16:24:28,838 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000343 size 1707 bytes.
2019-09-29 16:24:28,844 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=344&endTxId=345&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-29 16:24:28,848 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-29 16:24:28,848 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000344-0000000000000000345_0000000000001335231 size 0 bytes.
2019-09-29 16:24:28,896 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 21 INodes.
2019-09-29 16:24:28,929 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-09-29 16:24:28,929 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 343 from /orgz/snnfsi/current/fsimage_0000000000000000343
2019-09-29 16:24:28,930 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-09-29 16:24:28,933 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-29 16:24:28,936 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000344-0000000000000000345 expecting start txid #344
2019-09-29 16:24:28,936 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000344-0000000000000000345
2019-09-29 16:24:28,950 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000344-0000000000000000345 of size 42 edits # 2 loaded in 0 seconds
2019-09-29 16:24:28,961 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000345 using no compression
2019-09-29 16:24:29,021 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000345 of size 1707 bytes saved in 0 seconds.
2019-09-29 16:24:29,034 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 343
2019-09-29 16:24:29,035 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000340, cpktTxId=0000000000000000340)
2019-09-29 16:24:29,081 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 345 to namenode at http://um1:50070 in 0.021 seconds
2019-09-29 16:24:29,081 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1707
2019-09-29 16:34:29,203 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-29 16:34:29,203 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=346&endTxId=347&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-29 16:34:29,209 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-29 16:34:29,209 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000346-0000000000000000347_0000000000001935591 size 0 bytes.
2019-09-29 16:34:29,209 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-29 16:34:29,210 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000346-0000000000000000347 expecting start txid #346
2019-09-29 16:34:29,210 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000346-0000000000000000347
2019-09-29 16:34:29,210 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000346-0000000000000000347 of size 42 edits # 2 loaded in 0 seconds
2019-09-29 16:34:29,213 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000347 using no compression
2019-09-29 16:34:29,225 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000347 of size 1707 bytes saved in 0 seconds.
2019-09-29 16:34:29,229 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 345
2019-09-29 16:34:29,230 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000343, cpktTxId=0000000000000000343)
2019-09-29 16:34:29,258 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 347 to namenode at http://um1:50070 in 0.011 seconds
2019-09-29 16:34:29,258 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1707
2019-09-29 16:40:29,527 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-09-29 16:40:29,529 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.182.5
************************************************************/
2019-09-29 16:55:24,526 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.182.5
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-09-29 16:55:24,538 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-29 16:55:25,185 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-29 16:55:25,257 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-09-29 16:55:25,258 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-29 16:55:25,385 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-29 16:55:25,386 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-29 16:55:25,447 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 5375@um2
2019-09-29 16:55:25,513 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 5375@um2
2019-09-29 16:55:25,532 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-09-29 16:55:25,540 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-09-29 16:55:25,578 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-09-29 16:55:25,578 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-29 16:55:25,580 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-29 16:55:25,582 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Sep 29 16:55:25
2019-09-29 16:55:25,584 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-09-29 16:55:25,584 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-29 16:55:25,585 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-09-29 16:55:25,585 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-09-29 16:55:25,596 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-09-29 16:55:25,597 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-09-29 16:55:25,597 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-09-29 16:55:25,597 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-09-29 16:55:25,597 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-09-29 16:55:25,597 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-09-29 16:55:25,597 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-09-29 16:55:25,597 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-09-29 16:55:25,598 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-09-29 16:55:25,598 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-09-29 16:55:25,598 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-09-29 16:55:25,598 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-09-29 16:55:25,600 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-09-29 16:55:25,982 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-09-29 16:55:25,982 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-29 16:55:25,983 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-09-29 16:55:25,983 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-09-29 16:55:25,983 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-09-29 16:55:25,991 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-09-29 16:55:25,991 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-29 16:55:25,991 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-09-29 16:55:25,991 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-09-29 16:55:25,993 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-29 16:55:25,993 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-09-29 16:55:25,995 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-09-29 16:55:25,996 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-09-29 16:55:25,996 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-09-29 16:55:25,996 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-09-29 16:55:26,004 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-09-29 16:55:26,048 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-29 16:55:26,053 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-09-29 16:55:26,065 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-29 16:55:26,067 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-09-29 16:55:26,067 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-29 16:55:26,067 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-29 16:55:26,085 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-09-29 16:55:26,085 INFO org.mortbay.log: jetty-6.1.26
2019-09-29 16:55:26,327 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-09-29 16:55:26,327 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-09-29 16:55:26,327 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-09-29 16:55:26,327 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-09-29 16:56:26,601 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-09-29 16:56:26,715 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=347&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-29 16:56:26,764 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-09-29 16:56:26,953 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 100.00 KB/s
2019-09-29 16:56:26,953 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000347 size 1707 bytes.
2019-09-29 16:56:26,975 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=348&endTxId=348&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-29 16:56:27,015 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 31030.30 KB/s
2019-09-29 16:56:27,015 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000348-0000000000000000348_0000000000003253362 size 0 bytes.
2019-09-29 16:56:27,016 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=349&endTxId=350&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-29 16:56:27,025 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-29 16:56:27,025 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000349-0000000000000000350_0000000000003253403 size 0 bytes.
2019-09-29 16:56:27,062 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 21 INodes.
2019-09-29 16:56:27,109 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-09-29 16:56:27,110 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 347 from /orgz/snnfsi/current/fsimage_0000000000000000347
2019-09-29 16:56:27,110 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-09-29 16:56:27,114 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2019-09-29 16:56:27,117 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000348-0000000000000000348 expecting start txid #348
2019-09-29 16:56:27,117 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000348-0000000000000000348
2019-09-29 16:56:27,133 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000348-0000000000000000348 of size 1048576 edits # 1 loaded in 0 seconds
2019-09-29 16:56:27,133 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000349-0000000000000000350 expecting start txid #349
2019-09-29 16:56:27,133 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000349-0000000000000000350
2019-09-29 16:56:27,133 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000349-0000000000000000350 of size 42 edits # 2 loaded in 0 seconds
2019-09-29 16:56:27,138 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000350 using no compression
2019-09-29 16:56:27,177 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000350 of size 1707 bytes saved in 0 seconds.
2019-09-29 16:56:27,182 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 347
2019-09-29 16:56:27,182 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000345, cpktTxId=0000000000000000345)
2019-09-29 16:56:27,257 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 350 to namenode at http://um1:50070 in 0.055 seconds
2019-09-29 16:56:27,257 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1707
2019-09-29 16:57:47,979 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-09-29 16:57:47,981 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.182.5
************************************************************/
2019-09-29 16:59:06,077 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.182.5
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-09-29 16:59:06,089 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-29 16:59:06,763 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-29 16:59:06,845 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-09-29 16:59:06,845 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-29 16:59:06,980 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-29 16:59:06,980 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-29 16:59:07,034 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 6933@um2
2019-09-29 16:59:07,096 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 6933@um2
2019-09-29 16:59:07,104 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-09-29 16:59:07,110 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-09-29 16:59:07,153 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-09-29 16:59:07,153 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-29 16:59:07,155 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-29 16:59:07,157 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Sep 29 16:59:07
2019-09-29 16:59:07,159 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-09-29 16:59:07,159 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-29 16:59:07,161 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-09-29 16:59:07,161 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-09-29 16:59:07,171 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-09-29 16:59:07,171 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-09-29 16:59:07,171 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-09-29 16:59:07,171 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-09-29 16:59:07,172 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-09-29 16:59:07,172 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-09-29 16:59:07,172 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-09-29 16:59:07,172 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-09-29 16:59:07,172 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-09-29 16:59:07,173 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-09-29 16:59:07,173 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-09-29 16:59:07,173 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-09-29 16:59:07,175 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-09-29 16:59:07,569 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-09-29 16:59:07,569 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-29 16:59:07,570 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-09-29 16:59:07,570 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-09-29 16:59:07,571 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-09-29 16:59:07,582 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-09-29 16:59:07,582 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-29 16:59:07,583 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-09-29 16:59:07,583 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-09-29 16:59:07,585 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-29 16:59:07,585 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-09-29 16:59:07,585 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-09-29 16:59:07,588 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-09-29 16:59:07,588 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-09-29 16:59:07,589 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-09-29 16:59:07,602 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-09-29 16:59:07,659 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-29 16:59:07,672 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-09-29 16:59:07,693 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-29 16:59:07,695 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-09-29 16:59:07,696 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-29 16:59:07,696 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-29 16:59:07,716 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-09-29 16:59:07,716 INFO org.mortbay.log: jetty-6.1.26
2019-09-29 16:59:07,966 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-09-29 16:59:07,966 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-09-29 16:59:07,966 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-09-29 16:59:07,966 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-09-29 17:00:08,176 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-09-29 17:00:08,262 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=350&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-29 17:00:08,292 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-09-29 17:00:08,463 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 200.00 KB/s
2019-09-29 17:00:08,463 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000350 size 1707 bytes.
2019-09-29 17:00:08,469 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=351&endTxId=351&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-29 17:00:08,508 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 31030.30 KB/s
2019-09-29 17:00:08,508 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000351-0000000000000000351_0000000000003474857 size 0 bytes.
2019-09-29 17:00:08,509 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=352&endTxId=353&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-29 17:00:08,521 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-29 17:00:08,521 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000352-0000000000000000353_0000000000003474896 size 0 bytes.
2019-09-29 17:00:08,568 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 21 INodes.
2019-09-29 17:00:08,595 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-09-29 17:00:08,595 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 350 from /orgz/snnfsi/current/fsimage_0000000000000000350
2019-09-29 17:00:08,595 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-09-29 17:00:08,599 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2019-09-29 17:00:08,601 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000351-0000000000000000351 expecting start txid #351
2019-09-29 17:00:08,601 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000351-0000000000000000351
2019-09-29 17:00:08,619 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000351-0000000000000000351 of size 1048576 edits # 1 loaded in 0 seconds
2019-09-29 17:00:08,620 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000352-0000000000000000353 expecting start txid #352
2019-09-29 17:00:08,620 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000352-0000000000000000353
2019-09-29 17:00:08,620 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000352-0000000000000000353 of size 42 edits # 2 loaded in 0 seconds
2019-09-29 17:00:08,629 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000353 using no compression
2019-09-29 17:00:08,680 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000353 of size 1707 bytes saved in 0 seconds.
2019-09-29 17:00:08,685 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 350
2019-09-29 17:00:08,685 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000347, cpktTxId=0000000000000000347)
2019-09-29 17:00:08,746 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 353 to namenode at http://um1:50070 in 0.035 seconds
2019-09-29 17:00:08,746 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1707
2019-09-29 17:10:08,910 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-29 17:10:08,911 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=354&endTxId=355&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-29 17:10:08,917 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-29 17:10:08,917 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000354-0000000000000000355_0000000000004075298 size 0 bytes.
2019-09-29 17:10:08,917 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-29 17:10:08,917 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000354-0000000000000000355 expecting start txid #354
2019-09-29 17:10:08,917 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000354-0000000000000000355
2019-09-29 17:10:08,918 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000354-0000000000000000355 of size 42 edits # 2 loaded in 0 seconds
2019-09-29 17:10:08,919 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000355 using no compression
2019-09-29 17:10:08,928 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000355 of size 1707 bytes saved in 0 seconds.
2019-09-29 17:10:08,932 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 353
2019-09-29 17:10:08,932 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000350, cpktTxId=0000000000000000350)
2019-09-29 17:10:08,955 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 355 to namenode at http://um1:50070 in 0.014 seconds
2019-09-29 17:10:08,956 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1707
2019-09-29 17:20:10,096 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.182.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-29 17:20:10,127 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-09-29 17:20:10,128 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.182.5
************************************************************/
2019-09-29 17:21:28,064 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.182.5
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-09-29 17:21:28,077 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-29 17:21:28,698 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-29 17:21:28,788 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-09-29 17:21:28,788 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-29 17:21:28,893 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-29 17:21:28,893 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-29 17:21:28,942 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 8616@um2
2019-09-29 17:21:29,003 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 8616@um2
2019-09-29 17:21:29,013 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-09-29 17:21:29,021 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-09-29 17:21:29,060 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-09-29 17:21:29,060 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-29 17:21:29,061 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-29 17:21:29,063 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Sep 29 17:21:29
2019-09-29 17:21:29,064 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-09-29 17:21:29,064 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-29 17:21:29,065 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-09-29 17:21:29,066 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-09-29 17:21:29,077 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-09-29 17:21:29,077 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-09-29 17:21:29,077 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-09-29 17:21:29,077 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-09-29 17:21:29,077 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-09-29 17:21:29,078 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-09-29 17:21:29,078 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-09-29 17:21:29,078 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-09-29 17:21:29,078 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-09-29 17:21:29,078 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-09-29 17:21:29,078 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-09-29 17:21:29,079 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-09-29 17:21:29,084 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-09-29 17:21:29,439 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-09-29 17:21:29,439 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-29 17:21:29,439 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-09-29 17:21:29,439 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-09-29 17:21:29,440 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-09-29 17:21:29,446 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-09-29 17:21:29,446 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-29 17:21:29,446 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-09-29 17:21:29,446 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-09-29 17:21:29,447 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-29 17:21:29,447 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-09-29 17:21:29,448 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-09-29 17:21:29,449 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-09-29 17:21:29,449 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-09-29 17:21:29,449 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-09-29 17:21:29,458 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-09-29 17:21:29,502 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-29 17:21:29,506 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-09-29 17:21:29,515 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-29 17:21:29,517 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-09-29 17:21:29,517 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-29 17:21:29,517 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-29 17:21:29,533 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-09-29 17:21:29,533 INFO org.mortbay.log: jetty-6.1.26
2019-09-29 17:21:29,748 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-09-29 17:21:29,749 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-09-29 17:21:29,749 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-09-29 17:21:29,749 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-09-29 17:22:30,074 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-09-29 17:22:30,162 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=355&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-29 17:22:30,198 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-09-29 17:22:30,416 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 250.00 KB/s
2019-09-29 17:22:30,417 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000355 size 1707 bytes.
2019-09-29 17:22:30,425 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=356&endTxId=356&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-29 17:22:30,451 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 73142.86 KB/s
2019-09-29 17:22:30,451 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000356-0000000000000000356_0000000000004816812 size 0 bytes.
2019-09-29 17:22:30,452 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=357&endTxId=358&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-29 17:22:30,459 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-29 17:22:30,459 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000357-0000000000000000358_0000000000004816839 size 0 bytes.
2019-09-29 17:22:30,519 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 21 INodes.
2019-09-29 17:22:30,555 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-09-29 17:22:30,555 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 355 from /orgz/snnfsi/current/fsimage_0000000000000000355
2019-09-29 17:22:30,555 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-09-29 17:22:30,560 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2019-09-29 17:22:30,564 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000356-0000000000000000356 expecting start txid #356
2019-09-29 17:22:30,567 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000356-0000000000000000356
2019-09-29 17:22:30,585 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000356-0000000000000000356 of size 1048576 edits # 1 loaded in 0 seconds
2019-09-29 17:22:30,585 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000357-0000000000000000358 expecting start txid #357
2019-09-29 17:22:30,585 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000357-0000000000000000358
2019-09-29 17:22:30,585 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000357-0000000000000000358 of size 42 edits # 2 loaded in 0 seconds
2019-09-29 17:22:30,590 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000358 using no compression
2019-09-29 17:22:30,636 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000358 of size 1707 bytes saved in 0 seconds.
2019-09-29 17:22:30,641 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 355
2019-09-29 17:22:30,641 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000353, cpktTxId=0000000000000000353)
2019-09-29 17:22:30,725 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 358 to namenode at http://um1:50070 in 0.064 seconds
2019-09-29 17:22:30,725 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1707
2019-09-29 17:32:30,836 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-29 17:32:30,837 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=359&endTxId=360&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-29 17:32:30,844 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-29 17:32:30,844 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000359-0000000000000000360_0000000000005417224 size 0 bytes.
2019-09-29 17:32:30,844 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-29 17:32:30,844 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000359-0000000000000000360 expecting start txid #359
2019-09-29 17:32:30,844 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000359-0000000000000000360
2019-09-29 17:32:30,844 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000359-0000000000000000360 of size 42 edits # 2 loaded in 0 seconds
2019-09-29 17:32:30,845 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000360 using no compression
2019-09-29 17:32:30,850 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000360 of size 1707 bytes saved in 0 seconds.
2019-09-29 17:32:30,855 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 358
2019-09-29 17:32:30,855 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000355, cpktTxId=0000000000000000355)
2019-09-29 17:32:30,881 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 360 to namenode at http://um1:50070 in 0.016 seconds
2019-09-29 17:32:30,881 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1707
2019-09-29 17:42:31,066 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-09-29 17:42:31,067 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=361&endTxId=370&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-29 17:42:31,086 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-29 17:42:31,086 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000361-0000000000000000370_0000000000006017454 size 0 bytes.
2019-09-29 17:42:31,087 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-09-29 17:42:31,087 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000361-0000000000000000370 expecting start txid #361
2019-09-29 17:42:31,087 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000361-0000000000000000370
2019-09-29 17:42:31,123 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000361-0000000000000000370 of size 638 edits # 10 loaded in 0 seconds
2019-09-29 17:42:31,125 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000370 using no compression
2019-09-29 17:42:31,135 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000370 of size 1765 bytes saved in 0 seconds.
2019-09-29 17:42:31,138 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 360
2019-09-29 17:42:31,138 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000358, cpktTxId=0000000000000000358)
2019-09-29 17:42:31,166 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 370 to namenode at http://um1:50070 in 0.013 seconds
2019-09-29 17:42:31,166 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1765
2019-09-29 17:45:02,530 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2019-09-29 17:45:02,536 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.182.5
************************************************************/
2019-09-29 17:45:31,032 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.182.5
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-09-29 17:45:31,046 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-29 17:45:31,811 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-29 17:45:31,917 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-09-29 17:45:31,917 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-09-29 17:45:32,040 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-29 17:45:32,041 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-09-29 17:45:32,090 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 10890@um2
2019-09-29 17:45:32,139 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 10890@um2
2019-09-29 17:45:32,152 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-09-29 17:45:32,160 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-09-29 17:45:32,202 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-09-29 17:45:32,202 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-29 17:45:32,204 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-29 17:45:32,206 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Sep 29 17:45:32
2019-09-29 17:45:32,208 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-09-29 17:45:32,208 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-29 17:45:32,209 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-09-29 17:45:32,210 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-09-29 17:45:32,223 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-09-29 17:45:32,224 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-09-29 17:45:32,224 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-09-29 17:45:32,224 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-09-29 17:45:32,224 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-09-29 17:45:32,224 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-09-29 17:45:32,224 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-09-29 17:45:32,224 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-09-29 17:45:32,225 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-09-29 17:45:32,225 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-09-29 17:45:32,225 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-09-29 17:45:32,225 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-09-29 17:45:32,228 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-09-29 17:45:32,630 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-09-29 17:45:32,630 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-29 17:45:32,631 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-09-29 17:45:32,631 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-09-29 17:45:32,631 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-09-29 17:45:32,638 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-09-29 17:45:32,638 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-09-29 17:45:32,638 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-09-29 17:45:32,638 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-09-29 17:45:32,640 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-29 17:45:32,640 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-09-29 17:45:32,640 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-09-29 17:45:32,641 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-09-29 17:45:32,642 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-09-29 17:45:32,642 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-09-29 17:45:32,652 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-09-29 17:45:32,703 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-29 17:45:32,707 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-09-29 17:45:32,726 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-29 17:45:32,736 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-09-29 17:45:32,736 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-29 17:45:32,737 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-29 17:45:32,782 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-09-29 17:45:32,782 INFO org.mortbay.log: jetty-6.1.26
2019-09-29 17:45:33,002 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-09-29 17:45:33,002 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-09-29 17:45:33,003 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-09-29 17:45:33,003 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-09-29 17:46:33,257 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-09-29 17:46:33,391 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=370&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-29 17:46:33,427 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-09-29 17:46:33,600 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 125.00 KB/s
2019-09-29 17:46:33,601 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000370 size 1765 bytes.
2019-09-29 17:46:33,606 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=371&endTxId=371&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-29 17:46:33,625 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 68266.67 KB/s
2019-09-29 17:46:33,625 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000371-0000000000000000371_0000000000006259994 size 0 bytes.
2019-09-29 17:46:33,626 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=372&endTxId=373&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-09-29 17:46:33,634 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-09-29 17:46:33,634 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000372-0000000000000000373_0000000000006260014 size 0 bytes.
2019-09-29 17:46:33,676 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 22 INodes.
2019-09-29 17:46:33,703 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-09-29 17:46:33,704 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 370 from /orgz/snnfsi/current/fsimage_0000000000000000370
2019-09-29 17:46:33,704 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-09-29 17:46:33,710 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2019-09-29 17:46:33,713 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000371-0000000000000000371 expecting start txid #371
2019-09-29 17:46:33,713 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000371-0000000000000000371
2019-09-29 17:46:33,728 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000371-0000000000000000371 of size 1048576 edits # 1 loaded in 0 seconds
2019-09-29 17:46:33,729 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000372-0000000000000000373 expecting start txid #372
2019-09-29 17:46:33,729 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000372-0000000000000000373
2019-09-29 17:46:33,729 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000372-0000000000000000373 of size 42 edits # 2 loaded in 0 seconds
2019-09-29 17:46:33,733 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000373 using no compression
2019-09-29 17:46:33,780 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000373 of size 1765 bytes saved in 0 seconds.
2019-09-29 17:46:33,785 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 370
2019-09-29 17:46:33,785 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000360, cpktTxId=0000000000000000360)
2019-09-29 17:46:33,842 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 373 to namenode at http://um1:50070 in 0.029 seconds
2019-09-29 17:46:33,842 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1765
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         2019-10-09 21:36:33,989 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.182.5
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-10-09 21:36:34,003 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-10-09 21:36:34,590 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-10-09 21:36:34,671 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-10-09 21:36:34,671 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-10-09 21:36:34,779 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-09 21:36:34,779 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-09 21:36:34,862 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 20032@um2
2019-10-09 21:36:34,911 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 20032@um2
2019-10-09 21:36:34,920 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-10-09 21:36:34,930 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-10-09 21:36:35,011 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-10-09 21:36:35,011 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-10-09 21:36:35,016 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-10-09 21:36:35,020 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Oct 09 21:36:35
2019-10-09 21:36:35,023 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-10-09 21:36:35,023 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-09 21:36:35,025 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-10-09 21:36:35,026 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-10-09 21:36:35,042 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-10-09 21:36:35,043 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-10-09 21:36:35,043 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-10-09 21:36:35,043 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-10-09 21:36:35,043 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-10-09 21:36:35,043 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-10-09 21:36:35,043 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-10-09 21:36:35,043 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-10-09 21:36:35,045 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-10-09 21:36:35,045 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-10-09 21:36:35,046 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-10-09 21:36:35,046 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-10-09 21:36:35,048 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-10-09 21:36:35,389 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-10-09 21:36:35,389 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-09 21:36:35,389 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-10-09 21:36:35,389 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-10-09 21:36:35,390 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-10-09 21:36:35,399 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-10-09 21:36:35,399 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-09 21:36:35,399 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-10-09 21:36:35,399 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-10-09 21:36:35,400 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-10-09 21:36:35,400 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-10-09 21:36:35,400 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-10-09 21:36:35,402 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-10-09 21:36:35,402 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-10-09 21:36:35,402 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-10-09 21:36:35,411 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-10-09 21:36:35,451 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-10-09 21:36:35,454 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-10-09 21:36:35,466 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-09 21:36:35,470 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-10-09 21:36:35,471 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-09 21:36:35,472 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-09 21:36:35,485 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-10-09 21:36:35,485 INFO org.mortbay.log: jetty-6.1.26
2019-10-09 21:36:35,681 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-10-09 21:36:35,681 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-10-09 21:36:35,682 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-10-09 21:36:35,682 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-10-09 21:37:35,896 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-10-09 21:37:36,053 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=376&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-10-09 21:37:36,102 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-10-09 21:37:36,462 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 200.00 KB/s
2019-10-09 21:37:36,463 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000376 size 1765 bytes.
2019-10-09 21:37:36,470 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=377&endTxId=383&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-10-09 21:37:36,476 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-10-09 21:37:36,477 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000377-0000000000000000383_0000000000002588264 size 0 bytes.
2019-10-09 21:37:36,521 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 22 INodes.
2019-10-09 21:37:36,550 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-10-09 21:37:36,550 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 376 from /orgz/snnfsi/current/fsimage_0000000000000000376
2019-10-09 21:37:36,551 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-10-09 21:37:36,557 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-09 21:37:36,561 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000377-0000000000000000383 expecting start txid #377
2019-10-09 21:37:36,561 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000377-0000000000000000383
2019-10-09 21:37:36,591 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000377-0000000000000000383 of size 507 edits # 7 loaded in 0 seconds
2019-10-09 21:37:36,596 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000383 using no compression
2019-10-09 21:37:36,642 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000383 of size 2113 bytes saved in 0 seconds.
2019-10-09 21:37:36,656 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 376
2019-10-09 21:37:36,656 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000375, cpktTxId=0000000000000000375)
2019-10-09 21:37:36,658 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000373, cpktTxId=0000000000000000373)
2019-10-09 21:37:36,722 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 383 to namenode at http://um1:50070 in 0.032 seconds
2019-10-09 21:37:36,723 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2113
2019-10-09 21:47:36,863 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-09 21:47:36,863 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=384&endTxId=547&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-10-09 21:47:36,869 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 11500.00 KB/s
2019-10-09 21:47:36,869 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000384-0000000000000000547_0000000000003188658 size 0 bytes.
2019-10-09 21:47:36,869 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-09 21:47:36,869 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000384-0000000000000000547 expecting start txid #384
2019-10-09 21:47:36,869 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000384-0000000000000000547
2019-10-09 21:47:36,908 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000384-0000000000000000547 of size 23608 edits # 164 loaded in 0 seconds
2019-10-09 21:47:36,910 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000547 using no compression
2019-10-09 21:47:36,915 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000547 of size 3266 bytes saved in 0 seconds.
2019-10-09 21:47:36,922 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 383
2019-10-09 21:47:36,922 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000376, cpktTxId=0000000000000000376)
2019-10-09 21:47:36,941 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 547 to namenode at http://um1:50070 in 0.012 seconds
2019-10-09 21:47:36,942 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 3266
2019-10-09 21:57:37,098 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-09 21:57:37,098 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=548&endTxId=549&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-10-09 21:57:37,103 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-10-09 21:57:37,104 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000548-0000000000000000549_0000000000003788894 size 0 bytes.
2019-10-09 21:57:37,104 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-09 21:57:37,104 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000548-0000000000000000549 expecting start txid #548
2019-10-09 21:57:37,104 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000548-0000000000000000549
2019-10-09 21:57:37,104 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000548-0000000000000000549 of size 42 edits # 2 loaded in 0 seconds
2019-10-09 21:57:37,106 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000549 using no compression
2019-10-09 21:57:37,115 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000549 of size 3266 bytes saved in 0 seconds.
2019-10-09 21:57:37,118 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 547
2019-10-09 21:57:37,118 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000383, cpktTxId=0000000000000000383)
2019-10-09 21:57:37,137 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 549 to namenode at http://um1:50070 in 0.013 seconds
2019-10-09 21:57:37,137 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 3266
2019-10-09 22:07:37,279 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-09 22:07:37,279 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=550&endTxId=551&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-10-09 22:07:37,285 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-10-09 22:07:37,285 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000550-0000000000000000551_0000000000004389074 size 0 bytes.
2019-10-09 22:07:37,285 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-09 22:07:37,285 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000550-0000000000000000551 expecting start txid #550
2019-10-09 22:07:37,285 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000550-0000000000000000551
2019-10-09 22:07:37,285 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000550-0000000000000000551 of size 42 edits # 2 loaded in 0 seconds
2019-10-09 22:07:37,286 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000551 using no compression
2019-10-09 22:07:37,303 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000551 of size 3266 bytes saved in 0 seconds.
2019-10-09 22:07:37,307 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 549
2019-10-09 22:07:37,307 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000547, cpktTxId=0000000000000000547)
2019-10-09 22:07:37,322 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 551 to namenode at http://um1:50070 in 0.011 seconds
2019-10-09 22:07:37,323 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 3266
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        2019-10-13 17:29:00,973 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.182.5
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-10-13 17:29:00,988 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-10-13 17:29:01,614 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-10-13 17:29:01,716 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-10-13 17:29:01,716 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-10-13 17:29:01,862 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-13 17:29:01,862 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-13 17:29:01,979 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 2889@um2
2019-10-13 17:29:02,056 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 2889@um2
2019-10-13 17:29:02,079 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-10-13 17:29:02,088 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-10-13 17:29:02,137 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-10-13 17:29:02,137 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-10-13 17:29:02,139 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-10-13 17:29:02,140 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Oct 13 17:29:02
2019-10-13 17:29:02,142 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-10-13 17:29:02,142 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-13 17:29:02,143 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-10-13 17:29:02,143 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-10-13 17:29:02,168 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-10-13 17:29:02,169 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-10-13 17:29:02,169 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-10-13 17:29:02,169 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-10-13 17:29:02,169 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-10-13 17:29:02,169 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-10-13 17:29:02,169 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-10-13 17:29:02,169 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-10-13 17:29:02,169 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-10-13 17:29:02,170 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-10-13 17:29:02,170 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-10-13 17:29:02,170 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-10-13 17:29:02,172 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-10-13 17:29:02,594 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-10-13 17:29:02,594 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-13 17:29:02,595 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-10-13 17:29:02,595 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-10-13 17:29:02,595 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-10-13 17:29:02,603 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-10-13 17:29:02,603 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-13 17:29:02,603 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-10-13 17:29:02,603 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-10-13 17:29:02,605 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-10-13 17:29:02,605 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-10-13 17:29:02,611 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-10-13 17:29:02,613 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-10-13 17:29:02,613 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-10-13 17:29:02,613 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-10-13 17:29:02,623 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-10-13 17:29:02,676 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-10-13 17:29:02,680 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-10-13 17:29:02,691 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-13 17:29:02,694 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-10-13 17:29:02,695 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-13 17:29:02,696 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-13 17:29:02,712 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-10-13 17:29:02,712 INFO org.mortbay.log: jetty-6.1.26
2019-10-13 17:29:02,947 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-10-13 17:29:02,947 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-10-13 17:29:02,947 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-10-13 17:29:02,947 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-10-13 17:38:03,248 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-10-13 17:38:03,434 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=554&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-10-13 17:38:03,482 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-10-13 17:38:03,804 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 375.00 KB/s
2019-10-13 17:38:03,805 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000554 size 3266 bytes.
2019-10-13 17:38:03,812 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=555&endTxId=561&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-10-13 17:38:03,818 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-10-13 17:38:03,818 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000555-0000000000000000561_0000000000000637661 size 0 bytes.
2019-10-13 17:38:03,905 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 42 INodes.
2019-10-13 17:38:03,942 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-10-13 17:38:03,942 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 554 from /orgz/snnfsi/current/fsimage_0000000000000000554
2019-10-13 17:38:03,942 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-10-13 17:38:03,950 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-13 17:38:03,953 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000555-0000000000000000561 expecting start txid #555
2019-10-13 17:38:03,953 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000555-0000000000000000561
2019-10-13 17:38:03,989 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000555-0000000000000000561 of size 533 edits # 7 loaded in 0 seconds
2019-10-13 17:38:03,993 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000561 using no compression
2019-10-13 17:38:04,045 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000561 of size 3328 bytes saved in 0 seconds.
2019-10-13 17:38:04,061 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 554
2019-10-13 17:38:04,061 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000553, cpktTxId=0000000000000000553)
2019-10-13 17:38:04,062 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000551, cpktTxId=0000000000000000551)
2019-10-13 17:38:04,149 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 561 to namenode at http://um1:50070 in 0.038 seconds
2019-10-13 17:38:04,149 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 3328
2019-10-13 17:48:04,325 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-13 17:48:04,326 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=562&endTxId=570&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-10-13 17:48:04,333 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-10-13 17:48:04,333 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000562-0000000000000000570_0000000000001238175 size 0 bytes.
2019-10-13 17:48:04,333 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-13 17:48:04,334 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000562-0000000000000000570 expecting start txid #562
2019-10-13 17:48:04,334 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000562-0000000000000000570
2019-10-13 17:48:04,335 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000562-0000000000000000570 of size 873 edits # 9 loaded in 0 seconds
2019-10-13 17:48:04,337 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000570 using no compression
2019-10-13 17:48:04,349 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000570 of size 3655 bytes saved in 0 seconds.
2019-10-13 17:48:04,358 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 561
2019-10-13 17:48:04,358 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000554, cpktTxId=0000000000000000554)
2019-10-13 17:48:04,392 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 570 to namenode at http://um1:50070 in 0.017 seconds
2019-10-13 17:48:04,392 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 3655
2019-10-19 06:54:00,330 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.182.5
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-10-19 06:54:00,349 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-10-19 06:54:01,769 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-10-19 06:54:01,962 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-10-19 06:54:01,962 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-10-19 06:54:02,250 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-19 06:54:02,250 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-10-19 06:54:02,362 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 5016@um2
2019-10-19 06:54:02,487 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 5016@um2
2019-10-19 06:54:02,581 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-10-19 06:54:02,605 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-10-19 06:54:02,690 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-10-19 06:54:02,690 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-10-19 06:54:02,691 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-10-19 06:54:02,693 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Oct 19 06:54:02
2019-10-19 06:54:02,700 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-10-19 06:54:02,700 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-19 06:54:02,702 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-10-19 06:54:02,703 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-10-19 06:54:02,753 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-10-19 06:54:02,769 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-10-19 06:54:02,769 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-10-19 06:54:02,769 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-10-19 06:54:02,769 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-10-19 06:54:02,769 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-10-19 06:54:02,769 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-10-19 06:54:02,769 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-10-19 06:54:02,770 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-10-19 06:54:02,770 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-10-19 06:54:02,770 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-10-19 06:54:02,770 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-10-19 06:54:02,772 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-10-19 06:54:03,353 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-10-19 06:54:03,353 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-19 06:54:03,353 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-10-19 06:54:03,353 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-10-19 06:54:03,354 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-10-19 06:54:03,376 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-10-19 06:54:03,376 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-10-19 06:54:03,376 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-10-19 06:54:03,376 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-10-19 06:54:03,377 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-10-19 06:54:03,377 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-10-19 06:54:03,378 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-10-19 06:54:03,379 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-10-19 06:54:03,379 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-10-19 06:54:03,379 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-10-19 06:54:03,400 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-10-19 06:54:03,506 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-10-19 06:54:03,510 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-10-19 06:54:03,528 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-10-19 06:54:03,536 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-10-19 06:54:03,536 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-10-19 06:54:03,536 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-10-19 06:54:03,559 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-10-19 06:54:03,559 INFO org.mortbay.log: jetty-6.1.26
2019-10-19 06:54:03,872 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-10-19 06:54:03,872 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-10-19 06:54:03,874 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-10-19 06:54:03,874 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-10-19 06:55:04,114 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-10-19 06:55:04,264 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=572&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-10-19 06:55:04,321 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-10-19 06:55:04,598 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 500.00 KB/s
2019-10-19 06:55:04,600 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000572 size 3495 bytes.
2019-10-19 06:55:04,612 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=573&endTxId=576&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-10-19 06:55:04,618 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-10-19 06:55:04,618 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000573-0000000000000000576_0000000000004843614 size 0 bytes.
2019-10-19 06:55:04,663 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 45 INodes.
2019-10-19 06:55:04,692 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-10-19 06:55:04,692 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 572 from /orgz/snnfsi/current/fsimage_0000000000000000572
2019-10-19 06:55:04,692 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-10-19 06:55:04,696 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-19 06:55:04,700 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000573-0000000000000000576 expecting start txid #573
2019-10-19 06:55:04,700 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000573-0000000000000000576
2019-10-19 06:55:04,735 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000573-0000000000000000576 of size 286 edits # 4 loaded in 0 seconds
2019-10-19 06:55:04,741 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000576 using no compression
2019-10-19 06:55:04,789 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000576 of size 3655 bytes saved in 0 seconds.
2019-10-19 06:55:04,806 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 572
2019-10-19 06:55:04,806 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000561, cpktTxId=0000000000000000561)
2019-10-19 06:55:04,808 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000570, cpktTxId=0000000000000000570)
2019-10-19 06:55:04,876 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 576 to namenode at http://um1:50070 in 0.03 seconds
2019-10-19 06:55:04,877 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 3655
2019-10-19 07:05:05,034 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-19 07:05:05,035 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=577&endTxId=644&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-10-19 07:05:05,041 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 3000.00 KB/s
2019-10-19 07:05:05,041 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000577-0000000000000000644_0000000000005444039 size 0 bytes.
2019-10-19 07:05:05,042 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-19 07:05:05,042 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000577-0000000000000000644 expecting start txid #577
2019-10-19 07:05:05,042 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000577-0000000000000000644
2019-10-19 07:05:05,101 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000577-0000000000000000644 of size 9429 edits # 68 loaded in 0 seconds
2019-10-19 07:05:05,102 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000644 using no compression
2019-10-19 07:05:05,108 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000644 of size 3865 bytes saved in 0 seconds.
2019-10-19 07:05:05,112 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 576
2019-10-19 07:05:05,112 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000572, cpktTxId=0000000000000000572)
2019-10-19 07:05:05,161 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 644 to namenode at http://um1:50070 in 0.037 seconds
2019-10-19 07:05:05,163 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 3865
2019-10-19 07:15:05,268 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-19 07:15:05,268 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=645&endTxId=648&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-10-19 07:15:05,277 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-10-19 07:15:05,277 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000645-0000000000000000648_0000000000006044272 size 0 bytes.
2019-10-19 07:15:05,277 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-19 07:15:05,277 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000645-0000000000000000648 expecting start txid #645
2019-10-19 07:15:05,277 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000645-0000000000000000648
2019-10-19 07:15:05,278 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000645-0000000000000000648 of size 286 edits # 4 loaded in 0 seconds
2019-10-19 07:15:05,279 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000648 using no compression
2019-10-19 07:15:05,285 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000648 of size 4025 bytes saved in 0 seconds.
2019-10-19 07:15:05,288 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 644
2019-10-19 07:15:05,288 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000576, cpktTxId=0000000000000000576)
2019-10-19 07:15:05,316 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 648 to namenode at http://um1:50070 in 0.021 seconds
2019-10-19 07:15:05,316 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4025
2019-10-19 07:25:05,430 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-19 07:25:05,430 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=649&endTxId=650&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-10-19 07:25:05,437 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-10-19 07:25:05,437 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000649-0000000000000000650_0000000000006644434 size 0 bytes.
2019-10-19 07:25:05,437 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-19 07:25:05,437 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000649-0000000000000000650 expecting start txid #649
2019-10-19 07:25:05,437 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000649-0000000000000000650
2019-10-19 07:25:05,437 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000649-0000000000000000650 of size 42 edits # 2 loaded in 0 seconds
2019-10-19 07:25:05,438 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000650 using no compression
2019-10-19 07:25:05,443 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000650 of size 4025 bytes saved in 0 seconds.
2019-10-19 07:25:05,446 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 648
2019-10-19 07:25:05,446 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000644, cpktTxId=0000000000000000644)
2019-10-19 07:25:05,471 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 650 to namenode at http://um1:50070 in 0.016 seconds
2019-10-19 07:25:05,471 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4025
2019-10-19 07:35:05,595 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-19 07:35:05,595 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=651&endTxId=652&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-10-19 07:35:05,602 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-10-19 07:35:05,602 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000651-0000000000000000652_0000000000007244599 size 0 bytes.
2019-10-19 07:35:05,602 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-19 07:35:05,602 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000651-0000000000000000652 expecting start txid #651
2019-10-19 07:35:05,603 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000651-0000000000000000652
2019-10-19 07:35:05,603 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000651-0000000000000000652 of size 42 edits # 2 loaded in 0 seconds
2019-10-19 07:35:05,604 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000652 using no compression
2019-10-19 07:35:05,609 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000652 of size 4025 bytes saved in 0 seconds.
2019-10-19 07:35:05,613 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 650
2019-10-19 07:35:05,613 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000648, cpktTxId=0000000000000000648)
2019-10-19 07:35:05,643 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 652 to namenode at http://um1:50070 in 0.019 seconds
2019-10-19 07:35:05,644 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4025
2019-10-19 07:45:05,779 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-19 07:45:05,779 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=653&endTxId=722&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-10-19 07:45:05,786 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 2333.33 KB/s
2019-10-19 07:45:05,786 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000653-0000000000000000722_0000000000007844783 size 0 bytes.
2019-10-19 07:45:05,786 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-19 07:45:05,786 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000653-0000000000000000722 expecting start txid #653
2019-10-19 07:45:05,786 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000653-0000000000000000722
2019-10-19 07:45:05,798 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000653-0000000000000000722 of size 7748 edits # 70 loaded in 0 seconds
2019-10-19 07:45:05,799 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000722 using no compression
2019-10-19 07:45:05,804 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000722 of size 4924 bytes saved in 0 seconds.
2019-10-19 07:45:05,809 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 652
2019-10-19 07:45:05,809 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000650, cpktTxId=0000000000000000650)
2019-10-19 07:45:05,836 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 722 to namenode at http://um1:50070 in 0.023 seconds
2019-10-19 07:45:05,836 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4924
2019-10-19 07:55:06,052 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-19 07:55:06,052 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=723&endTxId=724&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-10-19 07:55:06,058 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-10-19 07:55:06,058 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000723-0000000000000000724_0000000000008445056 size 0 bytes.
2019-10-19 07:55:06,058 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-19 07:55:06,058 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000723-0000000000000000724 expecting start txid #723
2019-10-19 07:55:06,059 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000723-0000000000000000724
2019-10-19 07:55:06,059 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000723-0000000000000000724 of size 42 edits # 2 loaded in 0 seconds
2019-10-19 07:55:06,059 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000724 using no compression
2019-10-19 07:55:06,064 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000724 of size 4924 bytes saved in 0 seconds.
2019-10-19 07:55:06,066 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 722
2019-10-19 07:55:06,066 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000652, cpktTxId=0000000000000000652)
2019-10-19 07:55:06,094 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 724 to namenode at http://um1:50070 in 0.02 seconds
2019-10-19 07:55:06,095 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4924
2019-10-19 08:05:06,221 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-19 08:05:06,222 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=725&endTxId=755&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-10-19 08:05:06,228 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1333.33 KB/s
2019-10-19 08:05:06,228 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000725-0000000000000000755_0000000000009045226 size 0 bytes.
2019-10-19 08:05:06,228 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-19 08:05:06,228 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000725-0000000000000000755 expecting start txid #725
2019-10-19 08:05:06,228 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000725-0000000000000000755
2019-10-19 08:05:06,239 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000725-0000000000000000755 of size 4776 edits # 31 loaded in 0 seconds
2019-10-19 08:05:06,240 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000755 using no compression
2019-10-19 08:05:06,248 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000755 of size 5170 bytes saved in 0 seconds.
2019-10-19 08:05:06,250 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 724
2019-10-19 08:05:06,250 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000722, cpktTxId=0000000000000000722)
2019-10-19 08:05:06,271 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 755 to namenode at http://um1:50070 in 0.012 seconds
2019-10-19 08:05:06,271 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5170
2019-10-19 08:15:06,383 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-19 08:15:06,383 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=756&endTxId=780&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-10-19 08:15:06,390 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 750.00 KB/s
2019-10-19 08:15:06,390 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000756-0000000000000000780_0000000000009645387 size 0 bytes.
2019-10-19 08:15:06,390 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-19 08:15:06,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000756-0000000000000000780 expecting start txid #756
2019-10-19 08:15:06,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000756-0000000000000000780
2019-10-19 08:15:06,393 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000756-0000000000000000780 of size 3515 edits # 25 loaded in 0 seconds
2019-10-19 08:15:06,394 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000780 using no compression
2019-10-19 08:15:06,402 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000780 of size 5170 bytes saved in 0 seconds.
2019-10-19 08:15:06,404 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 755
2019-10-19 08:15:06,404 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000724, cpktTxId=0000000000000000724)
2019-10-19 08:15:06,430 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 780 to namenode at http://um1:50070 in 0.018 seconds
2019-10-19 08:15:06,430 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5170
2019-10-19 08:25:06,567 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-19 08:25:06,567 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=781&endTxId=2234&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-10-19 08:25:06,578 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 41500.00 KB/s
2019-10-19 08:25:06,578 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000781-0000000000000002234_0000000000010245572 size 0 bytes.
2019-10-19 08:25:06,578 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-19 08:25:06,578 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000781-0000000000000002234 expecting start txid #781
2019-10-19 08:25:06,578 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000781-0000000000000002234
2019-10-19 08:25:06,681 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000781-0000000000000002234 of size 255251 edits # 1454 loaded in 0 seconds
2019-10-19 08:25:06,682 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002234 using no compression
2019-10-19 08:25:06,697 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002234 of size 46016 bytes saved in 0 seconds.
2019-10-19 08:25:06,700 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 780
2019-10-19 08:25:06,700 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000755, cpktTxId=0000000000000000755)
2019-10-19 08:25:06,732 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2234 to namenode at http://um1:50070 in 0.015 seconds
2019-10-19 08:25:06,732 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46016
2019-10-19 08:35:06,809 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-19 08:35:06,809 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2235&endTxId=2236&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-10-19 08:35:06,815 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-10-19 08:35:06,815 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002235-0000000000000002236_0000000000010845813 size 0 bytes.
2019-10-19 08:35:06,815 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-19 08:35:06,815 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002235-0000000000000002236 expecting start txid #2235
2019-10-19 08:35:06,815 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002235-0000000000000002236
2019-10-19 08:35:06,815 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002235-0000000000000002236 of size 42 edits # 2 loaded in 0 seconds
2019-10-19 08:35:06,822 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002236 using no compression
2019-10-19 08:35:06,847 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002236 of size 46016 bytes saved in 0 seconds.
2019-10-19 08:35:06,850 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2234
2019-10-19 08:35:06,850 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000780, cpktTxId=0000000000000000780)
2019-10-19 08:35:06,864 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2236 to namenode at http://um1:50070 in 0.01 seconds
2019-10-19 08:35:06,864 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46016
2019-10-19 08:45:06,967 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-19 08:45:06,968 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2237&endTxId=2238&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-10-19 08:45:06,975 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-10-19 08:45:06,975 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002237-0000000000000002238_0000000000011445972 size 0 bytes.
2019-10-19 08:45:06,975 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-19 08:45:06,975 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002237-0000000000000002238 expecting start txid #2237
2019-10-19 08:45:06,975 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002237-0000000000000002238
2019-10-19 08:45:06,976 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002237-0000000000000002238 of size 42 edits # 2 loaded in 0 seconds
2019-10-19 08:45:06,976 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002238 using no compression
2019-10-19 08:45:06,993 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002238 of size 46016 bytes saved in 0 seconds.
2019-10-19 08:45:06,995 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2236
2019-10-19 08:45:06,996 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002234, cpktTxId=0000000000000002234)
2019-10-19 08:45:07,010 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2238 to namenode at http://um1:50070 in 0.01 seconds
2019-10-19 08:45:07,010 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46016
2019-10-19 08:55:07,132 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-19 08:55:07,132 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2239&endTxId=2240&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-10-19 08:55:07,137 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-10-19 08:55:07,137 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002239-0000000000000002240_0000000000012046136 size 0 bytes.
2019-10-19 08:55:07,137 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-19 08:55:07,137 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002239-0000000000000002240 expecting start txid #2239
2019-10-19 08:55:07,137 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002239-0000000000000002240
2019-10-19 08:55:07,137 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002239-0000000000000002240 of size 42 edits # 2 loaded in 0 seconds
2019-10-19 08:55:07,144 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002240 using no compression
2019-10-19 08:55:07,152 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002240 of size 46016 bytes saved in 0 seconds.
2019-10-19 08:55:07,155 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2238
2019-10-19 08:55:07,155 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002236, cpktTxId=0000000000000002236)
2019-10-19 08:55:07,183 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2240 to namenode at http://um1:50070 in 0.009 seconds
2019-10-19 08:55:07,183 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46016
2019-10-19 09:05:07,291 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-19 09:05:07,291 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2241&endTxId=2242&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-10-19 09:05:07,301 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-10-19 09:05:07,301 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002241-0000000000000002242_0000000000012646295 size 0 bytes.
2019-10-19 09:05:07,302 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-19 09:05:07,302 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002241-0000000000000002242 expecting start txid #2241
2019-10-19 09:05:07,302 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002241-0000000000000002242
2019-10-19 09:05:07,302 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002241-0000000000000002242 of size 42 edits # 2 loaded in 0 seconds
2019-10-19 09:05:07,302 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002242 using no compression
2019-10-19 09:05:07,309 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002242 of size 46016 bytes saved in 0 seconds.
2019-10-19 09:05:07,318 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2240
2019-10-19 09:05:07,318 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002238, cpktTxId=0000000000000002238)
2019-10-19 09:05:07,346 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2242 to namenode at http://um1:50070 in 0.016 seconds
2019-10-19 09:05:07,346 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46016
2019-10-19 09:15:07,482 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-19 09:15:07,483 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2243&endTxId=2244&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-10-19 09:15:07,489 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-10-19 09:15:07,489 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002243-0000000000000002244_0000000000013246487 size 0 bytes.
2019-10-19 09:15:07,490 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-19 09:15:07,490 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002243-0000000000000002244 expecting start txid #2243
2019-10-19 09:15:07,490 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002243-0000000000000002244
2019-10-19 09:15:07,490 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002243-0000000000000002244 of size 42 edits # 2 loaded in 0 seconds
2019-10-19 09:15:07,491 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002244 using no compression
2019-10-19 09:15:07,503 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002244 of size 46016 bytes saved in 0 seconds.
2019-10-19 09:15:07,509 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2242
2019-10-19 09:15:07,510 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002240, cpktTxId=0000000000000002240)
2019-10-19 09:15:07,528 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2244 to namenode at http://um1:50070 in 0.014 seconds
2019-10-19 09:15:07,528 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46016
2019-10-19 09:25:07,686 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-19 09:25:07,686 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2245&endTxId=2247&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-10-19 09:25:07,696 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-10-19 09:25:07,696 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002245-0000000000000002247_0000000000013846691 size 0 bytes.
2019-10-19 09:25:07,696 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-19 09:25:07,696 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002245-0000000000000002247 expecting start txid #2245
2019-10-19 09:25:07,696 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002245-0000000000000002247
2019-10-19 09:25:07,696 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002245-0000000000000002247 of size 141 edits # 3 loaded in 0 seconds
2019-10-19 09:25:07,697 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002247 using no compression
2019-10-19 09:25:07,701 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002247 of size 45856 bytes saved in 0 seconds.
2019-10-19 09:25:07,703 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2244
2019-10-19 09:25:07,703 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002242, cpktTxId=0000000000000002242)
2019-10-19 09:25:07,719 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2247 to namenode at http://um1:50070 in 0.011 seconds
2019-10-19 09:25:07,719 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 45856
2019-10-19 09:35:07,815 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-10-19 09:35:07,815 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2248&endTxId=2249&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-10-19 09:35:07,832 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-10-19 09:35:07,832 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002248-0000000000000002249_0000000000014446819 size 0 bytes.
2019-10-19 09:35:07,832 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-10-19 09:35:07,832 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002248-0000000000000002249 expecting start txid #2248
2019-10-19 09:35:07,832 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002248-0000000000000002249
2019-10-19 09:35:07,832 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002248-0000000000000002249 of size 42 edits # 2 loaded in 0 seconds
2019-10-19 09:35:07,836 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002249 using no compression
2019-10-19 09:35:07,842 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002249 of size 45856 bytes saved in 0 seconds.
2019-10-19 09:35:07,853 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2247
2019-10-19 09:35:07,853 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002244, cpktTxId=0000000000000002244)
2019-10-19 09:35:07,898 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2249 to namenode at http://um1:50070 in 0.04 seconds
2019-10-19 09:35:07,898 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 45856
2019-11-02 05:14:20,889 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.251.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-11-02 05:14:20,902 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-11-02 05:14:21,515 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-11-02 05:14:21,620 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-11-02 05:14:21,620 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-11-02 05:14:21,743 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-11-02 05:14:21,744 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-11-02 05:14:21,819 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 629@um2
2019-11-02 05:14:21,886 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 629@um2
2019-11-02 05:14:21,913 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-11-02 05:14:21,921 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-11-02 05:14:21,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-11-02 05:14:21,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-11-02 05:14:21,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-11-02 05:14:21,975 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Nov 02 05:14:21
2019-11-02 05:14:21,976 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-11-02 05:14:21,977 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-11-02 05:14:21,977 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-11-02 05:14:21,978 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-11-02 05:14:22,021 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-11-02 05:14:22,022 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-11-02 05:14:22,022 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-11-02 05:14:22,022 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-11-02 05:14:22,022 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-11-02 05:14:22,022 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-11-02 05:14:22,022 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-11-02 05:14:22,022 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-11-02 05:14:22,023 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-11-02 05:14:22,023 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-11-02 05:14:22,023 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-11-02 05:14:22,023 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-11-02 05:14:22,025 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-11-02 05:14:22,531 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-11-02 05:14:22,531 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-11-02 05:14:22,531 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-11-02 05:14:22,532 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-11-02 05:14:22,532 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-11-02 05:14:22,539 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-11-02 05:14:22,539 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-11-02 05:14:22,540 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-11-02 05:14:22,540 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-11-02 05:14:22,542 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-11-02 05:14:22,542 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-11-02 05:14:22,542 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-11-02 05:14:22,544 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-11-02 05:14:22,544 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-11-02 05:14:22,544 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-11-02 05:14:22,553 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-11-02 05:14:22,609 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-11-02 05:14:22,612 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-11-02 05:14:22,621 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-02 05:14:22,623 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-11-02 05:14:22,624 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-02 05:14:22,624 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-02 05:14:22,641 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-11-02 05:14:22,641 INFO org.mortbay.log: jetty-6.1.26
2019-11-02 05:14:22,844 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-11-02 05:14:22,844 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-11-02 05:14:22,844 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-11-02 05:14:22,844 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-11-02 05:15:23,174 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-11-02 05:15:23,371 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=2250&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 05:15:23,420 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-11-02 05:15:23,779 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 2933.33 KB/s
2019-11-02 05:15:23,780 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000002250 size 45856 bytes.
2019-11-02 05:15:23,788 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2251&endTxId=2252&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 05:15:23,793 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 05:15:23,793 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002251-0000000000000002252_0000000000001163615 size 0 bytes.
2019-11-02 05:15:23,847 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 475 INodes.
2019-11-02 05:15:23,926 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-11-02 05:15:23,926 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 2250 from /orgz/snnfsi/current/fsimage_0000000000000002250
2019-11-02 05:15:23,926 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 1 entries 205 lookups
2019-11-02 05:15:23,931 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 05:15:23,935 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002251-0000000000000002252 expecting start txid #2251
2019-11-02 05:15:23,936 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002251-0000000000000002252
2019-11-02 05:15:23,952 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002251-0000000000000002252 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 05:15:23,961 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002252 using no compression
2019-11-02 05:15:24,029 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002252 of size 45856 bytes saved in 0 seconds.
2019-11-02 05:15:24,042 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2250
2019-11-02 05:15:24,042 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002247, cpktTxId=0000000000000002247)
2019-11-02 05:15:24,042 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002249, cpktTxId=0000000000000002249)
2019-11-02 05:15:24,111 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2252 to namenode at http://um1:50070 in 0.035 seconds
2019-11-02 05:15:24,111 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 45856
2019-11-02 05:25:24,229 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 05:25:24,229 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2253&endTxId=2280&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 05:25:24,235 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1000.00 KB/s
2019-11-02 05:25:24,235 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002253-0000000000000002280_0000000000001764057 size 0 bytes.
2019-11-02 05:25:24,235 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 05:25:24,235 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002253-0000000000000002280 expecting start txid #2253
2019-11-02 05:25:24,235 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002253-0000000000000002280
2019-11-02 05:25:24,269 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002253-0000000000000002280 of size 3193 edits # 28 loaded in 0 seconds
2019-11-02 05:25:24,272 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002280 using no compression
2019-11-02 05:25:24,299 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002280 of size 46553 bytes saved in 0 seconds.
2019-11-02 05:25:24,311 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2252
2019-11-02 05:25:24,311 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002250, cpktTxId=0000000000000002250)
2019-11-02 05:25:24,342 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2280 to namenode at http://um1:50070 in 0.018 seconds
2019-11-02 05:25:24,342 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46553
2019-11-02 05:35:24,476 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 05:35:24,476 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2281&endTxId=2292&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 05:35:24,482 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 500.00 KB/s
2019-11-02 05:35:24,482 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002281-0000000000000002292_0000000000002364304 size 0 bytes.
2019-11-02 05:35:24,482 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 05:35:24,482 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002281-0000000000000002292 expecting start txid #2281
2019-11-02 05:35:24,482 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002281-0000000000000002292
2019-11-02 05:35:24,485 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002281-0000000000000002292 of size 1531 edits # 12 loaded in 0 seconds
2019-11-02 05:35:24,489 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002292 using no compression
2019-11-02 05:35:24,504 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002292 of size 46398 bytes saved in 0 seconds.
2019-11-02 05:35:24,506 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2280
2019-11-02 05:35:24,506 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002252, cpktTxId=0000000000000002252)
2019-11-02 05:35:24,533 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2292 to namenode at http://um1:50070 in 0.012 seconds
2019-11-02 05:35:24,533 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46398
2019-11-02 05:45:24,643 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 05:45:24,644 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2293&endTxId=2326&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 05:45:24,650 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1000.00 KB/s
2019-11-02 05:45:24,650 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002293-0000000000000002326_0000000000002964472 size 0 bytes.
2019-11-02 05:45:24,651 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 05:45:24,651 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002293-0000000000000002326 expecting start txid #2293
2019-11-02 05:45:24,651 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002293-0000000000000002326
2019-11-02 05:45:24,660 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002293-0000000000000002326 of size 3262 edits # 34 loaded in 0 seconds
2019-11-02 05:45:24,660 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002326 using no compression
2019-11-02 05:45:24,677 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002326 of size 46600 bytes saved in 0 seconds.
2019-11-02 05:45:24,681 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2292
2019-11-02 05:45:24,681 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002280, cpktTxId=0000000000000002280)
2019-11-02 05:45:24,709 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2326 to namenode at http://um1:50070 in 0.014 seconds
2019-11-02 05:45:24,709 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46600
2019-11-02 05:55:24,881 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 05:55:24,882 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2327&endTxId=2338&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 05:55:24,887 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 500.00 KB/s
2019-11-02 05:55:24,887 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002327-0000000000000002338_0000000000003564710 size 0 bytes.
2019-11-02 05:55:24,887 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 05:55:24,887 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002327-0000000000000002338 expecting start txid #2327
2019-11-02 05:55:24,887 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002327-0000000000000002338
2019-11-02 05:55:24,889 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002327-0000000000000002338 of size 1586 edits # 12 loaded in 0 seconds
2019-11-02 05:55:24,890 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002338 using no compression
2019-11-02 05:55:24,896 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002338 of size 46218 bytes saved in 0 seconds.
2019-11-02 05:55:24,899 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2326
2019-11-02 05:55:24,899 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002292, cpktTxId=0000000000000002292)
2019-11-02 05:55:24,919 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2338 to namenode at http://um1:50070 in 0.012 seconds
2019-11-02 05:55:24,919 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46218
2019-11-02 06:05:25,250 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 06:05:25,250 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2339&endTxId=2367&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 06:05:25,285 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 62.50 KB/s
2019-11-02 06:05:25,285 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002339-0000000000000002367_0000000000004165078 size 0 bytes.
2019-11-02 06:05:25,286 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 06:05:25,286 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002339-0000000000000002367 expecting start txid #2339
2019-11-02 06:05:25,286 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002339-0000000000000002367
2019-11-02 06:05:25,296 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002339-0000000000000002367 of size 2845 edits # 29 loaded in 0 seconds
2019-11-02 06:05:25,297 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002367 using no compression
2019-11-02 06:05:25,329 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002367 of size 46518 bytes saved in 0 seconds.
2019-11-02 06:05:25,332 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2338
2019-11-02 06:05:25,332 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002326, cpktTxId=0000000000000002326)
2019-11-02 06:05:25,431 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2367 to namenode at http://um1:50070 in 0.038 seconds
2019-11-02 06:05:25,431 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 06:15:25,551 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 06:15:25,552 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2368&endTxId=2376&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 06:15:25,556 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 500.00 KB/s
2019-11-02 06:15:25,556 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002368-0000000000000002376_0000000000004765379 size 0 bytes.
2019-11-02 06:15:25,556 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 06:15:25,556 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002368-0000000000000002376 expecting start txid #2368
2019-11-02 06:15:25,556 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002368-0000000000000002376
2019-11-02 06:15:25,558 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002368-0000000000000002376 of size 1255 edits # 9 loaded in 0 seconds
2019-11-02 06:15:25,560 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002376 using no compression
2019-11-02 06:15:25,568 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002376 of size 46518 bytes saved in 0 seconds.
2019-11-02 06:15:25,572 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2367
2019-11-02 06:15:25,572 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002338, cpktTxId=0000000000000002338)
2019-11-02 06:15:25,595 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2376 to namenode at http://um1:50070 in 0.011 seconds
2019-11-02 06:15:25,596 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 06:25:25,743 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 06:25:25,744 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2377&endTxId=2378&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 06:25:25,751 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 06:25:25,752 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002377-0000000000000002378_0000000000005365571 size 0 bytes.
2019-11-02 06:25:25,752 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 06:25:25,752 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002377-0000000000000002378 expecting start txid #2377
2019-11-02 06:25:25,752 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002377-0000000000000002378
2019-11-02 06:25:25,752 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002377-0000000000000002378 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 06:25:25,753 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002378 using no compression
2019-11-02 06:25:25,759 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002378 of size 46518 bytes saved in 0 seconds.
2019-11-02 06:25:25,764 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2376
2019-11-02 06:25:25,764 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002367, cpktTxId=0000000000000002367)
2019-11-02 06:25:25,780 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2378 to namenode at http://um1:50070 in 0.012 seconds
2019-11-02 06:25:25,780 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 06:35:25,902 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 06:35:25,903 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2379&endTxId=2380&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 06:35:25,908 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 06:35:25,908 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002379-0000000000000002380_0000000000005965731 size 0 bytes.
2019-11-02 06:35:25,909 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 06:35:25,909 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002379-0000000000000002380 expecting start txid #2379
2019-11-02 06:35:25,909 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002379-0000000000000002380
2019-11-02 06:35:25,909 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002379-0000000000000002380 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 06:35:25,909 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002380 using no compression
2019-11-02 06:35:25,913 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002380 of size 46518 bytes saved in 0 seconds.
2019-11-02 06:35:25,916 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2378
2019-11-02 06:35:25,917 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002376, cpktTxId=0000000000000002376)
2019-11-02 06:35:25,934 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2380 to namenode at http://um1:50070 in 0.01 seconds
2019-11-02 06:35:25,934 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 06:45:26,080 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 06:45:26,080 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2381&endTxId=2382&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 06:45:26,085 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 06:45:26,085 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002381-0000000000000002382_0000000000006565908 size 0 bytes.
2019-11-02 06:45:26,085 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 06:45:26,085 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002381-0000000000000002382 expecting start txid #2381
2019-11-02 06:45:26,085 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002381-0000000000000002382
2019-11-02 06:45:26,085 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002381-0000000000000002382 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 06:45:26,090 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002382 using no compression
2019-11-02 06:45:26,096 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002382 of size 46518 bytes saved in 0 seconds.
2019-11-02 06:45:26,100 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2380
2019-11-02 06:45:26,100 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002378, cpktTxId=0000000000000002378)
2019-11-02 06:45:26,131 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2382 to namenode at http://um1:50070 in 0.027 seconds
2019-11-02 06:45:26,131 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 06:55:26,255 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 06:55:26,255 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2383&endTxId=2384&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 06:55:26,261 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 06:55:26,261 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002383-0000000000000002384_0000000000007166083 size 0 bytes.
2019-11-02 06:55:26,262 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 06:55:26,262 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002383-0000000000000002384 expecting start txid #2383
2019-11-02 06:55:26,262 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002383-0000000000000002384
2019-11-02 06:55:26,262 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002383-0000000000000002384 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 06:55:26,263 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002384 using no compression
2019-11-02 06:55:26,268 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002384 of size 46518 bytes saved in 0 seconds.
2019-11-02 06:55:26,272 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2382
2019-11-02 06:55:26,273 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002380, cpktTxId=0000000000000002380)
2019-11-02 06:55:26,295 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2384 to namenode at http://um1:50070 in 0.018 seconds
2019-11-02 06:55:26,295 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 07:05:26,407 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 07:05:26,408 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2385&endTxId=2386&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 07:05:26,417 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 07:05:26,417 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002385-0000000000000002386_0000000000007766235 size 0 bytes.
2019-11-02 07:05:26,417 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 07:05:26,417 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002385-0000000000000002386 expecting start txid #2385
2019-11-02 07:05:26,417 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002385-0000000000000002386
2019-11-02 07:05:26,417 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002385-0000000000000002386 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 07:05:26,421 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002386 using no compression
2019-11-02 07:05:26,425 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002386 of size 46518 bytes saved in 0 seconds.
2019-11-02 07:05:26,429 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2384
2019-11-02 07:05:26,429 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002382, cpktTxId=0000000000000002382)
2019-11-02 07:05:26,445 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2386 to namenode at http://um1:50070 in 0.011 seconds
2019-11-02 07:05:26,445 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 07:15:26,572 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 07:15:26,572 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2387&endTxId=2388&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 07:15:26,578 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 07:15:26,578 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002387-0000000000000002388_0000000000008366400 size 0 bytes.
2019-11-02 07:15:26,578 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 07:15:26,578 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002387-0000000000000002388 expecting start txid #2387
2019-11-02 07:15:26,578 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002387-0000000000000002388
2019-11-02 07:15:26,579 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002387-0000000000000002388 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 07:15:26,579 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002388 using no compression
2019-11-02 07:15:26,586 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002388 of size 46518 bytes saved in 0 seconds.
2019-11-02 07:15:26,589 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2386
2019-11-02 07:15:26,589 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002384, cpktTxId=0000000000000002384)
2019-11-02 07:15:26,607 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2388 to namenode at http://um1:50070 in 0.013 seconds
2019-11-02 07:15:26,607 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 07:25:26,712 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 07:25:26,712 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2389&endTxId=2390&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 07:25:26,720 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 07:25:26,720 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002389-0000000000000002390_0000000000008966540 size 0 bytes.
2019-11-02 07:25:26,720 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 07:25:26,720 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002389-0000000000000002390 expecting start txid #2389
2019-11-02 07:25:26,721 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002389-0000000000000002390
2019-11-02 07:25:26,721 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002389-0000000000000002390 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 07:25:26,722 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002390 using no compression
2019-11-02 07:25:26,727 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002390 of size 46518 bytes saved in 0 seconds.
2019-11-02 07:25:26,731 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2388
2019-11-02 07:25:26,731 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002386, cpktTxId=0000000000000002386)
2019-11-02 07:25:26,755 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2390 to namenode at http://um1:50070 in 0.014 seconds
2019-11-02 07:25:26,755 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 07:35:26,906 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 07:35:26,906 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2391&endTxId=2392&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 07:35:26,912 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 07:35:26,912 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002391-0000000000000002392_0000000000009566734 size 0 bytes.
2019-11-02 07:35:26,913 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 07:35:26,913 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002391-0000000000000002392 expecting start txid #2391
2019-11-02 07:35:26,913 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002391-0000000000000002392
2019-11-02 07:35:26,913 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002391-0000000000000002392 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 07:35:26,914 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002392 using no compression
2019-11-02 07:35:26,928 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002392 of size 46518 bytes saved in 0 seconds.
2019-11-02 07:35:26,937 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2390
2019-11-02 07:35:26,937 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002388, cpktTxId=0000000000000002388)
2019-11-02 07:35:26,962 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2392 to namenode at http://um1:50070 in 0.013 seconds
2019-11-02 07:35:26,962 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 07:45:27,172 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 07:45:27,172 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2393&endTxId=2394&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 07:45:27,177 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 07:45:27,177 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002393-0000000000000002394_0000000000010167000 size 0 bytes.
2019-11-02 07:45:27,177 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 07:45:27,177 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002393-0000000000000002394 expecting start txid #2393
2019-11-02 07:45:27,177 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002393-0000000000000002394
2019-11-02 07:45:27,178 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002393-0000000000000002394 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 07:45:27,179 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002394 using no compression
2019-11-02 07:45:27,194 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002394 of size 46518 bytes saved in 0 seconds.
2019-11-02 07:45:27,202 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2392
2019-11-02 07:45:27,202 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002390, cpktTxId=0000000000000002390)
2019-11-02 07:45:27,218 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2394 to namenode at http://um1:50070 in 0.012 seconds
2019-11-02 07:45:27,219 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 07:55:27,365 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 07:55:27,365 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2395&endTxId=2396&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 07:55:27,371 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 07:55:27,371 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002395-0000000000000002396_0000000000010767193 size 0 bytes.
2019-11-02 07:55:27,371 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 07:55:27,371 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002395-0000000000000002396 expecting start txid #2395
2019-11-02 07:55:27,371 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002395-0000000000000002396
2019-11-02 07:55:27,372 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002395-0000000000000002396 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 07:55:27,373 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002396 using no compression
2019-11-02 07:55:27,380 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002396 of size 46518 bytes saved in 0 seconds.
2019-11-02 07:55:27,383 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2394
2019-11-02 07:55:27,383 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002392, cpktTxId=0000000000000002392)
2019-11-02 07:55:27,403 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2396 to namenode at http://um1:50070 in 0.015 seconds
2019-11-02 07:55:27,403 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 08:05:27,479 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 08:05:27,480 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2397&endTxId=2398&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 08:05:27,485 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 08:05:27,485 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002397-0000000000000002398_0000000000011367307 size 0 bytes.
2019-11-02 08:05:27,485 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 08:05:27,485 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002397-0000000000000002398 expecting start txid #2397
2019-11-02 08:05:27,485 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002397-0000000000000002398
2019-11-02 08:05:27,485 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002397-0000000000000002398 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 08:05:27,486 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002398 using no compression
2019-11-02 08:05:27,489 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002398 of size 46518 bytes saved in 0 seconds.
2019-11-02 08:05:27,492 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2396
2019-11-02 08:05:27,492 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002394, cpktTxId=0000000000000002394)
2019-11-02 08:05:27,514 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2398 to namenode at http://um1:50070 in 0.015 seconds
2019-11-02 08:05:27,514 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 08:15:27,616 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 08:15:27,617 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2399&endTxId=2400&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 08:15:27,622 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 08:15:27,622 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002399-0000000000000002400_0000000000011967445 size 0 bytes.
2019-11-02 08:15:27,622 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 08:15:27,622 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002399-0000000000000002400 expecting start txid #2399
2019-11-02 08:15:27,622 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002399-0000000000000002400
2019-11-02 08:15:27,622 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002399-0000000000000002400 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 08:15:27,625 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002400 using no compression
2019-11-02 08:15:27,629 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002400 of size 46518 bytes saved in 0 seconds.
2019-11-02 08:15:27,633 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2398
2019-11-02 08:15:27,633 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002396, cpktTxId=0000000000000002396)
2019-11-02 08:15:27,658 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2400 to namenode at http://um1:50070 in 0.019 seconds
2019-11-02 08:15:27,658 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 08:25:27,859 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 08:25:27,859 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2401&endTxId=2402&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 08:25:27,866 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 08:25:27,866 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002401-0000000000000002402_0000000000012567687 size 0 bytes.
2019-11-02 08:25:27,866 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 08:25:27,866 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002401-0000000000000002402 expecting start txid #2401
2019-11-02 08:25:27,866 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002401-0000000000000002402
2019-11-02 08:25:27,866 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002401-0000000000000002402 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 08:25:27,872 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002402 using no compression
2019-11-02 08:25:27,878 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002402 of size 46518 bytes saved in 0 seconds.
2019-11-02 08:25:27,882 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2400
2019-11-02 08:25:27,882 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002398, cpktTxId=0000000000000002398)
2019-11-02 08:25:27,897 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2402 to namenode at http://um1:50070 in 0.01 seconds
2019-11-02 08:25:27,898 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 08:35:27,996 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 08:35:27,996 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2403&endTxId=2404&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 08:35:28,005 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-11-02 08:35:28,005 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002403-0000000000000002404_0000000000013167824 size 0 bytes.
2019-11-02 08:35:28,006 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 08:35:28,006 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002403-0000000000000002404 expecting start txid #2403
2019-11-02 08:35:28,006 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002403-0000000000000002404
2019-11-02 08:35:28,006 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002403-0000000000000002404 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 08:35:28,010 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002404 using no compression
2019-11-02 08:35:28,017 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002404 of size 46518 bytes saved in 0 seconds.
2019-11-02 08:35:28,019 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2402
2019-11-02 08:35:28,019 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002400, cpktTxId=0000000000000002400)
2019-11-02 08:35:28,033 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2404 to namenode at http://um1:50070 in 0.01 seconds
2019-11-02 08:35:28,033 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 08:45:28,174 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 08:45:28,175 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2405&endTxId=2406&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 08:45:28,181 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 08:45:28,181 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002405-0000000000000002406_0000000000013768002 size 0 bytes.
2019-11-02 08:45:28,181 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 08:45:28,181 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002405-0000000000000002406 expecting start txid #2405
2019-11-02 08:45:28,181 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002405-0000000000000002406
2019-11-02 08:45:28,181 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002405-0000000000000002406 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 08:45:28,181 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002406 using no compression
2019-11-02 08:45:28,184 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002406 of size 46518 bytes saved in 0 seconds.
2019-11-02 08:45:28,186 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2404
2019-11-02 08:45:28,186 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002402, cpktTxId=0000000000000002402)
2019-11-02 08:45:28,200 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2406 to namenode at http://um1:50070 in 0.011 seconds
2019-11-02 08:45:28,200 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 08:55:28,412 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 08:55:28,412 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2407&endTxId=2408&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 08:55:28,421 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-11-02 08:55:28,421 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002407-0000000000000002408_0000000000014368240 size 0 bytes.
2019-11-02 08:55:28,421 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 08:55:28,421 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002407-0000000000000002408 expecting start txid #2407
2019-11-02 08:55:28,421 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002407-0000000000000002408
2019-11-02 08:55:28,422 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002407-0000000000000002408 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 08:55:28,433 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002408 using no compression
2019-11-02 08:55:28,436 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002408 of size 46518 bytes saved in 0 seconds.
2019-11-02 08:55:28,439 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2406
2019-11-02 08:55:28,439 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002404, cpktTxId=0000000000000002404)
2019-11-02 08:55:28,453 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2408 to namenode at http://um1:50070 in 0.01 seconds
2019-11-02 08:55:28,453 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 09:05:28,588 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 09:05:28,589 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2409&endTxId=2410&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 09:05:28,593 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 09:05:28,593 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002409-0000000000000002410_0000000000014968416 size 0 bytes.
2019-11-02 09:05:28,593 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 09:05:28,593 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002409-0000000000000002410 expecting start txid #2409
2019-11-02 09:05:28,593 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002409-0000000000000002410
2019-11-02 09:05:28,594 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002409-0000000000000002410 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 09:05:28,594 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002410 using no compression
2019-11-02 09:05:28,602 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002410 of size 46518 bytes saved in 0 seconds.
2019-11-02 09:05:28,605 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2408
2019-11-02 09:05:28,605 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002406, cpktTxId=0000000000000002406)
2019-11-02 09:05:28,618 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2410 to namenode at http://um1:50070 in 0.01 seconds
2019-11-02 09:05:28,619 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 09:15:28,786 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 09:15:28,786 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2411&endTxId=2412&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 09:15:28,790 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 09:15:28,790 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002411-0000000000000002412_0000000000015568614 size 0 bytes.
2019-11-02 09:15:28,790 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 09:15:28,790 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002411-0000000000000002412 expecting start txid #2411
2019-11-02 09:15:28,790 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002411-0000000000000002412
2019-11-02 09:15:28,790 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002411-0000000000000002412 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 09:15:28,790 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002412 using no compression
2019-11-02 09:15:28,793 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002412 of size 46518 bytes saved in 0 seconds.
2019-11-02 09:15:28,795 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2410
2019-11-02 09:15:28,795 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002408, cpktTxId=0000000000000002408)
2019-11-02 09:15:28,812 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2412 to namenode at http://um1:50070 in 0.01 seconds
2019-11-02 09:15:28,812 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 17:48:18,341 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 17:48:18,341 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2413&endTxId=2414&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 17:48:18,345 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 17:48:18,345 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002413-0000000000000002414_0000000000016168783 size 0 bytes.
2019-11-02 17:48:18,345 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 17:48:18,345 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002413-0000000000000002414 expecting start txid #2413
2019-11-02 17:48:18,345 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002413-0000000000000002414
2019-11-02 17:48:18,345 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002413-0000000000000002414 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 17:48:18,345 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002414 using no compression
2019-11-02 17:48:18,349 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002414 of size 46518 bytes saved in 0 seconds.
2019-11-02 17:48:18,360 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2412
2019-11-02 17:48:18,360 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002410, cpktTxId=0000000000000002410)
2019-11-02 17:48:18,378 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2414 to namenode at http://um1:50070 in 0.013 seconds
2019-11-02 17:48:18,379 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 17:58:18,545 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 17:58:18,546 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2415&endTxId=2416&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 17:58:18,552 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 17:58:18,552 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002415-0000000000000002416_0000000000016768988 size 0 bytes.
2019-11-02 17:58:18,553 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 17:58:18,553 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002415-0000000000000002416 expecting start txid #2415
2019-11-02 17:58:18,553 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002415-0000000000000002416
2019-11-02 17:58:18,553 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002415-0000000000000002416 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 17:58:18,554 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002416 using no compression
2019-11-02 17:58:18,558 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002416 of size 46518 bytes saved in 0 seconds.
2019-11-02 17:58:18,560 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2414
2019-11-02 17:58:18,561 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002412, cpktTxId=0000000000000002412)
2019-11-02 17:58:18,597 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2416 to namenode at http://um1:50070 in 0.027 seconds
2019-11-02 17:58:18,597 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 18:08:18,906 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 18:08:18,907 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2417&endTxId=2418&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 18:08:18,923 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 18:08:18,923 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002417-0000000000000002418_0000000000017369350 size 0 bytes.
2019-11-02 18:08:18,924 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 18:08:18,924 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002417-0000000000000002418 expecting start txid #2417
2019-11-02 18:08:18,924 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002417-0000000000000002418
2019-11-02 18:08:18,924 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002417-0000000000000002418 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 18:08:18,924 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002418 using no compression
2019-11-02 18:08:18,934 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002418 of size 46518 bytes saved in 0 seconds.
2019-11-02 18:08:18,944 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2416
2019-11-02 18:08:18,944 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002414, cpktTxId=0000000000000002414)
2019-11-02 18:08:18,991 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2418 to namenode at http://um1:50070 in 0.017 seconds
2019-11-02 18:08:18,992 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 19:56:39,813 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 19:56:39,813 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2419&endTxId=2420&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 19:56:39,820 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 19:56:39,820 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002419-0000000000000002420_0000000000017969629 size 0 bytes.
2019-11-02 19:56:39,820 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 19:56:39,820 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002419-0000000000000002420 expecting start txid #2419
2019-11-02 19:56:39,820 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002419-0000000000000002420
2019-11-02 19:56:39,820 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002419-0000000000000002420 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 19:56:39,820 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002420 using no compression
2019-11-02 19:56:39,839 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002420 of size 46518 bytes saved in 0 seconds.
2019-11-02 19:56:39,846 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2418
2019-11-02 19:56:39,846 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002416, cpktTxId=0000000000000002416)
2019-11-02 19:56:39,869 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2420 to namenode at http://um1:50070 in 0.01 seconds
2019-11-02 19:56:39,869 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 20:06:40,045 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 20:06:40,045 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2421&endTxId=2422&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 20:06:40,058 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-11-02 20:06:40,058 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002421-0000000000000002422_0000000000018569861 size 0 bytes.
2019-11-02 20:06:40,058 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 20:06:40,058 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002421-0000000000000002422 expecting start txid #2421
2019-11-02 20:06:40,058 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002421-0000000000000002422
2019-11-02 20:06:40,059 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002421-0000000000000002422 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 20:06:40,061 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002422 using no compression
2019-11-02 20:06:40,068 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002422 of size 46518 bytes saved in 0 seconds.
2019-11-02 20:06:40,073 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2420
2019-11-02 20:06:40,073 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002418, cpktTxId=0000000000000002418)
2019-11-02 20:06:40,113 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2422 to namenode at http://um1:50070 in 0.022 seconds
2019-11-02 20:06:40,113 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 20:16:40,240 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 20:16:40,241 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2423&endTxId=2424&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 20:16:40,253 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 20:16:40,253 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002423-0000000000000002424_0000000000019170057 size 0 bytes.
2019-11-02 20:16:40,253 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 20:16:40,253 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002423-0000000000000002424 expecting start txid #2423
2019-11-02 20:16:40,253 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002423-0000000000000002424
2019-11-02 20:16:40,253 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002423-0000000000000002424 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 20:16:40,254 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002424 using no compression
2019-11-02 20:16:40,260 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002424 of size 46518 bytes saved in 0 seconds.
2019-11-02 20:16:40,264 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2422
2019-11-02 20:16:40,264 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002420, cpktTxId=0000000000000002420)
2019-11-02 20:16:40,290 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2424 to namenode at http://um1:50070 in 0.018 seconds
2019-11-02 20:16:40,291 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 20:26:40,472 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 20:26:40,473 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2425&endTxId=2426&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 20:26:40,490 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-11-02 20:26:40,490 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002425-0000000000000002426_0000000000019770289 size 0 bytes.
2019-11-02 20:26:40,492 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 20:26:40,493 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002425-0000000000000002426 expecting start txid #2425
2019-11-02 20:26:40,493 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002425-0000000000000002426
2019-11-02 20:26:40,494 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002425-0000000000000002426 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 20:26:40,496 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002426 using no compression
2019-11-02 20:26:40,511 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002426 of size 46518 bytes saved in 0 seconds.
2019-11-02 20:26:40,518 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2424
2019-11-02 20:26:40,518 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002422, cpktTxId=0000000000000002422)
2019-11-02 20:26:40,580 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2426 to namenode at http://um1:50070 in 0.04 seconds
2019-11-02 20:26:40,581 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 20:36:40,772 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 20:36:40,772 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2427&endTxId=2428&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 20:36:40,779 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 20:36:40,779 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002427-0000000000000002428_0000000000020370589 size 0 bytes.
2019-11-02 20:36:40,780 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 20:36:40,780 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002427-0000000000000002428 expecting start txid #2427
2019-11-02 20:36:40,780 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002427-0000000000000002428
2019-11-02 20:36:40,780 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002427-0000000000000002428 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 20:36:40,780 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002428 using no compression
2019-11-02 20:36:40,790 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002428 of size 46518 bytes saved in 0 seconds.
2019-11-02 20:36:40,794 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2426
2019-11-02 20:36:40,794 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002424, cpktTxId=0000000000000002424)
2019-11-02 20:36:40,826 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2428 to namenode at http://um1:50070 in 0.023 seconds
2019-11-02 20:36:40,827 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 20:46:40,963 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 20:46:40,963 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2429&endTxId=2430&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 20:46:40,971 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 20:46:40,971 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002429-0000000000000002430_0000000000020970779 size 0 bytes.
2019-11-02 20:46:40,972 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 20:46:40,972 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002429-0000000000000002430 expecting start txid #2429
2019-11-02 20:46:40,972 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002429-0000000000000002430
2019-11-02 20:46:40,972 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002429-0000000000000002430 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 20:46:40,973 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002430 using no compression
2019-11-02 20:46:40,979 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002430 of size 46518 bytes saved in 0 seconds.
2019-11-02 20:46:40,982 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2428
2019-11-02 20:46:40,982 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002426, cpktTxId=0000000000000002426)
2019-11-02 20:46:41,007 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2430 to namenode at http://um1:50070 in 0.016 seconds
2019-11-02 20:46:41,007 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 20:56:41,171 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 20:56:41,172 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2431&endTxId=2432&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 20:56:41,181 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 20:56:41,182 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002431-0000000000000002432_0000000000021570988 size 0 bytes.
2019-11-02 20:56:41,182 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 20:56:41,182 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002431-0000000000000002432 expecting start txid #2431
2019-11-02 20:56:41,182 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002431-0000000000000002432
2019-11-02 20:56:41,182 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002431-0000000000000002432 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 20:56:41,183 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002432 using no compression
2019-11-02 20:56:41,188 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002432 of size 46518 bytes saved in 0 seconds.
2019-11-02 20:56:41,193 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2430
2019-11-02 20:56:41,193 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002428, cpktTxId=0000000000000002428)
2019-11-02 20:56:41,232 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2432 to namenode at http://um1:50070 in 0.022 seconds
2019-11-02 20:56:41,232 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 21:32:33,004 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 21:32:33,004 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2433&endTxId=2434&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 21:32:33,011 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 21:32:33,011 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002433-0000000000000002434_0000000000022171870 size 0 bytes.
2019-11-02 21:32:33,012 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 21:32:33,012 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002433-0000000000000002434 expecting start txid #2433
2019-11-02 21:32:33,012 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002433-0000000000000002434
2019-11-02 21:32:33,015 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002433-0000000000000002434 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 21:32:33,016 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002434 using no compression
2019-11-02 21:32:33,024 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002434 of size 46518 bytes saved in 0 seconds.
2019-11-02 21:32:33,029 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2432
2019-11-02 21:32:33,029 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002430, cpktTxId=0000000000000002430)
2019-11-02 21:32:33,060 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2434 to namenode at http://um1:50070 in 0.021 seconds
2019-11-02 21:32:33,060 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-02 21:42:33,251 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-02 21:42:33,251 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2435&endTxId=2436&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-02 21:42:33,257 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-02 21:42:33,257 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002435-0000000000000002436_0000000000022772117 size 0 bytes.
2019-11-02 21:42:33,257 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-02 21:42:33,257 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002435-0000000000000002436 expecting start txid #2435
2019-11-02 21:42:33,257 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002435-0000000000000002436
2019-11-02 21:42:33,257 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002435-0000000000000002436 of size 42 edits # 2 loaded in 0 seconds
2019-11-02 21:42:33,257 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002436 using no compression
2019-11-02 21:42:33,262 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002436 of size 46518 bytes saved in 0 seconds.
2019-11-02 21:42:33,266 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2434
2019-11-02 21:42:33,266 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002432, cpktTxId=0000000000000002432)
2019-11-02 21:42:33,292 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2436 to namenode at http://um1:50070 in 0.018 seconds
2019-11-02 21:42:33,292 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-03 09:52:44,759 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-03 09:52:44,759 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2437&endTxId=2438&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-03 09:52:44,772 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-03 09:52:44,772 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002437-0000000000000002438_0000000000023372307 size 0 bytes.
2019-11-03 09:52:44,773 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-03 09:52:44,773 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002437-0000000000000002438 expecting start txid #2437
2019-11-03 09:52:44,773 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002437-0000000000000002438
2019-11-03 09:52:44,773 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002437-0000000000000002438 of size 42 edits # 2 loaded in 0 seconds
2019-11-03 09:52:44,773 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002438 using no compression
2019-11-03 09:52:44,779 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002438 of size 46518 bytes saved in 0 seconds.
2019-11-03 09:52:44,782 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2436
2019-11-03 09:52:44,782 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002434, cpktTxId=0000000000000002434)
2019-11-03 09:52:44,806 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2438 to namenode at http://um1:50070 in 0.017 seconds
2019-11-03 09:52:44,806 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-03 10:02:44,989 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-03 10:02:44,989 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2439&endTxId=2440&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-03 10:02:44,996 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-03 10:02:44,997 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002439-0000000000000002440_0000000000023972538 size 0 bytes.
2019-11-03 10:02:44,997 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-03 10:02:44,997 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002439-0000000000000002440 expecting start txid #2439
2019-11-03 10:02:44,997 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002439-0000000000000002440
2019-11-03 10:02:44,997 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002439-0000000000000002440 of size 42 edits # 2 loaded in 0 seconds
2019-11-03 10:02:44,998 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002440 using no compression
2019-11-03 10:02:45,015 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002440 of size 46518 bytes saved in 0 seconds.
2019-11-03 10:02:45,017 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2438
2019-11-03 10:02:45,018 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002436, cpktTxId=0000000000000002436)
2019-11-03 10:02:45,049 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2440 to namenode at http://um1:50070 in 0.023 seconds
2019-11-03 10:02:45,049 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-03 10:12:45,263 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-03 10:12:45,263 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2441&endTxId=2442&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-03 10:12:45,268 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-03 10:12:45,268 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002441-0000000000000002442_0000000000024572812 size 0 bytes.
2019-11-03 10:12:45,268 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-03 10:12:45,268 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002441-0000000000000002442 expecting start txid #2441
2019-11-03 10:12:45,268 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002441-0000000000000002442
2019-11-03 10:12:45,268 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002441-0000000000000002442 of size 42 edits # 2 loaded in 0 seconds
2019-11-03 10:12:45,269 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002442 using no compression
2019-11-03 10:12:45,272 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002442 of size 46518 bytes saved in 0 seconds.
2019-11-03 10:12:45,275 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2440
2019-11-03 10:12:45,275 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002438, cpktTxId=0000000000000002438)
2019-11-03 10:12:45,295 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2442 to namenode at http://um1:50070 in 0.016 seconds
2019-11-03 10:12:45,295 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-03 10:22:45,471 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-03 10:22:45,472 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2443&endTxId=2444&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-03 10:22:45,479 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-03 10:22:45,479 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002443-0000000000000002444_0000000000025173020 size 0 bytes.
2019-11-03 10:22:45,479 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-03 10:22:45,479 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002443-0000000000000002444 expecting start txid #2443
2019-11-03 10:22:45,479 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002443-0000000000000002444
2019-11-03 10:22:45,480 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002443-0000000000000002444 of size 42 edits # 2 loaded in 0 seconds
2019-11-03 10:22:45,480 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002444 using no compression
2019-11-03 10:22:45,488 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002444 of size 46518 bytes saved in 0 seconds.
2019-11-03 10:22:45,492 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2442
2019-11-03 10:22:45,493 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002440, cpktTxId=0000000000000002440)
2019-11-03 10:22:45,529 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2444 to namenode at http://um1:50070 in 0.022 seconds
2019-11-03 10:22:45,529 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-03 10:32:45,734 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-03 10:32:45,735 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2445&endTxId=2446&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-03 10:32:45,760 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-11-03 10:32:45,761 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002445-0000000000000002446_0000000000025773283 size 0 bytes.
2019-11-03 10:32:45,762 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-03 10:32:45,762 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002445-0000000000000002446 expecting start txid #2445
2019-11-03 10:32:45,762 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002445-0000000000000002446
2019-11-03 10:32:45,763 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002445-0000000000000002446 of size 42 edits # 2 loaded in 0 seconds
2019-11-03 10:32:45,765 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002446 using no compression
2019-11-03 10:32:45,781 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002446 of size 46518 bytes saved in 0 seconds.
2019-11-03 10:32:45,793 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2444
2019-11-03 10:32:45,796 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002442, cpktTxId=0000000000000002442)
2019-11-03 10:32:45,868 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2446 to namenode at http://um1:50070 in 0.052 seconds
2019-11-03 10:32:45,869 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-03 10:42:46,104 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-03 10:42:46,104 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2447&endTxId=2448&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-03 10:42:46,112 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-03 10:42:46,112 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002447-0000000000000002448_0000000000026373652 size 0 bytes.
2019-11-03 10:42:46,113 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-03 10:42:46,113 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002447-0000000000000002448 expecting start txid #2447
2019-11-03 10:42:46,113 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002447-0000000000000002448
2019-11-03 10:42:46,114 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002447-0000000000000002448 of size 42 edits # 2 loaded in 0 seconds
2019-11-03 10:42:46,115 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002448 using no compression
2019-11-03 10:42:46,121 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002448 of size 46518 bytes saved in 0 seconds.
2019-11-03 10:42:46,132 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2446
2019-11-03 10:42:46,132 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002444, cpktTxId=0000000000000002444)
2019-11-03 10:42:46,184 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2448 to namenode at http://um1:50070 in 0.029 seconds
2019-11-03 10:42:46,184 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-11 18:59:57,935 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.251.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-11-11 18:59:57,948 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-11-11 18:59:58,615 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-11-11 18:59:58,703 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-11-11 18:59:58,704 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-11-11 18:59:58,859 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-11-11 18:59:58,859 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-11-11 18:59:58,964 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 2688@um2
2019-11-11 18:59:59,029 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 2688@um2
2019-11-11 18:59:59,063 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-11-11 18:59:59,077 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-11-11 18:59:59,184 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-11-11 18:59:59,184 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-11-11 18:59:59,188 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-11-11 18:59:59,191 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Nov 11 18:59:59
2019-11-11 18:59:59,194 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-11-11 18:59:59,195 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-11-11 18:59:59,200 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-11-11 18:59:59,200 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-11-11 18:59:59,216 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-11-11 18:59:59,216 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-11-11 18:59:59,217 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-11-11 18:59:59,217 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-11-11 18:59:59,217 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-11-11 18:59:59,217 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-11-11 18:59:59,217 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-11-11 18:59:59,217 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-11-11 18:59:59,218 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-11-11 18:59:59,218 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-11-11 18:59:59,218 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-11-11 18:59:59,219 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-11-11 18:59:59,221 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-11-11 18:59:59,622 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-11-11 18:59:59,622 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-11-11 18:59:59,622 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-11-11 18:59:59,622 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-11-11 18:59:59,630 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-11-11 18:59:59,637 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-11-11 18:59:59,637 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-11-11 18:59:59,638 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-11-11 18:59:59,638 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-11-11 18:59:59,643 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-11-11 18:59:59,643 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-11-11 18:59:59,643 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-11-11 18:59:59,645 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-11-11 18:59:59,645 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-11-11 18:59:59,645 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-11-11 18:59:59,654 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-11-11 18:59:59,815 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-11-11 18:59:59,819 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-11-11 18:59:59,835 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-11 18:59:59,838 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-11-11 18:59:59,838 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-11 18:59:59,838 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-11 18:59:59,855 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-11-11 18:59:59,855 INFO org.mortbay.log: jetty-6.1.26
2019-11-11 19:00:00,095 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-11-11 19:00:00,095 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-11-11 19:00:00,095 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-11-11 19:00:00,095 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-11-11 19:06:00,373 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-11-11 19:06:00,670 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=2449&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-11 19:06:00,760 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-11-11 19:06:01,110 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 1406.25 KB/s
2019-11-11 19:06:01,110 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000002449 size 46518 bytes.
2019-11-11 19:06:01,122 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2450&endTxId=2451&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-11 19:06:01,130 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-11 19:06:01,130 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002450-0000000000000002451_0000000000000611767 size 0 bytes.
2019-11-11 19:06:01,207 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 484 INodes.
2019-11-11 19:06:01,317 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-11-11 19:06:01,317 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 2449 from /orgz/snnfsi/current/fsimage_0000000000000002449
2019-11-11 19:06:01,318 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 1 entries 205 lookups
2019-11-11 19:06:01,324 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-11 19:06:01,330 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002450-0000000000000002451 expecting start txid #2450
2019-11-11 19:06:01,331 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002450-0000000000000002451
2019-11-11 19:06:01,365 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002450-0000000000000002451 of size 42 edits # 2 loaded in 0 seconds
2019-11-11 19:06:01,378 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002451 using no compression
2019-11-11 19:06:01,473 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002451 of size 46518 bytes saved in 0 seconds.
2019-11-11 19:06:01,492 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2449
2019-11-11 19:06:01,493 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002448, cpktTxId=0000000000000002448)
2019-11-11 19:06:01,497 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002446, cpktTxId=0000000000000002446)
2019-11-11 19:06:01,633 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2451 to namenode at http://um1:50070 in 0.065 seconds
2019-11-11 19:06:01,634 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-11 19:16:02,697 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-11 19:16:02,697 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2452&endTxId=2453&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-11 19:16:02,780 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.08s at 0.00 KB/s
2019-11-11 19:16:02,780 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002452-0000000000000002453_0000000000001213345 size 0 bytes.
2019-11-11 19:16:02,781 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-11 19:16:02,781 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002452-0000000000000002453 expecting start txid #2452
2019-11-11 19:16:02,781 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002452-0000000000000002453
2019-11-11 19:16:02,782 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002452-0000000000000002453 of size 42 edits # 2 loaded in 0 seconds
2019-11-11 19:16:02,784 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002453 using no compression
2019-11-11 19:16:02,811 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002453 of size 46518 bytes saved in 0 seconds.
2019-11-11 19:16:02,843 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2451
2019-11-11 19:16:02,843 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002449, cpktTxId=0000000000000002449)
2019-11-11 19:16:02,953 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2453 to namenode at http://um1:50070 in 0.079 seconds
2019-11-11 19:16:02,953 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-11 19:26:03,093 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-11 19:26:03,093 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2454&endTxId=2455&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-11 19:26:03,113 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-11 19:26:03,113 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002454-0000000000000002455_0000000000001813740 size 0 bytes.
2019-11-11 19:26:03,113 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-11 19:26:03,113 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002454-0000000000000002455 expecting start txid #2454
2019-11-11 19:26:03,113 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002454-0000000000000002455
2019-11-11 19:26:03,114 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002454-0000000000000002455 of size 42 edits # 2 loaded in 0 seconds
2019-11-11 19:26:03,146 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002455 using no compression
2019-11-11 19:26:03,168 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002455 of size 46518 bytes saved in 0 seconds.
2019-11-11 19:26:03,172 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2453
2019-11-11 19:26:03,172 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002451, cpktTxId=0000000000000002451)
2019-11-11 19:26:03,207 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2455 to namenode at http://um1:50070 in 0.016 seconds
2019-11-11 19:26:03,207 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-11 19:36:03,385 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-11 19:36:03,385 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2456&endTxId=2457&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-11 19:36:03,390 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-11 19:36:03,390 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002456-0000000000000002457_0000000000002414032 size 0 bytes.
2019-11-11 19:36:03,390 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-11 19:36:03,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002456-0000000000000002457 expecting start txid #2456
2019-11-11 19:36:03,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002456-0000000000000002457
2019-11-11 19:36:03,391 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002456-0000000000000002457 of size 42 edits # 2 loaded in 0 seconds
2019-11-11 19:36:03,392 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002457 using no compression
2019-11-11 19:36:03,411 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002457 of size 46518 bytes saved in 0 seconds.
2019-11-11 19:36:03,423 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2455
2019-11-11 19:36:03,423 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002453, cpktTxId=0000000000000002453)
2019-11-11 19:36:03,493 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2457 to namenode at http://um1:50070 in 0.058 seconds
2019-11-11 19:36:03,493 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-11 23:02:19,676 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-11 23:02:19,677 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2458&endTxId=2459&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-11 23:02:19,682 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-11 23:02:19,682 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002458-0000000000000002459_0000000000003014759 size 0 bytes.
2019-11-11 23:02:19,683 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-11 23:02:19,683 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002458-0000000000000002459 expecting start txid #2458
2019-11-11 23:02:19,683 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002458-0000000000000002459
2019-11-11 23:02:19,683 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002458-0000000000000002459 of size 42 edits # 2 loaded in 0 seconds
2019-11-11 23:02:19,684 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002459 using no compression
2019-11-11 23:02:19,690 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002459 of size 46518 bytes saved in 0 seconds.
2019-11-11 23:02:19,692 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2457
2019-11-11 23:02:19,692 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002455, cpktTxId=0000000000000002455)
2019-11-11 23:02:19,717 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2459 to namenode at http://um1:50070 in 0.014 seconds
2019-11-11 23:02:19,718 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-11 23:12:19,829 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-11 23:12:19,829 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2460&endTxId=2461&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-11 23:12:19,835 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-11 23:12:19,835 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002460-0000000000000002461_0000000000003614911 size 0 bytes.
2019-11-11 23:12:19,835 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-11 23:12:19,835 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002460-0000000000000002461 expecting start txid #2460
2019-11-11 23:12:19,835 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002460-0000000000000002461
2019-11-11 23:12:19,836 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002460-0000000000000002461 of size 42 edits # 2 loaded in 0 seconds
2019-11-11 23:12:19,837 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002461 using no compression
2019-11-11 23:12:19,841 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002461 of size 46518 bytes saved in 0 seconds.
2019-11-11 23:12:19,846 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2459
2019-11-11 23:12:19,846 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002457, cpktTxId=0000000000000002457)
2019-11-11 23:12:19,863 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2461 to namenode at http://um1:50070 in 0.011 seconds
2019-11-11 23:12:19,864 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-11 23:22:20,052 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-11 23:22:20,052 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2462&endTxId=2463&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-11 23:22:20,057 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-11 23:22:20,057 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002462-0000000000000002463_0000000000004215135 size 0 bytes.
2019-11-11 23:22:20,057 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-11 23:22:20,057 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002462-0000000000000002463 expecting start txid #2462
2019-11-11 23:22:20,057 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002462-0000000000000002463
2019-11-11 23:22:20,058 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002462-0000000000000002463 of size 42 edits # 2 loaded in 0 seconds
2019-11-11 23:22:20,059 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002463 using no compression
2019-11-11 23:22:20,063 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002463 of size 46518 bytes saved in 0 seconds.
2019-11-11 23:22:20,066 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2461
2019-11-11 23:22:20,066 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002459, cpktTxId=0000000000000002459)
2019-11-11 23:22:20,089 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2463 to namenode at http://um1:50070 in 0.018 seconds
2019-11-11 23:22:20,089 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-11 23:32:20,205 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-11 23:32:20,205 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2464&endTxId=2465&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-11 23:32:20,210 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-11 23:32:20,210 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002464-0000000000000002465_0000000000004815288 size 0 bytes.
2019-11-11 23:32:20,210 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-11 23:32:20,210 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002464-0000000000000002465 expecting start txid #2464
2019-11-11 23:32:20,210 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002464-0000000000000002465
2019-11-11 23:32:20,210 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002464-0000000000000002465 of size 42 edits # 2 loaded in 0 seconds
2019-11-11 23:32:20,211 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002465 using no compression
2019-11-11 23:32:20,215 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002465 of size 46518 bytes saved in 0 seconds.
2019-11-11 23:32:20,217 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2463
2019-11-11 23:32:20,218 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002461, cpktTxId=0000000000000002461)
2019-11-11 23:32:20,244 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2465 to namenode at http://um1:50070 in 0.019 seconds
2019-11-11 23:32:20,245 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-11 23:42:20,488 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-11 23:42:20,488 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2466&endTxId=2467&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-11 23:42:20,494 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-11 23:42:20,494 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002466-0000000000000002467_0000000000005415571 size 0 bytes.
2019-11-11 23:42:20,494 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-11 23:42:20,494 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002466-0000000000000002467 expecting start txid #2466
2019-11-11 23:42:20,494 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002466-0000000000000002467
2019-11-11 23:42:20,494 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002466-0000000000000002467 of size 42 edits # 2 loaded in 0 seconds
2019-11-11 23:42:20,495 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002467 using no compression
2019-11-11 23:42:20,504 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002467 of size 46518 bytes saved in 0 seconds.
2019-11-11 23:42:20,508 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2465
2019-11-11 23:42:20,508 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002463, cpktTxId=0000000000000002463)
2019-11-11 23:42:20,524 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2467 to namenode at http://um1:50070 in 0.01 seconds
2019-11-11 23:42:20,524 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-11 23:52:20,715 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-11 23:52:20,715 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2468&endTxId=2469&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-11 23:52:20,724 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-11 23:52:20,724 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002468-0000000000000002469_0000000000006015798 size 0 bytes.
2019-11-11 23:52:20,724 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-11 23:52:20,724 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002468-0000000000000002469 expecting start txid #2468
2019-11-11 23:52:20,724 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002468-0000000000000002469
2019-11-11 23:52:20,724 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002468-0000000000000002469 of size 42 edits # 2 loaded in 0 seconds
2019-11-11 23:52:20,725 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002469 using no compression
2019-11-11 23:52:20,735 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002469 of size 46518 bytes saved in 0 seconds.
2019-11-11 23:52:20,737 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2467
2019-11-11 23:52:20,737 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002465, cpktTxId=0000000000000002465)
2019-11-11 23:52:20,760 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2469 to namenode at http://um1:50070 in 0.015 seconds
2019-11-11 23:52:20,760 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 00:02:20,984 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 00:02:20,984 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2470&endTxId=2471&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 00:02:20,988 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 00:02:20,988 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002470-0000000000000002471_0000000000006616066 size 0 bytes.
2019-11-12 00:02:20,988 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 00:02:20,988 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002470-0000000000000002471 expecting start txid #2470
2019-11-12 00:02:20,988 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002470-0000000000000002471
2019-11-12 00:02:20,989 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002470-0000000000000002471 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 00:02:20,992 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002471 using no compression
2019-11-12 00:02:20,996 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002471 of size 46518 bytes saved in 0 seconds.
2019-11-12 00:02:20,999 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2469
2019-11-12 00:02:20,999 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002467, cpktTxId=0000000000000002467)
2019-11-12 00:02:21,037 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2471 to namenode at http://um1:50070 in 0.023 seconds
2019-11-12 00:02:21,038 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 00:12:21,213 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 00:12:21,213 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2472&endTxId=2473&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 00:12:21,217 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 00:12:21,217 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002472-0000000000000002473_0000000000007216296 size 0 bytes.
2019-11-12 00:12:21,217 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 00:12:21,217 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002472-0000000000000002473 expecting start txid #2472
2019-11-12 00:12:21,218 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002472-0000000000000002473
2019-11-12 00:12:21,218 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002472-0000000000000002473 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 00:12:21,218 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002473 using no compression
2019-11-12 00:12:21,222 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002473 of size 46518 bytes saved in 0 seconds.
2019-11-12 00:12:21,225 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2471
2019-11-12 00:12:21,225 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002469, cpktTxId=0000000000000002469)
2019-11-12 00:12:21,249 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2473 to namenode at http://um1:50070 in 0.012 seconds
2019-11-12 00:12:21,249 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 00:22:21,404 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 00:22:21,404 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2474&endTxId=2475&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 00:22:21,408 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 00:22:21,408 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002474-0000000000000002475_0000000000007816487 size 0 bytes.
2019-11-12 00:22:21,408 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 00:22:21,408 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002474-0000000000000002475 expecting start txid #2474
2019-11-12 00:22:21,408 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002474-0000000000000002475
2019-11-12 00:22:21,408 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002474-0000000000000002475 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 00:22:21,410 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002475 using no compression
2019-11-12 00:22:21,422 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002475 of size 46518 bytes saved in 0 seconds.
2019-11-12 00:22:21,428 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2473
2019-11-12 00:22:21,428 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002471, cpktTxId=0000000000000002471)
2019-11-12 00:22:21,444 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2475 to namenode at http://um1:50070 in 0.011 seconds
2019-11-12 00:22:21,444 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 00:32:21,710 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 00:32:21,710 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2476&endTxId=2477&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 00:32:21,725 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 00:32:21,725 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002476-0000000000000002477_0000000000008416793 size 0 bytes.
2019-11-12 00:32:21,725 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 00:32:21,727 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002476-0000000000000002477 expecting start txid #2476
2019-11-12 00:32:21,727 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002476-0000000000000002477
2019-11-12 00:32:21,728 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002476-0000000000000002477 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 00:32:21,729 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002477 using no compression
2019-11-12 00:32:21,732 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002477 of size 46518 bytes saved in 0 seconds.
2019-11-12 00:32:21,736 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2475
2019-11-12 00:32:21,736 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002473, cpktTxId=0000000000000002473)
2019-11-12 00:32:21,752 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2477 to namenode at http://um1:50070 in 0.011 seconds
2019-11-12 00:32:21,752 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 00:42:22,000 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 00:42:22,001 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2478&endTxId=2479&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 00:42:22,007 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 00:42:22,007 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002478-0000000000000002479_0000000000009017083 size 0 bytes.
2019-11-12 00:42:22,008 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 00:42:22,008 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002478-0000000000000002479 expecting start txid #2478
2019-11-12 00:42:22,008 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002478-0000000000000002479
2019-11-12 00:42:22,008 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002478-0000000000000002479 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 00:42:22,010 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002479 using no compression
2019-11-12 00:42:22,020 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002479 of size 46518 bytes saved in 0 seconds.
2019-11-12 00:42:22,046 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2477
2019-11-12 00:42:22,046 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002475, cpktTxId=0000000000000002475)
2019-11-12 00:42:22,066 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2479 to namenode at http://um1:50070 in 0.012 seconds
2019-11-12 00:42:22,066 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 00:52:22,165 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 00:52:22,165 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2480&endTxId=2481&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 00:52:22,170 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 00:52:22,170 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002480-0000000000000002481_0000000000009617248 size 0 bytes.
2019-11-12 00:52:22,170 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 00:52:22,170 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002480-0000000000000002481 expecting start txid #2480
2019-11-12 00:52:22,170 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002480-0000000000000002481
2019-11-12 00:52:22,170 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002480-0000000000000002481 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 00:52:22,173 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002481 using no compression
2019-11-12 00:52:22,178 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002481 of size 46518 bytes saved in 0 seconds.
2019-11-12 00:52:22,182 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2479
2019-11-12 00:52:22,182 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002477, cpktTxId=0000000000000002477)
2019-11-12 00:52:22,204 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2481 to namenode at http://um1:50070 in 0.012 seconds
2019-11-12 00:52:22,204 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 01:02:22,347 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 01:02:22,347 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2482&endTxId=2483&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 01:02:22,351 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 01:02:22,351 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002482-0000000000000002483_0000000000010217430 size 0 bytes.
2019-11-12 01:02:22,351 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 01:02:22,351 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002482-0000000000000002483 expecting start txid #2482
2019-11-12 01:02:22,351 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002482-0000000000000002483
2019-11-12 01:02:22,352 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002482-0000000000000002483 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 01:02:22,352 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002483 using no compression
2019-11-12 01:02:22,355 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002483 of size 46518 bytes saved in 0 seconds.
2019-11-12 01:02:22,359 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2481
2019-11-12 01:02:22,359 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002479, cpktTxId=0000000000000002479)
2019-11-12 01:02:22,379 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2483 to namenode at http://um1:50070 in 0.015 seconds
2019-11-12 01:02:22,379 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 01:12:22,536 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 01:12:22,536 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2484&endTxId=2485&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 01:12:22,540 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 01:12:22,540 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002484-0000000000000002485_0000000000010817619 size 0 bytes.
2019-11-12 01:12:22,540 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 01:12:22,540 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002484-0000000000000002485 expecting start txid #2484
2019-11-12 01:12:22,540 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002484-0000000000000002485
2019-11-12 01:12:22,541 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002484-0000000000000002485 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 01:12:22,541 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002485 using no compression
2019-11-12 01:12:22,544 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002485 of size 46518 bytes saved in 0 seconds.
2019-11-12 01:12:22,552 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2483
2019-11-12 01:12:22,552 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002481, cpktTxId=0000000000000002481)
2019-11-12 01:12:22,575 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2485 to namenode at http://um1:50070 in 0.011 seconds
2019-11-12 01:12:22,575 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 01:22:22,707 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 01:22:22,707 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2486&endTxId=2487&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 01:22:22,712 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 01:22:22,713 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002486-0000000000000002487_0000000000011417790 size 0 bytes.
2019-11-12 01:22:22,713 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 01:22:22,713 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002486-0000000000000002487 expecting start txid #2486
2019-11-12 01:22:22,713 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002486-0000000000000002487
2019-11-12 01:22:22,713 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002486-0000000000000002487 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 01:22:22,715 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002487 using no compression
2019-11-12 01:22:22,718 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002487 of size 46518 bytes saved in 0 seconds.
2019-11-12 01:22:22,721 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2485
2019-11-12 01:22:22,721 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002483, cpktTxId=0000000000000002483)
2019-11-12 01:22:22,751 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2487 to namenode at http://um1:50070 in 0.013 seconds
2019-11-12 01:22:22,751 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 01:32:22,922 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 01:32:22,923 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2488&endTxId=2489&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 01:32:22,928 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 01:32:22,928 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002488-0000000000000002489_0000000000012018005 size 0 bytes.
2019-11-12 01:32:22,928 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 01:32:22,928 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002488-0000000000000002489 expecting start txid #2488
2019-11-12 01:32:22,928 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002488-0000000000000002489
2019-11-12 01:32:22,928 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002488-0000000000000002489 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 01:32:22,929 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002489 using no compression
2019-11-12 01:32:22,932 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002489 of size 46518 bytes saved in 0 seconds.
2019-11-12 01:32:22,934 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2487
2019-11-12 01:32:22,934 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002485, cpktTxId=0000000000000002485)
2019-11-12 01:32:22,959 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2489 to namenode at http://um1:50070 in 0.011 seconds
2019-11-12 01:32:22,959 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 01:42:23,082 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 01:42:23,082 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2490&endTxId=2491&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 01:42:23,091 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-11-12 01:42:23,092 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002490-0000000000000002491_0000000000012618165 size 0 bytes.
2019-11-12 01:42:23,092 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 01:42:23,092 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002490-0000000000000002491 expecting start txid #2490
2019-11-12 01:42:23,092 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002490-0000000000000002491
2019-11-12 01:42:23,092 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002490-0000000000000002491 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 01:42:23,092 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002491 using no compression
2019-11-12 01:42:23,095 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002491 of size 46518 bytes saved in 0 seconds.
2019-11-12 01:42:23,098 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2489
2019-11-12 01:42:23,098 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002487, cpktTxId=0000000000000002487)
2019-11-12 01:42:23,118 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2491 to namenode at http://um1:50070 in 0.011 seconds
2019-11-12 01:42:23,118 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 01:52:23,301 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 01:52:23,301 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2492&endTxId=2493&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 01:52:23,306 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 01:52:23,306 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002492-0000000000000002493_0000000000013218384 size 0 bytes.
2019-11-12 01:52:23,306 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 01:52:23,306 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002492-0000000000000002493 expecting start txid #2492
2019-11-12 01:52:23,306 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002492-0000000000000002493
2019-11-12 01:52:23,306 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002492-0000000000000002493 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 01:52:23,307 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002493 using no compression
2019-11-12 01:52:23,309 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002493 of size 46518 bytes saved in 0 seconds.
2019-11-12 01:52:23,311 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2491
2019-11-12 01:52:23,311 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002489, cpktTxId=0000000000000002489)
2019-11-12 01:52:23,325 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2493 to namenode at http://um1:50070 in 0.01 seconds
2019-11-12 01:52:23,326 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 02:02:23,454 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 02:02:23,454 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2494&endTxId=2495&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 02:02:23,462 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 02:02:23,462 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002494-0000000000000002495_0000000000013818537 size 0 bytes.
2019-11-12 02:02:23,463 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 02:02:23,463 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002494-0000000000000002495 expecting start txid #2494
2019-11-12 02:02:23,463 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002494-0000000000000002495
2019-11-12 02:02:23,463 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002494-0000000000000002495 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 02:02:23,464 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002495 using no compression
2019-11-12 02:02:23,466 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002495 of size 46518 bytes saved in 0 seconds.
2019-11-12 02:02:23,469 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2493
2019-11-12 02:02:23,469 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002491, cpktTxId=0000000000000002491)
2019-11-12 02:02:23,502 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2495 to namenode at http://um1:50070 in 0.021 seconds
2019-11-12 02:02:23,502 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 02:12:24,181 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 02:12:24,181 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2496&endTxId=2497&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 02:12:24,334 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.15s at 0.00 KB/s
2019-11-12 02:12:24,334 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002496-0000000000000002497_0000000000014419263 size 0 bytes.
2019-11-12 02:12:24,334 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 02:12:24,334 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002496-0000000000000002497 expecting start txid #2496
2019-11-12 02:12:24,334 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002496-0000000000000002497
2019-11-12 02:12:24,334 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002496-0000000000000002497 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 02:12:24,336 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002497 using no compression
2019-11-12 02:12:24,340 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002497 of size 46518 bytes saved in 0 seconds.
2019-11-12 02:12:24,413 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2495
2019-11-12 02:12:24,413 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002493, cpktTxId=0000000000000002493)
2019-11-12 02:12:24,465 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2497 to namenode at http://um1:50070 in 0.012 seconds
2019-11-12 02:12:24,465 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 02:22:24,677 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 02:22:24,677 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2498&endTxId=2499&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 02:22:24,685 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-11-12 02:22:24,686 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002498-0000000000000002499_0000000000015019759 size 0 bytes.
2019-11-12 02:22:24,686 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 02:22:24,686 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002498-0000000000000002499 expecting start txid #2498
2019-11-12 02:22:24,686 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002498-0000000000000002499
2019-11-12 02:22:24,686 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002498-0000000000000002499 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 02:22:24,686 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002499 using no compression
2019-11-12 02:22:24,690 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002499 of size 46518 bytes saved in 0 seconds.
2019-11-12 02:22:24,697 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2497
2019-11-12 02:22:24,697 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002495, cpktTxId=0000000000000002495)
2019-11-12 02:22:24,753 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2499 to namenode at http://um1:50070 in 0.05 seconds
2019-11-12 02:22:24,753 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 02:32:24,929 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 02:32:24,930 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2500&endTxId=2501&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 02:32:24,935 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 02:32:24,935 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002500-0000000000000002501_0000000000015620012 size 0 bytes.
2019-11-12 02:32:24,935 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 02:32:24,935 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002500-0000000000000002501 expecting start txid #2500
2019-11-12 02:32:24,935 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002500-0000000000000002501
2019-11-12 02:32:24,935 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002500-0000000000000002501 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 02:32:24,936 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002501 using no compression
2019-11-12 02:32:24,939 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002501 of size 46518 bytes saved in 0 seconds.
2019-11-12 02:32:24,942 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2499
2019-11-12 02:32:24,942 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002497, cpktTxId=0000000000000002497)
2019-11-12 02:32:24,984 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2501 to namenode at http://um1:50070 in 0.03 seconds
2019-11-12 02:32:24,985 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 02:42:25,128 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 02:42:25,128 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2502&endTxId=2503&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 02:42:25,136 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 02:42:25,136 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002502-0000000000000002503_0000000000016220210 size 0 bytes.
2019-11-12 02:42:25,136 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 02:42:25,136 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002502-0000000000000002503 expecting start txid #2502
2019-11-12 02:42:25,136 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002502-0000000000000002503
2019-11-12 02:42:25,136 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002502-0000000000000002503 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 02:42:25,137 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002503 using no compression
2019-11-12 02:42:25,141 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002503 of size 46518 bytes saved in 0 seconds.
2019-11-12 02:42:25,144 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2501
2019-11-12 02:42:25,144 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002499, cpktTxId=0000000000000002499)
2019-11-12 02:42:25,160 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2503 to namenode at http://um1:50070 in 0.011 seconds
2019-11-12 02:42:25,160 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 02:52:25,332 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 02:52:25,332 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2504&endTxId=2505&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 02:52:25,339 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 02:52:25,339 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002504-0000000000000002505_0000000000016820415 size 0 bytes.
2019-11-12 02:52:25,339 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 02:52:25,339 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002504-0000000000000002505 expecting start txid #2504
2019-11-12 02:52:25,339 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002504-0000000000000002505
2019-11-12 02:52:25,339 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002504-0000000000000002505 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 02:52:25,340 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002505 using no compression
2019-11-12 02:52:25,343 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002505 of size 46518 bytes saved in 0 seconds.
2019-11-12 02:52:25,346 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2503
2019-11-12 02:52:25,346 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002501, cpktTxId=0000000000000002501)
2019-11-12 02:52:25,389 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2505 to namenode at http://um1:50070 in 0.027 seconds
2019-11-12 02:52:25,389 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 03:02:25,578 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 03:02:25,578 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2506&endTxId=2507&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 03:02:25,587 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-11-12 03:02:25,587 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002506-0000000000000002507_0000000000017420661 size 0 bytes.
2019-11-12 03:02:25,587 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 03:02:25,587 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002506-0000000000000002507 expecting start txid #2506
2019-11-12 03:02:25,587 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002506-0000000000000002507
2019-11-12 03:02:25,587 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002506-0000000000000002507 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 03:02:25,588 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002507 using no compression
2019-11-12 03:02:25,598 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002507 of size 46518 bytes saved in 0 seconds.
2019-11-12 03:02:25,603 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2505
2019-11-12 03:02:25,603 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002503, cpktTxId=0000000000000002503)
2019-11-12 03:02:25,690 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2507 to namenode at http://um1:50070 in 0.075 seconds
2019-11-12 03:02:25,690 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 03:12:25,884 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 03:12:25,884 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2508&endTxId=2509&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 03:12:25,888 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 03:12:25,889 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002508-0000000000000002509_0000000000018020966 size 0 bytes.
2019-11-12 03:12:25,889 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 03:12:25,889 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002508-0000000000000002509 expecting start txid #2508
2019-11-12 03:12:25,889 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002508-0000000000000002509
2019-11-12 03:12:25,889 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002508-0000000000000002509 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 03:12:25,890 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002509 using no compression
2019-11-12 03:12:25,893 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002509 of size 46518 bytes saved in 0 seconds.
2019-11-12 03:12:25,897 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2507
2019-11-12 03:12:25,897 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002505, cpktTxId=0000000000000002505)
2019-11-12 03:12:25,925 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2509 to namenode at http://um1:50070 in 0.02 seconds
2019-11-12 03:12:25,925 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 03:22:26,101 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 03:22:26,101 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2510&endTxId=2511&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 03:22:26,105 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 03:22:26,105 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002510-0000000000000002511_0000000000018621184 size 0 bytes.
2019-11-12 03:22:26,105 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 03:22:26,106 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002510-0000000000000002511 expecting start txid #2510
2019-11-12 03:22:26,106 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002510-0000000000000002511
2019-11-12 03:22:26,106 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002510-0000000000000002511 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 03:22:26,106 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002511 using no compression
2019-11-12 03:22:26,116 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002511 of size 46518 bytes saved in 0 seconds.
2019-11-12 03:22:26,120 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2509
2019-11-12 03:22:26,120 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002507, cpktTxId=0000000000000002507)
2019-11-12 03:22:26,140 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2511 to namenode at http://um1:50070 in 0.014 seconds
2019-11-12 03:22:26,141 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 03:32:26,334 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 03:32:26,334 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2512&endTxId=2513&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 03:32:26,360 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 03:32:26,360 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002512-0000000000000002513_0000000000019221417 size 0 bytes.
2019-11-12 03:32:26,361 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 03:32:26,361 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002512-0000000000000002513 expecting start txid #2512
2019-11-12 03:32:26,361 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002512-0000000000000002513
2019-11-12 03:32:26,361 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002512-0000000000000002513 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 03:32:26,362 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002513 using no compression
2019-11-12 03:32:26,367 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002513 of size 46518 bytes saved in 0 seconds.
2019-11-12 03:32:26,370 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2511
2019-11-12 03:32:26,370 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002509, cpktTxId=0000000000000002509)
2019-11-12 03:32:26,384 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2513 to namenode at http://um1:50070 in 0.009 seconds
2019-11-12 03:32:26,384 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 03:42:26,527 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 03:42:26,527 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2514&endTxId=2515&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 03:42:26,531 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 03:42:26,531 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002514-0000000000000002515_0000000000019821610 size 0 bytes.
2019-11-12 03:42:26,531 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 03:42:26,531 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002514-0000000000000002515 expecting start txid #2514
2019-11-12 03:42:26,531 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002514-0000000000000002515
2019-11-12 03:42:26,531 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002514-0000000000000002515 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 03:42:26,532 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002515 using no compression
2019-11-12 03:42:26,540 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002515 of size 46518 bytes saved in 0 seconds.
2019-11-12 03:42:26,543 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2513
2019-11-12 03:42:26,543 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002511, cpktTxId=0000000000000002511)
2019-11-12 03:42:26,560 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2515 to namenode at http://um1:50070 in 0.014 seconds
2019-11-12 03:42:26,560 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 03:52:26,657 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 03:52:26,657 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2516&endTxId=2517&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 03:52:26,664 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 03:52:26,664 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002516-0000000000000002517_0000000000020421740 size 0 bytes.
2019-11-12 03:52:26,664 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 03:52:26,664 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002516-0000000000000002517 expecting start txid #2516
2019-11-12 03:52:26,664 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002516-0000000000000002517
2019-11-12 03:52:26,665 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002516-0000000000000002517 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 03:52:26,665 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002517 using no compression
2019-11-12 03:52:26,671 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002517 of size 46518 bytes saved in 0 seconds.
2019-11-12 03:52:26,674 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2515
2019-11-12 03:52:26,674 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002513, cpktTxId=0000000000000002513)
2019-11-12 03:52:26,690 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2517 to namenode at http://um1:50070 in 0.011 seconds
2019-11-12 03:52:26,690 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 04:02:26,987 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 04:02:26,988 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2518&endTxId=2519&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 04:02:26,998 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-11-12 04:02:26,998 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002518-0000000000000002519_0000000000021022071 size 0 bytes.
2019-11-12 04:02:26,998 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 04:02:26,998 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002518-0000000000000002519 expecting start txid #2518
2019-11-12 04:02:26,998 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002518-0000000000000002519
2019-11-12 04:02:26,999 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002518-0000000000000002519 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 04:02:27,009 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002519 using no compression
2019-11-12 04:02:27,014 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002519 of size 46518 bytes saved in 0 seconds.
2019-11-12 04:02:27,018 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2517
2019-11-12 04:02:27,018 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002515, cpktTxId=0000000000000002515)
2019-11-12 04:02:27,050 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2519 to namenode at http://um1:50070 in 0.021 seconds
2019-11-12 04:02:27,050 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 04:12:27,205 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 04:12:27,205 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2520&endTxId=2521&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 04:12:27,210 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 04:12:27,210 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002520-0000000000000002521_0000000000021622288 size 0 bytes.
2019-11-12 04:12:27,210 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 04:12:27,210 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002520-0000000000000002521 expecting start txid #2520
2019-11-12 04:12:27,210 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002520-0000000000000002521
2019-11-12 04:12:27,210 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002520-0000000000000002521 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 04:12:27,211 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002521 using no compression
2019-11-12 04:12:27,214 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002521 of size 46518 bytes saved in 0 seconds.
2019-11-12 04:12:27,217 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2519
2019-11-12 04:12:27,217 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002517, cpktTxId=0000000000000002517)
2019-11-12 04:12:27,241 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2521 to namenode at http://um1:50070 in 0.019 seconds
2019-11-12 04:12:27,244 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 04:22:27,370 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 04:22:27,370 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2522&endTxId=2523&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 04:22:27,379 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-11-12 04:22:27,379 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002522-0000000000000002523_0000000000022222453 size 0 bytes.
2019-11-12 04:22:27,379 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 04:22:27,379 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002522-0000000000000002523 expecting start txid #2522
2019-11-12 04:22:27,379 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002522-0000000000000002523
2019-11-12 04:22:27,379 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002522-0000000000000002523 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 04:22:27,380 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002523 using no compression
2019-11-12 04:22:27,383 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002523 of size 46518 bytes saved in 0 seconds.
2019-11-12 04:22:27,385 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2521
2019-11-12 04:22:27,385 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002519, cpktTxId=0000000000000002519)
2019-11-12 04:22:27,399 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2523 to namenode at http://um1:50070 in 0.008 seconds
2019-11-12 04:22:27,399 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 04:32:27,508 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 04:32:27,509 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2524&endTxId=2525&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 04:32:27,512 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 04:32:27,512 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002524-0000000000000002525_0000000000022822591 size 0 bytes.
2019-11-12 04:32:27,512 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 04:32:27,512 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002524-0000000000000002525 expecting start txid #2524
2019-11-12 04:32:27,512 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002524-0000000000000002525
2019-11-12 04:32:27,512 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002524-0000000000000002525 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 04:32:27,512 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002525 using no compression
2019-11-12 04:32:27,515 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002525 of size 46518 bytes saved in 0 seconds.
2019-11-12 04:32:27,517 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2523
2019-11-12 04:32:27,517 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002521, cpktTxId=0000000000000002521)
2019-11-12 04:32:27,533 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2525 to namenode at http://um1:50070 in 0.012 seconds
2019-11-12 04:32:27,533 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 04:42:27,665 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 04:42:27,665 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2526&endTxId=2527&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 04:42:27,669 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 04:42:27,669 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002526-0000000000000002527_0000000000023422748 size 0 bytes.
2019-11-12 04:42:27,669 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 04:42:27,669 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002526-0000000000000002527 expecting start txid #2526
2019-11-12 04:42:27,669 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002526-0000000000000002527
2019-11-12 04:42:27,669 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002526-0000000000000002527 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 04:42:27,678 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002527 using no compression
2019-11-12 04:42:27,682 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002527 of size 46518 bytes saved in 0 seconds.
2019-11-12 04:42:27,684 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2525
2019-11-12 04:42:27,684 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002523, cpktTxId=0000000000000002523)
2019-11-12 04:42:27,700 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2527 to namenode at http://um1:50070 in 0.012 seconds
2019-11-12 04:42:27,701 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 04:52:27,797 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 04:52:27,798 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2528&endTxId=2529&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 04:52:27,802 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 04:52:27,802 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002528-0000000000000002529_0000000000024022880 size 0 bytes.
2019-11-12 04:52:27,802 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 04:52:27,802 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002528-0000000000000002529 expecting start txid #2528
2019-11-12 04:52:27,802 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002528-0000000000000002529
2019-11-12 04:52:27,802 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002528-0000000000000002529 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 04:52:27,802 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002529 using no compression
2019-11-12 04:52:27,805 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002529 of size 46518 bytes saved in 0 seconds.
2019-11-12 04:52:27,808 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2527
2019-11-12 04:52:27,808 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002525, cpktTxId=0000000000000002525)
2019-11-12 04:52:27,821 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2529 to namenode at http://um1:50070 in 0.009 seconds
2019-11-12 04:52:27,822 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 05:02:27,923 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 05:02:27,923 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2530&endTxId=2531&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 05:02:27,928 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 05:02:27,928 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002530-0000000000000002531_0000000000024623006 size 0 bytes.
2019-11-12 05:02:27,928 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 05:02:27,928 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002530-0000000000000002531 expecting start txid #2530
2019-11-12 05:02:27,928 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002530-0000000000000002531
2019-11-12 05:02:27,928 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002530-0000000000000002531 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 05:02:27,929 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002531 using no compression
2019-11-12 05:02:27,932 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002531 of size 46518 bytes saved in 0 seconds.
2019-11-12 05:02:27,934 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2529
2019-11-12 05:02:27,934 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002527, cpktTxId=0000000000000002527)
2019-11-12 05:02:27,959 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2531 to namenode at http://um1:50070 in 0.02 seconds
2019-11-12 05:02:27,959 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 05:12:28,111 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 05:12:28,111 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2532&endTxId=2533&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 05:12:28,116 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 05:12:28,116 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002532-0000000000000002533_0000000000025223194 size 0 bytes.
2019-11-12 05:12:28,116 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 05:12:28,116 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002532-0000000000000002533 expecting start txid #2532
2019-11-12 05:12:28,116 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002532-0000000000000002533
2019-11-12 05:12:28,117 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002532-0000000000000002533 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 05:12:28,117 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002533 using no compression
2019-11-12 05:12:28,138 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002533 of size 46518 bytes saved in 0 seconds.
2019-11-12 05:12:28,150 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2531
2019-11-12 05:12:28,150 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002529, cpktTxId=0000000000000002529)
2019-11-12 05:12:28,172 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2533 to namenode at http://um1:50070 in 0.012 seconds
2019-11-12 05:12:28,172 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 05:22:28,282 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 05:22:28,282 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2534&endTxId=2535&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 05:22:28,289 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 05:22:28,289 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002534-0000000000000002535_0000000000025823365 size 0 bytes.
2019-11-12 05:22:28,289 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 05:22:28,289 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002534-0000000000000002535 expecting start txid #2534
2019-11-12 05:22:28,289 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002534-0000000000000002535
2019-11-12 05:22:28,289 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002534-0000000000000002535 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 05:22:28,290 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002535 using no compression
2019-11-12 05:22:28,292 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002535 of size 46518 bytes saved in 0 seconds.
2019-11-12 05:22:28,295 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2533
2019-11-12 05:22:28,295 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002531, cpktTxId=0000000000000002531)
2019-11-12 05:22:28,323 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2535 to namenode at http://um1:50070 in 0.023 seconds
2019-11-12 05:22:28,323 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 05:32:28,464 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 05:32:28,465 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2536&endTxId=2537&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 05:32:28,473 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 05:32:28,473 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002536-0000000000000002537_0000000000026423547 size 0 bytes.
2019-11-12 05:32:28,473 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 05:32:28,473 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002536-0000000000000002537 expecting start txid #2536
2019-11-12 05:32:28,474 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002536-0000000000000002537
2019-11-12 05:32:28,474 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002536-0000000000000002537 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 05:32:28,474 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002537 using no compression
2019-11-12 05:32:28,476 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002537 of size 46518 bytes saved in 0 seconds.
2019-11-12 05:32:28,479 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2535
2019-11-12 05:32:28,479 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002533, cpktTxId=0000000000000002533)
2019-11-12 05:32:28,499 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2537 to namenode at http://um1:50070 in 0.015 seconds
2019-11-12 05:32:28,499 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 05:42:28,669 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 05:42:28,669 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2538&endTxId=2539&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 05:42:28,678 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 05:42:28,680 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002538-0000000000000002539_0000000000027023752 size 0 bytes.
2019-11-12 05:42:28,680 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 05:42:28,680 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002538-0000000000000002539 expecting start txid #2538
2019-11-12 05:42:28,680 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002538-0000000000000002539
2019-11-12 05:42:28,680 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002538-0000000000000002539 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 05:42:28,681 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002539 using no compression
2019-11-12 05:42:28,687 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002539 of size 46518 bytes saved in 0 seconds.
2019-11-12 05:42:28,693 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2537
2019-11-12 05:42:28,693 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002535, cpktTxId=0000000000000002535)
2019-11-12 05:42:28,716 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2539 to namenode at http://um1:50070 in 0.015 seconds
2019-11-12 05:42:28,716 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 05:52:28,901 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 05:52:28,902 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2540&endTxId=2541&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 05:52:28,918 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-11-12 05:52:28,918 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002540-0000000000000002541_0000000000027623984 size 0 bytes.
2019-11-12 05:52:28,918 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 05:52:28,918 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002540-0000000000000002541 expecting start txid #2540
2019-11-12 05:52:28,918 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002540-0000000000000002541
2019-11-12 05:52:28,919 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002540-0000000000000002541 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 05:52:28,920 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002541 using no compression
2019-11-12 05:52:28,962 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002541 of size 46518 bytes saved in 0 seconds.
2019-11-12 05:52:28,972 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2539
2019-11-12 05:52:28,972 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002537, cpktTxId=0000000000000002537)
2019-11-12 05:52:29,049 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2541 to namenode at http://um1:50070 in 0.048 seconds
2019-11-12 05:52:29,050 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 06:29:38,426 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 06:29:38,426 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2542&endTxId=2543&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 06:29:38,442 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-11-12 06:29:38,443 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002542-0000000000000002543_0000000000028224258 size 0 bytes.
2019-11-12 06:29:38,443 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 06:29:38,443 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002542-0000000000000002543 expecting start txid #2542
2019-11-12 06:29:38,443 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002542-0000000000000002543
2019-11-12 06:29:38,443 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002542-0000000000000002543 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 06:29:38,444 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002543 using no compression
2019-11-12 06:29:38,449 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002543 of size 46518 bytes saved in 0 seconds.
2019-11-12 06:29:38,466 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2541
2019-11-12 06:29:38,466 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002539, cpktTxId=0000000000000002539)
2019-11-12 06:29:38,496 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2543 to namenode at http://um1:50070 in 0.016 seconds
2019-11-12 06:29:38,497 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 07:30:08,060 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 07:30:08,060 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2544&endTxId=2545&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 07:30:08,064 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 07:30:08,064 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002544-0000000000000002545_0000000000028824476 size 0 bytes.
2019-11-12 07:30:08,064 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 07:30:08,064 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002544-0000000000000002545 expecting start txid #2544
2019-11-12 07:30:08,064 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002544-0000000000000002545
2019-11-12 07:30:08,064 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002544-0000000000000002545 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 07:30:08,064 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002545 using no compression
2019-11-12 07:30:08,068 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002545 of size 46518 bytes saved in 0 seconds.
2019-11-12 07:30:08,071 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2543
2019-11-12 07:30:08,071 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002541, cpktTxId=0000000000000002541)
2019-11-12 07:30:08,096 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2545 to namenode at http://um1:50070 in 0.019 seconds
2019-11-12 07:30:08,096 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 07:40:08,232 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 07:40:08,232 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2546&endTxId=2547&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 07:40:08,239 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 07:40:08,239 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002546-0000000000000002547_0000000000029424648 size 0 bytes.
2019-11-12 07:40:08,239 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 07:40:08,239 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002546-0000000000000002547 expecting start txid #2546
2019-11-12 07:40:08,239 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002546-0000000000000002547
2019-11-12 07:40:08,241 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002546-0000000000000002547 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 07:40:08,241 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002547 using no compression
2019-11-12 07:40:08,247 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002547 of size 46518 bytes saved in 0 seconds.
2019-11-12 07:40:08,252 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2545
2019-11-12 07:40:08,252 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002543, cpktTxId=0000000000000002543)
2019-11-12 07:40:08,279 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2547 to namenode at http://um1:50070 in 0.017 seconds
2019-11-12 07:40:08,280 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 07:50:08,524 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 07:50:08,524 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2548&endTxId=2549&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 07:50:08,539 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-11-12 07:50:08,539 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002548-0000000000000002549_0000000000030024940 size 0 bytes.
2019-11-12 07:50:08,540 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 07:50:08,540 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002548-0000000000000002549 expecting start txid #2548
2019-11-12 07:50:08,540 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002548-0000000000000002549
2019-11-12 07:50:08,541 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002548-0000000000000002549 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 07:50:08,542 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002549 using no compression
2019-11-12 07:50:08,551 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002549 of size 46518 bytes saved in 0 seconds.
2019-11-12 07:50:08,556 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2547
2019-11-12 07:50:08,556 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002545, cpktTxId=0000000000000002545)
2019-11-12 07:50:08,586 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2549 to namenode at http://um1:50070 in 0.019 seconds
2019-11-12 07:50:08,586 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 08:00:08,760 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 08:00:08,760 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2550&endTxId=2551&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 08:00:08,767 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 08:00:08,767 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002550-0000000000000002551_0000000000030625177 size 0 bytes.
2019-11-12 08:00:08,767 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 08:00:08,767 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002550-0000000000000002551 expecting start txid #2550
2019-11-12 08:00:08,767 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002550-0000000000000002551
2019-11-12 08:00:08,767 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002550-0000000000000002551 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 08:00:08,768 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002551 using no compression
2019-11-12 08:00:08,772 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002551 of size 46518 bytes saved in 0 seconds.
2019-11-12 08:00:08,775 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2549
2019-11-12 08:00:08,775 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002547, cpktTxId=0000000000000002547)
2019-11-12 08:00:08,797 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2551 to namenode at http://um1:50070 in 0.014 seconds
2019-11-12 08:00:08,797 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 08:10:08,981 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 08:10:08,981 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2552&endTxId=2553&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 08:10:08,988 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 08:10:08,988 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002552-0000000000000002553_0000000000031225397 size 0 bytes.
2019-11-12 08:10:08,988 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 08:10:08,988 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002552-0000000000000002553 expecting start txid #2552
2019-11-12 08:10:08,988 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002552-0000000000000002553
2019-11-12 08:10:08,988 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002552-0000000000000002553 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 08:10:08,989 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002553 using no compression
2019-11-12 08:10:08,993 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002553 of size 46518 bytes saved in 0 seconds.
2019-11-12 08:10:08,997 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2551
2019-11-12 08:10:08,997 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002549, cpktTxId=0000000000000002549)
2019-11-12 08:10:09,036 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2553 to namenode at http://um1:50070 in 0.02 seconds
2019-11-12 08:10:09,036 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 08:20:09,209 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 08:20:09,209 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2554&endTxId=2555&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 08:20:09,217 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 08:20:09,217 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002554-0000000000000002555_0000000000031825625 size 0 bytes.
2019-11-12 08:20:09,217 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 08:20:09,217 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002554-0000000000000002555 expecting start txid #2554
2019-11-12 08:20:09,217 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002554-0000000000000002555
2019-11-12 08:20:09,218 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002554-0000000000000002555 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 08:20:09,220 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002555 using no compression
2019-11-12 08:20:09,224 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002555 of size 46518 bytes saved in 0 seconds.
2019-11-12 08:20:09,231 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2553
2019-11-12 08:20:09,231 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002551, cpktTxId=0000000000000002551)
2019-11-12 08:20:09,255 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2555 to namenode at http://um1:50070 in 0.018 seconds
2019-11-12 08:20:09,260 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 08:30:09,397 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 08:30:09,397 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2556&endTxId=2557&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 08:30:09,403 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 08:30:09,403 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002556-0000000000000002557_0000000000032425813 size 0 bytes.
2019-11-12 08:30:09,403 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 08:30:09,403 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002556-0000000000000002557 expecting start txid #2556
2019-11-12 08:30:09,403 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002556-0000000000000002557
2019-11-12 08:30:09,403 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002556-0000000000000002557 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 08:30:09,404 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002557 using no compression
2019-11-12 08:30:09,410 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002557 of size 46518 bytes saved in 0 seconds.
2019-11-12 08:30:09,414 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2555
2019-11-12 08:30:09,414 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002553, cpktTxId=0000000000000002553)
2019-11-12 08:30:09,437 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2557 to namenode at http://um1:50070 in 0.012 seconds
2019-11-12 08:30:09,437 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 08:40:09,690 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 08:40:09,691 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2558&endTxId=2559&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 08:40:09,696 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 08:40:09,696 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002558-0000000000000002559_0000000000033026107 size 0 bytes.
2019-11-12 08:40:09,697 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 08:40:09,697 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002558-0000000000000002559 expecting start txid #2558
2019-11-12 08:40:09,697 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002558-0000000000000002559
2019-11-12 08:40:09,697 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002558-0000000000000002559 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 08:40:09,699 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002559 using no compression
2019-11-12 08:40:09,705 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002559 of size 46518 bytes saved in 0 seconds.
2019-11-12 08:40:09,709 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2557
2019-11-12 08:40:09,710 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002555, cpktTxId=0000000000000002555)
2019-11-12 08:40:09,731 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2559 to namenode at http://um1:50070 in 0.013 seconds
2019-11-12 08:40:09,731 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 08:50:09,849 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 08:50:09,850 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2560&endTxId=2561&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 08:50:09,857 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 08:50:09,857 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002560-0000000000000002561_0000000000033626266 size 0 bytes.
2019-11-12 08:50:09,857 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 08:50:09,857 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002560-0000000000000002561 expecting start txid #2560
2019-11-12 08:50:09,858 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002560-0000000000000002561
2019-11-12 08:50:09,858 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002560-0000000000000002561 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 08:50:09,858 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002561 using no compression
2019-11-12 08:50:09,864 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002561 of size 46518 bytes saved in 0 seconds.
2019-11-12 08:50:09,869 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2559
2019-11-12 08:50:09,869 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002557, cpktTxId=0000000000000002557)
2019-11-12 08:50:09,897 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2561 to namenode at http://um1:50070 in 0.018 seconds
2019-11-12 08:50:09,897 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 13:13:44,008 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.251.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-11-12 13:13:44,021 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-11-12 13:13:44,674 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-11-12 13:13:44,761 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-11-12 13:13:44,761 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-11-12 13:13:44,921 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-11-12 13:13:44,921 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-11-12 13:13:45,035 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 3104@um2
2019-11-12 13:13:45,109 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 3104@um2
2019-11-12 13:13:45,129 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-11-12 13:13:45,146 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-11-12 13:13:45,195 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-11-12 13:13:45,195 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-11-12 13:13:45,197 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-11-12 13:13:45,198 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Nov 12 13:13:45
2019-11-12 13:13:45,200 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-11-12 13:13:45,200 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-11-12 13:13:45,201 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-11-12 13:13:45,201 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-11-12 13:13:45,211 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-11-12 13:13:45,212 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-11-12 13:13:45,212 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-11-12 13:13:45,212 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-11-12 13:13:45,212 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-11-12 13:13:45,212 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-11-12 13:13:45,212 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-11-12 13:13:45,212 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-11-12 13:13:45,212 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-11-12 13:13:45,212 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-11-12 13:13:45,213 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-11-12 13:13:45,213 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-11-12 13:13:45,214 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-11-12 13:13:45,589 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-11-12 13:13:45,589 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-11-12 13:13:45,589 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-11-12 13:13:45,589 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-11-12 13:13:45,606 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-11-12 13:13:45,621 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-11-12 13:13:45,621 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-11-12 13:13:45,621 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-11-12 13:13:45,621 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-11-12 13:13:45,623 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-11-12 13:13:45,623 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-11-12 13:13:45,623 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-11-12 13:13:45,624 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-11-12 13:13:45,624 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-11-12 13:13:45,624 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-11-12 13:13:45,658 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-11-12 13:13:45,853 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-11-12 13:13:45,857 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-11-12 13:13:45,866 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-12 13:13:45,868 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-11-12 13:13:45,868 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-12 13:13:45,868 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-12 13:13:45,882 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-11-12 13:13:45,882 INFO org.mortbay.log: jetty-6.1.26
2019-11-12 13:13:46,088 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-11-12 13:13:46,088 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-11-12 13:13:46,088 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-11-12 13:13:46,088 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-11-12 13:14:46,407 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-11-12 13:14:46,643 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=2562&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 13:14:46,693 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-11-12 13:14:46,998 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 1285.71 KB/s
2019-11-12 13:14:46,999 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000002562 size 46518 bytes.
2019-11-12 13:14:47,020 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2563&endTxId=2564&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 13:14:47,029 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 13:14:47,029 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002563-0000000000000002564_0000000000009613701 size 0 bytes.
2019-11-12 13:14:47,118 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 484 INodes.
2019-11-12 13:14:47,214 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-11-12 13:14:47,214 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 2562 from /orgz/snnfsi/current/fsimage_0000000000000002562
2019-11-12 13:14:47,215 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 1 entries 205 lookups
2019-11-12 13:14:47,237 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 13:14:47,240 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002563-0000000000000002564 expecting start txid #2563
2019-11-12 13:14:47,240 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002563-0000000000000002564
2019-11-12 13:14:47,259 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002563-0000000000000002564 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 13:14:47,275 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002564 using no compression
2019-11-12 13:14:47,341 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002564 of size 46518 bytes saved in 0 seconds.
2019-11-12 13:14:47,357 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2562
2019-11-12 13:14:47,357 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002561, cpktTxId=0000000000000002561)
2019-11-12 13:14:47,357 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002559, cpktTxId=0000000000000002559)
2019-11-12 13:14:47,440 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2564 to namenode at http://um1:50070 in 0.039 seconds
2019-11-12 13:14:47,441 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 13:24:47,705 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 13:24:47,706 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2565&endTxId=2566&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 13:24:47,718 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 13:24:47,718 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002565-0000000000000002566_0000000000010214390 size 0 bytes.
2019-11-12 13:24:47,719 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 13:24:47,719 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002565-0000000000000002566 expecting start txid #2565
2019-11-12 13:24:47,719 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002565-0000000000000002566
2019-11-12 13:24:47,720 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002565-0000000000000002566 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 13:24:47,725 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002566 using no compression
2019-11-12 13:24:47,749 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002566 of size 46518 bytes saved in 0 seconds.
2019-11-12 13:24:47,762 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2564
2019-11-12 13:24:47,762 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002562, cpktTxId=0000000000000002562)
2019-11-12 13:24:47,820 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2566 to namenode at http://um1:50070 in 0.027 seconds
2019-11-12 13:24:47,821 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 13:34:47,984 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 13:34:47,985 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2567&endTxId=2568&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 13:34:47,997 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 13:34:47,997 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002567-0000000000000002568_0000000000010814669 size 0 bytes.
2019-11-12 13:34:47,997 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 13:34:47,997 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002567-0000000000000002568 expecting start txid #2567
2019-11-12 13:34:47,997 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002567-0000000000000002568
2019-11-12 13:34:47,998 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002567-0000000000000002568 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 13:34:47,999 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002568 using no compression
2019-11-12 13:34:48,017 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002568 of size 46518 bytes saved in 0 seconds.
2019-11-12 13:34:48,022 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2566
2019-11-12 13:34:48,022 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002564, cpktTxId=0000000000000002564)
2019-11-12 13:34:48,051 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2568 to namenode at http://um1:50070 in 0.016 seconds
2019-11-12 13:34:48,051 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 13:44:48,197 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 13:44:48,197 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2569&endTxId=2570&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 13:44:48,203 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 13:44:48,203 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002569-0000000000000002570_0000000000011414882 size 0 bytes.
2019-11-12 13:44:48,204 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 13:44:48,204 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002569-0000000000000002570 expecting start txid #2569
2019-11-12 13:44:48,204 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002569-0000000000000002570
2019-11-12 13:44:48,204 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002569-0000000000000002570 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 13:44:48,208 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002570 using no compression
2019-11-12 13:44:48,226 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002570 of size 46518 bytes saved in 0 seconds.
2019-11-12 13:44:48,230 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2568
2019-11-12 13:44:48,230 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002566, cpktTxId=0000000000000002566)
2019-11-12 13:44:48,262 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2570 to namenode at http://um1:50070 in 0.021 seconds
2019-11-12 13:44:48,262 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 13:54:48,389 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 13:54:48,389 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2571&endTxId=2572&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 13:54:48,394 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 13:54:48,394 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002571-0000000000000002572_0000000000012015074 size 0 bytes.
2019-11-12 13:54:48,395 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 13:54:48,395 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002571-0000000000000002572 expecting start txid #2571
2019-11-12 13:54:48,395 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002571-0000000000000002572
2019-11-12 13:54:48,395 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002571-0000000000000002572 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 13:54:48,396 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002572 using no compression
2019-11-12 13:54:48,403 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002572 of size 46518 bytes saved in 0 seconds.
2019-11-12 13:54:48,406 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2570
2019-11-12 13:54:48,406 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002568, cpktTxId=0000000000000002568)
2019-11-12 13:54:48,433 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2572 to namenode at http://um1:50070 in 0.018 seconds
2019-11-12 13:54:48,433 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 14:04:48,652 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 14:04:48,653 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2573&endTxId=2577&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 14:04:48,658 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 14:04:48,658 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002573-0000000000000002577_0000000000012615338 size 0 bytes.
2019-11-12 14:04:48,659 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 14:04:48,659 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002573-0000000000000002577 expecting start txid #2573
2019-11-12 14:04:48,659 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002573-0000000000000002577
2019-11-12 14:04:48,685 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002573-0000000000000002577 of size 385 edits # 5 loaded in 0 seconds
2019-11-12 14:04:48,685 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002577 using no compression
2019-11-12 14:04:48,691 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002577 of size 46518 bytes saved in 0 seconds.
2019-11-12 14:04:48,706 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2572
2019-11-12 14:04:48,706 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002570, cpktTxId=0000000000000002570)
2019-11-12 14:04:48,731 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2577 to namenode at http://um1:50070 in 0.016 seconds
2019-11-12 14:04:48,732 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 14:14:48,886 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 14:14:48,886 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2578&endTxId=2579&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 14:14:48,891 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 14:14:48,891 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002578-0000000000000002579_0000000000013215571 size 0 bytes.
2019-11-12 14:14:48,891 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 14:14:48,891 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002578-0000000000000002579 expecting start txid #2578
2019-11-12 14:14:48,891 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002578-0000000000000002579
2019-11-12 14:14:48,891 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002578-0000000000000002579 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 14:14:48,892 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002579 using no compression
2019-11-12 14:14:48,899 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002579 of size 46518 bytes saved in 0 seconds.
2019-11-12 14:14:48,909 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2577
2019-11-12 14:14:48,909 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002572, cpktTxId=0000000000000002572)
2019-11-12 14:14:48,940 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2579 to namenode at http://um1:50070 in 0.023 seconds
2019-11-12 14:14:48,940 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 14:24:49,060 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 14:24:49,060 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2580&endTxId=2581&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 14:24:49,065 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 14:24:49,065 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002580-0000000000000002581_0000000000013815745 size 0 bytes.
2019-11-12 14:24:49,065 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 14:24:49,066 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002580-0000000000000002581 expecting start txid #2580
2019-11-12 14:24:49,066 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002580-0000000000000002581
2019-11-12 14:24:49,066 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002580-0000000000000002581 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 14:24:49,069 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002581 using no compression
2019-11-12 14:24:49,078 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002581 of size 46518 bytes saved in 0 seconds.
2019-11-12 14:24:49,083 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2579
2019-11-12 14:24:49,083 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002577, cpktTxId=0000000000000002577)
2019-11-12 14:24:49,109 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2581 to namenode at http://um1:50070 in 0.019 seconds
2019-11-12 14:24:49,109 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 14:34:49,253 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 14:34:49,253 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2582&endTxId=2583&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 14:34:49,258 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 14:34:49,258 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002582-0000000000000002583_0000000000014415938 size 0 bytes.
2019-11-12 14:34:49,259 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 14:34:49,259 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002582-0000000000000002583 expecting start txid #2582
2019-11-12 14:34:49,259 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002582-0000000000000002583
2019-11-12 14:34:49,259 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002582-0000000000000002583 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 14:34:49,260 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002583 using no compression
2019-11-12 14:34:49,265 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002583 of size 46518 bytes saved in 0 seconds.
2019-11-12 14:34:49,283 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2581
2019-11-12 14:34:49,283 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002579, cpktTxId=0000000000000002579)
2019-11-12 14:34:49,318 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2583 to namenode at http://um1:50070 in 0.028 seconds
2019-11-12 14:34:49,318 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 14:44:49,461 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 14:44:49,461 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2584&endTxId=2585&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 14:44:49,468 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 14:44:49,468 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002584-0000000000000002585_0000000000015016146 size 0 bytes.
2019-11-12 14:44:49,468 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 14:44:49,469 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002584-0000000000000002585 expecting start txid #2584
2019-11-12 14:44:49,469 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002584-0000000000000002585
2019-11-12 14:44:49,469 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002584-0000000000000002585 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 14:44:49,470 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002585 using no compression
2019-11-12 14:44:49,475 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002585 of size 46518 bytes saved in 0 seconds.
2019-11-12 14:44:49,478 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2583
2019-11-12 14:44:49,478 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002581, cpktTxId=0000000000000002581)
2019-11-12 14:44:49,511 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2585 to namenode at http://um1:50070 in 0.025 seconds
2019-11-12 14:44:49,512 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 14:54:49,630 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 14:54:49,630 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2586&endTxId=2587&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 14:54:49,637 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 14:54:49,637 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002586-0000000000000002587_0000000000015616315 size 0 bytes.
2019-11-12 14:54:49,638 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 14:54:49,638 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002586-0000000000000002587 expecting start txid #2586
2019-11-12 14:54:49,638 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002586-0000000000000002587
2019-11-12 14:54:49,638 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002586-0000000000000002587 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 14:54:49,641 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002587 using no compression
2019-11-12 14:54:49,646 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002587 of size 46518 bytes saved in 0 seconds.
2019-11-12 14:54:49,649 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2585
2019-11-12 14:54:49,649 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002583, cpktTxId=0000000000000002583)
2019-11-12 14:54:49,677 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2587 to namenode at http://um1:50070 in 0.02 seconds
2019-11-12 14:54:49,677 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 15:04:49,807 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 15:04:49,807 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2588&endTxId=2589&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 15:04:49,812 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 15:04:49,813 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002588-0000000000000002589_0000000000016216492 size 0 bytes.
2019-11-12 15:04:49,813 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 15:04:49,813 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002588-0000000000000002589 expecting start txid #2588
2019-11-12 15:04:49,813 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002588-0000000000000002589
2019-11-12 15:04:49,813 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002588-0000000000000002589 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 15:04:49,814 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002589 using no compression
2019-11-12 15:04:49,818 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002589 of size 46518 bytes saved in 0 seconds.
2019-11-12 15:04:49,824 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2587
2019-11-12 15:04:49,824 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002585, cpktTxId=0000000000000002585)
2019-11-12 15:04:49,849 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2589 to namenode at http://um1:50070 in 0.015 seconds
2019-11-12 15:04:49,849 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 15:14:49,974 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 15:14:49,975 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2590&endTxId=2591&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 15:14:49,985 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-11-12 15:14:49,985 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002590-0000000000000002591_0000000000016816659 size 0 bytes.
2019-11-12 15:14:49,985 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 15:14:49,985 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002590-0000000000000002591 expecting start txid #2590
2019-11-12 15:14:49,985 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002590-0000000000000002591
2019-11-12 15:14:49,985 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002590-0000000000000002591 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 15:14:49,989 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002591 using no compression
2019-11-12 15:14:50,001 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002591 of size 46518 bytes saved in 0 seconds.
2019-11-12 15:14:50,008 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2589
2019-11-12 15:14:50,008 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002587, cpktTxId=0000000000000002587)
2019-11-12 15:14:50,047 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2591 to namenode at http://um1:50070 in 0.023 seconds
2019-11-12 15:14:50,047 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 15:24:50,159 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 15:24:50,159 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2592&endTxId=2593&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 15:24:50,168 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 15:24:50,168 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002592-0000000000000002593_0000000000017416844 size 0 bytes.
2019-11-12 15:24:50,168 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 15:24:50,168 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002592-0000000000000002593 expecting start txid #2592
2019-11-12 15:24:50,168 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002592-0000000000000002593
2019-11-12 15:24:50,169 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002592-0000000000000002593 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 15:24:50,171 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002593 using no compression
2019-11-12 15:24:50,178 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002593 of size 46518 bytes saved in 0 seconds.
2019-11-12 15:24:50,182 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2591
2019-11-12 15:24:50,182 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002589, cpktTxId=0000000000000002589)
2019-11-12 15:24:50,201 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2593 to namenode at http://um1:50070 in 0.012 seconds
2019-11-12 15:24:50,201 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 15:34:50,292 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 15:34:50,292 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2594&endTxId=2595&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 15:34:50,299 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 15:34:50,299 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002594-0000000000000002595_0000000000018016977 size 0 bytes.
2019-11-12 15:34:50,299 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 15:34:50,299 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002594-0000000000000002595 expecting start txid #2594
2019-11-12 15:34:50,300 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002594-0000000000000002595
2019-11-12 15:34:50,300 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002594-0000000000000002595 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 15:34:50,301 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002595 using no compression
2019-11-12 15:34:50,312 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002595 of size 46518 bytes saved in 0 seconds.
2019-11-12 15:34:50,321 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2593
2019-11-12 15:34:50,321 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002591, cpktTxId=0000000000000002591)
2019-11-12 15:34:50,361 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2595 to namenode at http://um1:50070 in 0.032 seconds
2019-11-12 15:34:50,361 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-12 15:44:50,490 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-11-12 15:44:50,491 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2596&endTxId=2597&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-12 15:44:50,497 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-11-12 15:44:50,497 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002596-0000000000000002597_0000000000018617175 size 0 bytes.
2019-11-12 15:44:50,497 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-12 15:44:50,497 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002596-0000000000000002597 expecting start txid #2596
2019-11-12 15:44:50,497 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002596-0000000000000002597
2019-11-12 15:44:50,497 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002596-0000000000000002597 of size 42 edits # 2 loaded in 0 seconds
2019-11-12 15:44:50,498 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002597 using no compression
2019-11-12 15:44:50,515 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002597 of size 46518 bytes saved in 0 seconds.
2019-11-12 15:44:50,518 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2595
2019-11-12 15:44:50,519 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002593, cpktTxId=0000000000000002593)
2019-11-12 15:44:50,550 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2597 to namenode at http://um1:50070 in 0.014 seconds
2019-11-12 15:44:50,551 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 46518
2019-11-13 11:05:23,898 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.251.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-11-13 11:05:23,968 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-11-13 11:05:25,053 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-11-13 11:05:25,204 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-11-13 11:05:25,204 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-11-13 11:05:25,433 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-11-13 11:05:25,434 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-11-13 11:05:25,634 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 2522@um2
2019-11-13 11:05:25,713 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 2522@um2
2019-11-13 11:05:25,804 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-11-13 11:05:25,812 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-11-13 11:05:25,918 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-11-13 11:05:25,918 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-11-13 11:05:25,919 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-11-13 11:05:25,921 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Nov 13 11:05:25
2019-11-13 11:05:25,922 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-11-13 11:05:25,922 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-11-13 11:05:25,923 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-11-13 11:05:25,923 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-11-13 11:05:25,932 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-11-13 11:05:25,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-11-13 11:05:25,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-11-13 11:05:25,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-11-13 11:05:25,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-11-13 11:05:25,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-11-13 11:05:25,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-11-13 11:05:25,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-11-13 11:05:25,933 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-11-13 11:05:25,933 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-11-13 11:05:25,933 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-11-13 11:05:25,933 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-11-13 11:05:25,935 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-11-13 11:05:26,587 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-11-13 11:05:26,587 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-11-13 11:05:26,587 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-11-13 11:05:26,587 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-11-13 11:05:26,659 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-11-13 11:05:26,707 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-11-13 11:05:26,707 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-11-13 11:05:26,707 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-11-13 11:05:26,707 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-11-13 11:05:26,709 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-11-13 11:05:26,709 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-11-13 11:05:26,709 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-11-13 11:05:26,750 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-11-13 11:05:26,750 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-11-13 11:05:26,750 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-11-13 11:05:26,780 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-11-13 11:05:27,377 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-11-13 11:05:27,380 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-11-13 11:05:27,391 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-13 11:05:27,393 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-11-13 11:05:27,393 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-13 11:05:27,393 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-13 11:05:27,406 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-11-13 11:05:27,406 INFO org.mortbay.log: jetty-6.1.26
2019-11-13 11:05:27,668 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-11-13 11:05:27,669 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-11-13 11:05:27,671 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-11-13 11:05:27,671 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-11-13 14:49:50,500 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.251.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-11-13 14:49:50,587 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-11-13 14:49:54,475 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-11-13 14:49:54,856 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-11-13 14:49:54,856 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-11-13 14:49:55,509 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-11-13 14:49:55,509 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-11-13 14:49:55,929 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 2759@um2
2019-11-13 14:49:56,141 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 2759@um2
2019-11-13 14:49:56,317 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-11-13 14:49:56,375 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-11-13 14:49:56,586 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-11-13 14:49:56,586 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-11-13 14:49:56,589 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-11-13 14:49:56,592 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Nov 13 14:49:56
2019-11-13 14:49:56,595 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-11-13 14:49:56,595 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-11-13 14:49:56,612 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-11-13 14:49:56,613 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-11-13 14:49:56,641 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-11-13 14:49:56,648 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-11-13 14:49:56,648 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-11-13 14:49:56,648 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-11-13 14:49:56,648 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-11-13 14:49:56,648 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-11-13 14:49:56,649 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-11-13 14:49:56,649 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-11-13 14:49:56,650 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-11-13 14:49:56,650 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-11-13 14:49:56,651 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-11-13 14:49:56,651 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-11-13 14:49:56,674 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-11-13 14:49:58,809 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-11-13 14:49:58,809 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-11-13 14:49:58,810 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-11-13 14:49:58,810 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-11-13 14:49:58,832 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-11-13 14:49:58,909 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-11-13 14:49:58,909 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-11-13 14:49:58,910 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-11-13 14:49:58,910 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-11-13 14:49:58,947 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-11-13 14:49:58,947 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-11-13 14:49:58,947 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-11-13 14:49:58,949 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-11-13 14:49:58,950 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-11-13 14:49:58,950 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-11-13 14:49:59,000 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-11-13 14:49:59,470 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-11-13 14:49:59,476 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-11-13 14:49:59,502 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-11-13 14:49:59,506 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-11-13 14:49:59,508 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-11-13 14:49:59,509 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-11-13 14:49:59,539 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-11-13 14:49:59,539 INFO org.mortbay.log: jetty-6.1.26
2019-11-13 14:49:59,968 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-11-13 14:49:59,970 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-11-13 14:49:59,971 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-11-13 14:49:59,971 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-11-13 14:57:00,295 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-11-13 14:57:00,505 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=2599&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-13 14:57:00,560 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-11-13 14:57:00,810 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 1956.52 KB/s
2019-11-13 14:57:00,811 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000002599 size 46518 bytes.
2019-11-13 14:57:00,827 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=2600&endTxId=2878&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-11-13 14:57:00,836 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 16000.00 KB/s
2019-11-13 14:57:00,837 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000002600-0000000000000002878_0000000000000608051 size 0 bytes.
2019-11-13 14:57:00,870 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 484 INodes.
2019-11-13 14:57:00,938 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-11-13 14:57:00,939 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 2599 from /orgz/snnfsi/current/fsimage_0000000000000002599
2019-11-13 14:57:00,939 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 1 entries 205 lookups
2019-11-13 14:57:00,944 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-11-13 14:57:00,955 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000002600-0000000000000002878 expecting start txid #2600
2019-11-13 14:57:00,955 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000002600-0000000000000002878
2019-11-13 14:57:01,028 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000002600-0000000000000002878 of size 33054 edits # 279 loaded in 0 seconds
2019-11-13 14:57:01,034 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002878 using no compression
2019-11-13 14:57:01,086 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000002878 of size 51360 bytes saved in 0 seconds.
2019-11-13 14:57:01,109 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2599
2019-11-13 14:57:01,109 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002597, cpktTxId=0000000000000002597)
2019-11-13 14:57:01,111 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002595, cpktTxId=0000000000000002595)
2019-11-13 14:57:01,199 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2878 to namenode at http://um1:50070 in 0.041 seconds
2019-11-13 14:57:01,200 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 51360
2019-12-02 21:28:27,509 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.251.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-12-02 21:28:27,519 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-12-02 21:28:28,357 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-12-02 21:28:28,462 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-12-02 21:28:28,462 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-12-02 21:28:28,595 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-12-02 21:28:28,595 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-12-02 21:28:28,763 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 3663@um2
2019-12-02 21:28:28,839 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 3663@um2
2019-12-02 21:28:28,869 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-12-02 21:28:28,881 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-12-02 21:28:28,939 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-12-02 21:28:28,939 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-12-02 21:28:28,940 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-12-02 21:28:28,941 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Dec 02 21:28:28
2019-12-02 21:28:28,943 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-12-02 21:28:28,943 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-12-02 21:28:28,944 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-12-02 21:28:28,944 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-12-02 21:28:28,951 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-12-02 21:28:28,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-12-02 21:28:28,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-12-02 21:28:28,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-12-02 21:28:28,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-12-02 21:28:28,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-12-02 21:28:28,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-12-02 21:28:28,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-12-02 21:28:28,953 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-12-02 21:28:28,953 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-12-02 21:28:28,953 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-12-02 21:28:28,953 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-12-02 21:28:28,954 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-12-02 21:28:29,457 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-12-02 21:28:29,457 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-12-02 21:28:29,457 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-12-02 21:28:29,457 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-12-02 21:28:29,510 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-12-02 21:28:29,517 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-12-02 21:28:29,517 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-12-02 21:28:29,517 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-12-02 21:28:29,517 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-12-02 21:28:29,547 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-12-02 21:28:29,547 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-12-02 21:28:29,547 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-12-02 21:28:29,548 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-12-02 21:28:29,548 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-12-02 21:28:29,548 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-12-02 21:28:29,556 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-12-02 21:28:29,960 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-12-02 21:28:29,962 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-12-02 21:28:29,997 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-12-02 21:28:29,998 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-12-02 21:28:29,998 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-12-02 21:28:29,998 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-12-02 21:28:30,014 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-12-02 21:28:30,014 INFO org.mortbay.log: jetty-6.1.26
2019-12-02 21:28:30,202 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-12-02 21:28:30,202 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-12-02 21:28:30,202 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-12-02 21:28:30,202 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-12-02 21:29:30,442 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-12-02 21:29:30,616 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=3338&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-02 21:29:30,660 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-12-02 21:29:31,128 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 1485.71 KB/s
2019-12-02 21:29:31,128 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000003338 size 53874 bytes.
2019-12-02 21:29:31,154 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3339&endTxId=3340&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-02 21:29:31,159 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-02 21:29:31,159 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003339-0000000000000003340_0000000000001757637 size 0 bytes.
2019-12-02 21:29:31,256 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 573 INodes.
2019-12-02 21:29:31,410 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-12-02 21:29:31,410 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 3338 from /orgz/snnfsi/current/fsimage_0000000000000003338
2019-12-02 21:29:31,411 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 1 entries 205 lookups
2019-12-02 21:29:31,418 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-02 21:29:31,421 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003339-0000000000000003340 expecting start txid #3339
2019-12-02 21:29:31,422 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003339-0000000000000003340
2019-12-02 21:29:31,438 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003339-0000000000000003340 of size 42 edits # 2 loaded in 0 seconds
2019-12-02 21:29:31,457 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003340 using no compression
2019-12-02 21:29:31,588 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003340 of size 53874 bytes saved in 0 seconds.
2019-12-02 21:29:31,602 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3338
2019-12-02 21:29:31,602 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002878, cpktTxId=0000000000000002878)
2019-12-02 21:29:31,602 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000002599, cpktTxId=0000000000000002599)
2019-12-02 21:29:31,743 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3340 to namenode at http://um1:50070 in 0.051 seconds
2019-12-02 21:29:31,743 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53874
2019-12-02 21:39:31,980 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-02 21:39:31,980 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3341&endTxId=3343&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-02 21:39:31,985 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-02 21:39:31,985 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003341-0000000000000003343_0000000000002358463 size 0 bytes.
2019-12-02 21:39:31,985 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-02 21:39:31,985 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003341-0000000000000003343 expecting start txid #3341
2019-12-02 21:39:31,985 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003341-0000000000000003343
2019-12-02 21:39:32,009 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003341-0000000000000003343 of size 120 edits # 3 loaded in 0 seconds
2019-12-02 21:39:32,013 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003343 using no compression
2019-12-02 21:39:32,031 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003343 of size 53306 bytes saved in 0 seconds.
2019-12-02 21:39:32,034 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3340
2019-12-02 21:39:32,034 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003338, cpktTxId=0000000000000003338)
2019-12-02 21:39:32,064 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3343 to namenode at http://um1:50070 in 0.014 seconds
2019-12-02 21:39:32,065 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-02 21:49:32,220 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-02 21:49:32,220 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3344&endTxId=3345&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-02 21:49:32,225 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-02 21:49:32,225 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003344-0000000000000003345_0000000000002958702 size 0 bytes.
2019-12-02 21:49:32,225 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-02 21:49:32,225 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003344-0000000000000003345 expecting start txid #3344
2019-12-02 21:49:32,226 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003344-0000000000000003345
2019-12-02 21:49:32,226 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003344-0000000000000003345 of size 42 edits # 2 loaded in 0 seconds
2019-12-02 21:49:32,227 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003345 using no compression
2019-12-02 21:49:32,240 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003345 of size 53306 bytes saved in 0 seconds.
2019-12-02 21:49:32,244 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3343
2019-12-02 21:49:32,244 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003340, cpktTxId=0000000000000003340)
2019-12-02 21:49:32,279 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3345 to namenode at http://um1:50070 in 0.018 seconds
2019-12-02 21:49:32,279 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-02 21:59:32,418 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-02 21:59:32,419 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3346&endTxId=3347&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-02 21:59:32,427 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-02 21:59:32,427 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003346-0000000000000003347_0000000000003558901 size 0 bytes.
2019-12-02 21:59:32,427 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-02 21:59:32,427 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003346-0000000000000003347 expecting start txid #3346
2019-12-02 21:59:32,427 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003346-0000000000000003347
2019-12-02 21:59:32,427 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003346-0000000000000003347 of size 42 edits # 2 loaded in 0 seconds
2019-12-02 21:59:32,428 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003347 using no compression
2019-12-02 21:59:32,435 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003347 of size 53306 bytes saved in 0 seconds.
2019-12-02 21:59:32,438 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3345
2019-12-02 21:59:32,438 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003343, cpktTxId=0000000000000003343)
2019-12-02 21:59:32,461 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3347 to namenode at http://um1:50070 in 0.014 seconds
2019-12-02 21:59:32,461 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-02 22:09:32,623 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-02 22:09:32,624 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3348&endTxId=3349&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-02 22:09:32,629 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-02 22:09:32,629 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003348-0000000000000003349_0000000000004159106 size 0 bytes.
2019-12-02 22:09:32,629 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-02 22:09:32,629 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003348-0000000000000003349 expecting start txid #3348
2019-12-02 22:09:32,629 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003348-0000000000000003349
2019-12-02 22:09:32,631 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003348-0000000000000003349 of size 42 edits # 2 loaded in 0 seconds
2019-12-02 22:09:32,632 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003349 using no compression
2019-12-02 22:09:32,639 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003349 of size 53306 bytes saved in 0 seconds.
2019-12-02 22:09:32,644 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3347
2019-12-02 22:09:32,644 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003345, cpktTxId=0000000000000003345)
2019-12-02 22:09:32,678 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3349 to namenode at http://um1:50070 in 0.015 seconds
2019-12-02 22:09:32,678 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-02 22:19:32,854 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-02 22:19:32,854 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3350&endTxId=3351&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-02 22:19:32,859 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-02 22:19:32,859 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003350-0000000000000003351_0000000000004759336 size 0 bytes.
2019-12-02 22:19:32,859 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-02 22:19:32,859 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003350-0000000000000003351 expecting start txid #3350
2019-12-02 22:19:32,859 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003350-0000000000000003351
2019-12-02 22:19:32,860 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003350-0000000000000003351 of size 42 edits # 2 loaded in 0 seconds
2019-12-02 22:19:32,862 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003351 using no compression
2019-12-02 22:19:32,873 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003351 of size 53306 bytes saved in 0 seconds.
2019-12-02 22:19:32,887 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3349
2019-12-02 22:19:32,887 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003347, cpktTxId=0000000000000003347)
2019-12-02 22:19:32,924 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3351 to namenode at http://um1:50070 in 0.018 seconds
2019-12-02 22:19:32,924 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-02 22:29:33,112 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-02 22:29:33,112 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3352&endTxId=3353&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-02 22:29:33,119 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-02 22:29:33,119 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003352-0000000000000003353_0000000000005359595 size 0 bytes.
2019-12-02 22:29:33,119 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-02 22:29:33,119 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003352-0000000000000003353 expecting start txid #3352
2019-12-02 22:29:33,119 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003352-0000000000000003353
2019-12-02 22:29:33,119 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003352-0000000000000003353 of size 42 edits # 2 loaded in 0 seconds
2019-12-02 22:29:33,120 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003353 using no compression
2019-12-02 22:29:33,124 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003353 of size 53306 bytes saved in 0 seconds.
2019-12-02 22:29:33,127 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3351
2019-12-02 22:29:33,127 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003349, cpktTxId=0000000000000003349)
2019-12-02 22:29:33,146 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3353 to namenode at http://um1:50070 in 0.012 seconds
2019-12-02 22:29:33,146 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-02 22:39:33,318 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-02 22:39:33,318 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3354&endTxId=3355&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-02 22:39:33,322 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-02 22:39:33,322 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003354-0000000000000003355_0000000000005959800 size 0 bytes.
2019-12-02 22:39:33,322 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-02 22:39:33,322 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003354-0000000000000003355 expecting start txid #3354
2019-12-02 22:39:33,322 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003354-0000000000000003355
2019-12-02 22:39:33,322 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003354-0000000000000003355 of size 42 edits # 2 loaded in 0 seconds
2019-12-02 22:39:33,323 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003355 using no compression
2019-12-02 22:39:33,329 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003355 of size 53306 bytes saved in 0 seconds.
2019-12-02 22:39:33,331 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3353
2019-12-02 22:39:33,331 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003351, cpktTxId=0000000000000003351)
2019-12-02 22:39:33,350 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3355 to namenode at http://um1:50070 in 0.013 seconds
2019-12-02 22:39:33,350 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-02 22:49:33,531 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-02 22:49:33,532 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3356&endTxId=3357&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-02 22:49:33,536 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-02 22:49:33,536 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003356-0000000000000003357_0000000000006560014 size 0 bytes.
2019-12-02 22:49:33,536 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-02 22:49:33,536 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003356-0000000000000003357 expecting start txid #3356
2019-12-02 22:49:33,536 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003356-0000000000000003357
2019-12-02 22:49:33,536 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003356-0000000000000003357 of size 42 edits # 2 loaded in 0 seconds
2019-12-02 22:49:33,537 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003357 using no compression
2019-12-02 22:49:33,545 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003357 of size 53306 bytes saved in 0 seconds.
2019-12-02 22:49:33,559 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3355
2019-12-02 22:49:33,559 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003353, cpktTxId=0000000000000003353)
2019-12-02 22:49:33,581 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3357 to namenode at http://um1:50070 in 0.015 seconds
2019-12-02 22:49:33,581 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-02 22:59:33,738 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-02 22:59:33,738 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3358&endTxId=3359&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-02 22:59:33,743 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-02 22:59:33,743 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003358-0000000000000003359_0000000000007160220 size 0 bytes.
2019-12-02 22:59:33,743 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-02 22:59:33,743 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003358-0000000000000003359 expecting start txid #3358
2019-12-02 22:59:33,743 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003358-0000000000000003359
2019-12-02 22:59:33,743 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003358-0000000000000003359 of size 42 edits # 2 loaded in 0 seconds
2019-12-02 22:59:33,744 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003359 using no compression
2019-12-02 22:59:33,748 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003359 of size 53306 bytes saved in 0 seconds.
2019-12-02 22:59:33,752 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3357
2019-12-02 22:59:33,752 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003355, cpktTxId=0000000000000003355)
2019-12-02 22:59:33,779 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3359 to namenode at http://um1:50070 in 0.013 seconds
2019-12-02 22:59:33,780 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-02 23:09:33,926 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-02 23:09:33,927 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3360&endTxId=3361&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-02 23:09:33,931 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-02 23:09:33,931 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003360-0000000000000003361_0000000000007760409 size 0 bytes.
2019-12-02 23:09:33,932 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-02 23:09:33,932 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003360-0000000000000003361 expecting start txid #3360
2019-12-02 23:09:33,932 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003360-0000000000000003361
2019-12-02 23:09:33,932 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003360-0000000000000003361 of size 42 edits # 2 loaded in 0 seconds
2019-12-02 23:09:33,933 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003361 using no compression
2019-12-02 23:09:33,939 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003361 of size 53306 bytes saved in 0 seconds.
2019-12-02 23:09:33,942 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3359
2019-12-02 23:09:33,942 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003357, cpktTxId=0000000000000003357)
2019-12-02 23:09:33,971 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3361 to namenode at http://um1:50070 in 0.021 seconds
2019-12-02 23:09:33,971 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-02 23:19:34,152 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-02 23:19:34,153 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3362&endTxId=3363&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-02 23:19:34,157 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-02 23:19:34,157 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003362-0000000000000003363_0000000000008360635 size 0 bytes.
2019-12-02 23:19:34,157 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-02 23:19:34,158 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003362-0000000000000003363 expecting start txid #3362
2019-12-02 23:19:34,158 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003362-0000000000000003363
2019-12-02 23:19:34,158 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003362-0000000000000003363 of size 42 edits # 2 loaded in 0 seconds
2019-12-02 23:19:34,160 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003363 using no compression
2019-12-02 23:19:34,164 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003363 of size 53306 bytes saved in 0 seconds.
2019-12-02 23:19:34,168 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3361
2019-12-02 23:19:34,168 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003359, cpktTxId=0000000000000003359)
2019-12-02 23:19:34,188 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3363 to namenode at http://um1:50070 in 0.013 seconds
2019-12-02 23:19:34,188 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-02 23:29:34,322 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-02 23:29:34,324 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3364&endTxId=3365&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-02 23:29:34,329 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-02 23:29:34,330 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003364-0000000000000003365_0000000000008960806 size 0 bytes.
2019-12-02 23:29:34,330 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-02 23:29:34,330 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003364-0000000000000003365 expecting start txid #3364
2019-12-02 23:29:34,330 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003364-0000000000000003365
2019-12-02 23:29:34,330 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003364-0000000000000003365 of size 42 edits # 2 loaded in 0 seconds
2019-12-02 23:29:34,332 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003365 using no compression
2019-12-02 23:29:34,337 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003365 of size 53306 bytes saved in 0 seconds.
2019-12-02 23:29:34,349 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3363
2019-12-02 23:29:34,349 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003361, cpktTxId=0000000000000003361)
2019-12-02 23:29:34,371 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3365 to namenode at http://um1:50070 in 0.015 seconds
2019-12-02 23:29:34,371 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-02 23:39:34,505 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-02 23:39:34,505 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3366&endTxId=3367&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-02 23:39:34,511 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-02 23:39:34,511 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003366-0000000000000003367_0000000000009560987 size 0 bytes.
2019-12-02 23:39:34,512 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-02 23:39:34,512 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003366-0000000000000003367 expecting start txid #3366
2019-12-02 23:39:34,512 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003366-0000000000000003367
2019-12-02 23:39:34,512 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003366-0000000000000003367 of size 42 edits # 2 loaded in 0 seconds
2019-12-02 23:39:34,512 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003367 using no compression
2019-12-02 23:39:34,516 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003367 of size 53306 bytes saved in 0 seconds.
2019-12-02 23:39:34,519 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3365
2019-12-02 23:39:34,519 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003363, cpktTxId=0000000000000003363)
2019-12-02 23:39:34,537 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3367 to namenode at http://um1:50070 in 0.01 seconds
2019-12-02 23:39:34,537 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-02 23:49:34,745 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-02 23:49:34,745 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3368&endTxId=3369&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-02 23:49:34,752 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-02 23:49:34,752 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003368-0000000000000003369_0000000000010161228 size 0 bytes.
2019-12-02 23:49:34,752 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-02 23:49:34,752 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003368-0000000000000003369 expecting start txid #3368
2019-12-02 23:49:34,752 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003368-0000000000000003369
2019-12-02 23:49:34,753 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003368-0000000000000003369 of size 42 edits # 2 loaded in 0 seconds
2019-12-02 23:49:34,754 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003369 using no compression
2019-12-02 23:49:34,765 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003369 of size 53306 bytes saved in 0 seconds.
2019-12-02 23:49:34,770 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3367
2019-12-02 23:49:34,770 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003365, cpktTxId=0000000000000003365)
2019-12-02 23:49:34,788 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3369 to namenode at http://um1:50070 in 0.01 seconds
2019-12-02 23:49:34,788 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-02 23:59:34,927 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-02 23:59:34,927 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3370&endTxId=3371&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-02 23:59:34,936 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-02 23:59:34,936 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003370-0000000000000003371_0000000000010761410 size 0 bytes.
2019-12-02 23:59:34,936 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-02 23:59:34,936 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003370-0000000000000003371 expecting start txid #3370
2019-12-02 23:59:34,936 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003370-0000000000000003371
2019-12-02 23:59:34,936 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003370-0000000000000003371 of size 42 edits # 2 loaded in 0 seconds
2019-12-02 23:59:34,937 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003371 using no compression
2019-12-02 23:59:34,941 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003371 of size 53306 bytes saved in 0 seconds.
2019-12-02 23:59:34,944 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3369
2019-12-02 23:59:34,944 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003367, cpktTxId=0000000000000003367)
2019-12-02 23:59:34,969 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3371 to namenode at http://um1:50070 in 0.014 seconds
2019-12-02 23:59:34,969 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 00:09:35,111 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 00:09:35,111 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3372&endTxId=3373&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 00:09:35,117 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 00:09:35,117 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003372-0000000000000003373_0000000000011361594 size 0 bytes.
2019-12-03 00:09:35,117 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 00:09:35,117 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003372-0000000000000003373 expecting start txid #3372
2019-12-03 00:09:35,117 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003372-0000000000000003373
2019-12-03 00:09:35,117 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003372-0000000000000003373 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 00:09:35,121 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003373 using no compression
2019-12-03 00:09:35,126 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003373 of size 53306 bytes saved in 0 seconds.
2019-12-03 00:09:35,131 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3371
2019-12-03 00:09:35,131 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003369, cpktTxId=0000000000000003369)
2019-12-03 00:09:35,149 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3373 to namenode at http://um1:50070 in 0.012 seconds
2019-12-03 00:09:35,149 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 00:19:35,357 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 00:19:35,357 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3374&endTxId=3375&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 00:19:35,361 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 00:19:35,361 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003374-0000000000000003375_0000000000011961839 size 0 bytes.
2019-12-03 00:19:35,361 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 00:19:35,361 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003374-0000000000000003375 expecting start txid #3374
2019-12-03 00:19:35,361 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003374-0000000000000003375
2019-12-03 00:19:35,361 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003374-0000000000000003375 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 00:19:35,364 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003375 using no compression
2019-12-03 00:19:35,371 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003375 of size 53306 bytes saved in 0 seconds.
2019-12-03 00:19:35,382 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3373
2019-12-03 00:19:35,382 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003371, cpktTxId=0000000000000003371)
2019-12-03 00:19:35,406 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3375 to namenode at http://um1:50070 in 0.017 seconds
2019-12-03 00:19:35,406 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 00:29:35,548 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 00:29:35,548 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3376&endTxId=3377&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 00:29:35,554 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 00:29:35,554 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003376-0000000000000003377_0000000000012562031 size 0 bytes.
2019-12-03 00:29:35,554 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 00:29:35,554 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003376-0000000000000003377 expecting start txid #3376
2019-12-03 00:29:35,554 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003376-0000000000000003377
2019-12-03 00:29:35,554 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003376-0000000000000003377 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 00:29:35,555 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003377 using no compression
2019-12-03 00:29:35,559 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003377 of size 53306 bytes saved in 0 seconds.
2019-12-03 00:29:35,562 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3375
2019-12-03 00:29:35,562 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003373, cpktTxId=0000000000000003373)
2019-12-03 00:29:35,578 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3377 to namenode at http://um1:50070 in 0.011 seconds
2019-12-03 00:29:35,578 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 00:39:35,732 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 00:39:35,732 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3378&endTxId=3379&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 00:39:35,766 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2019-12-03 00:39:35,766 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003378-0000000000000003379_0000000000013162214 size 0 bytes.
2019-12-03 00:39:35,766 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 00:39:35,766 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003378-0000000000000003379 expecting start txid #3378
2019-12-03 00:39:35,766 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003378-0000000000000003379
2019-12-03 00:39:35,766 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003378-0000000000000003379 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 00:39:35,767 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003379 using no compression
2019-12-03 00:39:35,773 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003379 of size 53306 bytes saved in 0 seconds.
2019-12-03 00:39:35,776 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3377
2019-12-03 00:39:35,776 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003375, cpktTxId=0000000000000003375)
2019-12-03 00:39:35,798 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3379 to namenode at http://um1:50070 in 0.015 seconds
2019-12-03 00:39:35,798 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 00:49:35,942 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 00:49:35,942 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3380&endTxId=3381&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 00:49:35,946 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 00:49:35,946 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003380-0000000000000003381_0000000000013762424 size 0 bytes.
2019-12-03 00:49:35,946 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 00:49:35,946 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003380-0000000000000003381 expecting start txid #3380
2019-12-03 00:49:35,946 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003380-0000000000000003381
2019-12-03 00:49:35,946 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003380-0000000000000003381 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 00:49:35,950 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003381 using no compression
2019-12-03 00:49:35,971 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003381 of size 53306 bytes saved in 0 seconds.
2019-12-03 00:49:35,984 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3379
2019-12-03 00:49:35,984 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003377, cpktTxId=0000000000000003377)
2019-12-03 00:49:36,003 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3381 to namenode at http://um1:50070 in 0.012 seconds
2019-12-03 00:49:36,003 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 00:59:36,114 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 00:59:36,114 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3382&endTxId=3383&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 00:59:36,119 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 00:59:36,119 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003382-0000000000000003383_0000000000014362597 size 0 bytes.
2019-12-03 00:59:36,119 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 00:59:36,119 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003382-0000000000000003383 expecting start txid #3382
2019-12-03 00:59:36,119 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003382-0000000000000003383
2019-12-03 00:59:36,119 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003382-0000000000000003383 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 00:59:36,120 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003383 using no compression
2019-12-03 00:59:36,124 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003383 of size 53306 bytes saved in 0 seconds.
2019-12-03 00:59:36,127 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3381
2019-12-03 00:59:36,128 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003379, cpktTxId=0000000000000003379)
2019-12-03 00:59:36,150 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3383 to namenode at http://um1:50070 in 0.015 seconds
2019-12-03 00:59:36,150 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 01:09:36,322 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 01:09:36,322 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3384&endTxId=3385&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 01:09:36,328 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 01:09:36,328 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003384-0000000000000003385_0000000000014962805 size 0 bytes.
2019-12-03 01:09:36,328 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 01:09:36,328 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003384-0000000000000003385 expecting start txid #3384
2019-12-03 01:09:36,328 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003384-0000000000000003385
2019-12-03 01:09:36,329 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003384-0000000000000003385 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 01:09:36,329 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003385 using no compression
2019-12-03 01:09:36,344 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003385 of size 53306 bytes saved in 0 seconds.
2019-12-03 01:09:36,353 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3383
2019-12-03 01:09:36,353 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003381, cpktTxId=0000000000000003381)
2019-12-03 01:09:36,385 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3385 to namenode at http://um1:50070 in 0.025 seconds
2019-12-03 01:09:36,385 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 01:19:36,508 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 01:19:36,508 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3386&endTxId=3387&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 01:19:36,512 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 01:19:36,512 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003386-0000000000000003387_0000000000015562990 size 0 bytes.
2019-12-03 01:19:36,512 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 01:19:36,512 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003386-0000000000000003387 expecting start txid #3386
2019-12-03 01:19:36,512 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003386-0000000000000003387
2019-12-03 01:19:36,512 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003386-0000000000000003387 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 01:19:36,513 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003387 using no compression
2019-12-03 01:19:36,518 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003387 of size 53306 bytes saved in 0 seconds.
2019-12-03 01:19:36,520 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3385
2019-12-03 01:19:36,520 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003383, cpktTxId=0000000000000003383)
2019-12-03 01:19:36,539 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3387 to namenode at http://um1:50070 in 0.011 seconds
2019-12-03 01:19:36,539 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 01:29:36,770 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 01:29:36,771 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3388&endTxId=3389&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 01:29:36,776 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 01:29:36,776 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003388-0000000000000003389_0000000000016163253 size 0 bytes.
2019-12-03 01:29:36,776 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 01:29:36,776 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003388-0000000000000003389 expecting start txid #3388
2019-12-03 01:29:36,776 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003388-0000000000000003389
2019-12-03 01:29:36,778 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003388-0000000000000003389 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 01:29:36,779 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003389 using no compression
2019-12-03 01:29:36,783 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003389 of size 53306 bytes saved in 0 seconds.
2019-12-03 01:29:36,787 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3387
2019-12-03 01:29:36,787 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003385, cpktTxId=0000000000000003385)
2019-12-03 01:29:36,805 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3389 to namenode at http://um1:50070 in 0.012 seconds
2019-12-03 01:29:36,805 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 01:39:36,918 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 01:39:36,918 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3390&endTxId=3391&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 01:39:36,922 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 01:39:36,922 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003390-0000000000000003391_0000000000016763400 size 0 bytes.
2019-12-03 01:39:36,922 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 01:39:36,922 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003390-0000000000000003391 expecting start txid #3390
2019-12-03 01:39:36,922 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003390-0000000000000003391
2019-12-03 01:39:36,923 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003390-0000000000000003391 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 01:39:36,924 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003391 using no compression
2019-12-03 01:39:36,927 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003391 of size 53306 bytes saved in 0 seconds.
2019-12-03 01:39:36,929 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3389
2019-12-03 01:39:36,929 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003387, cpktTxId=0000000000000003387)
2019-12-03 01:39:36,955 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3391 to namenode at http://um1:50070 in 0.018 seconds
2019-12-03 01:39:36,956 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 01:49:37,105 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 01:49:37,106 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3392&endTxId=3393&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 01:49:37,110 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 01:49:37,110 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003392-0000000000000003393_0000000000017363588 size 0 bytes.
2019-12-03 01:49:37,110 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 01:49:37,110 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003392-0000000000000003393 expecting start txid #3392
2019-12-03 01:49:37,110 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003392-0000000000000003393
2019-12-03 01:49:37,110 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003392-0000000000000003393 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 01:49:37,111 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003393 using no compression
2019-12-03 01:49:37,114 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003393 of size 53306 bytes saved in 0 seconds.
2019-12-03 01:49:37,118 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3391
2019-12-03 01:49:37,119 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003389, cpktTxId=0000000000000003389)
2019-12-03 01:49:37,141 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3393 to namenode at http://um1:50070 in 0.009 seconds
2019-12-03 01:49:37,141 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 01:59:37,263 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 01:59:37,264 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3394&endTxId=3395&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 01:59:37,269 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 01:59:37,269 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003394-0000000000000003395_0000000000017963746 size 0 bytes.
2019-12-03 01:59:37,269 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 01:59:37,269 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003394-0000000000000003395 expecting start txid #3394
2019-12-03 01:59:37,269 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003394-0000000000000003395
2019-12-03 01:59:37,269 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003394-0000000000000003395 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 01:59:37,269 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003395 using no compression
2019-12-03 01:59:37,272 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003395 of size 53306 bytes saved in 0 seconds.
2019-12-03 01:59:37,274 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3393
2019-12-03 01:59:37,274 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003391, cpktTxId=0000000000000003391)
2019-12-03 01:59:37,295 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3395 to namenode at http://um1:50070 in 0.011 seconds
2019-12-03 01:59:37,295 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 02:09:37,417 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 02:09:37,417 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3396&endTxId=3397&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 02:09:37,422 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 02:09:37,422 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003396-0000000000000003397_0000000000018563900 size 0 bytes.
2019-12-03 02:09:37,422 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 02:09:37,422 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003396-0000000000000003397 expecting start txid #3396
2019-12-03 02:09:37,422 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003396-0000000000000003397
2019-12-03 02:09:37,423 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003396-0000000000000003397 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 02:09:37,423 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003397 using no compression
2019-12-03 02:09:37,432 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003397 of size 53306 bytes saved in 0 seconds.
2019-12-03 02:09:37,435 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3395
2019-12-03 02:09:37,435 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003393, cpktTxId=0000000000000003393)
2019-12-03 02:09:37,470 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3397 to namenode at http://um1:50070 in 0.02 seconds
2019-12-03 02:09:37,471 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 02:19:37,656 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 02:19:37,658 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3398&endTxId=3399&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 02:19:37,669 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-12-03 02:19:37,669 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003398-0000000000000003399_0000000000019164140 size 0 bytes.
2019-12-03 02:19:37,669 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 02:19:37,669 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003398-0000000000000003399 expecting start txid #3398
2019-12-03 02:19:37,669 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003398-0000000000000003399
2019-12-03 02:19:37,670 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003398-0000000000000003399 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 02:19:37,671 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003399 using no compression
2019-12-03 02:19:37,673 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003399 of size 53306 bytes saved in 0 seconds.
2019-12-03 02:19:37,688 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3397
2019-12-03 02:19:37,688 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003395, cpktTxId=0000000000000003395)
2019-12-03 02:19:37,711 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3399 to namenode at http://um1:50070 in 0.012 seconds
2019-12-03 02:19:37,711 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 02:29:37,843 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 02:29:37,843 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3400&endTxId=3401&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 02:29:37,846 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 02:29:37,846 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003400-0000000000000003401_0000000000019764325 size 0 bytes.
2019-12-03 02:29:37,846 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 02:29:37,846 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003400-0000000000000003401 expecting start txid #3400
2019-12-03 02:29:37,846 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003400-0000000000000003401
2019-12-03 02:29:37,847 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003400-0000000000000003401 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 02:29:37,847 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003401 using no compression
2019-12-03 02:29:37,856 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003401 of size 53306 bytes saved in 0 seconds.
2019-12-03 02:29:37,858 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3399
2019-12-03 02:29:37,858 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003397, cpktTxId=0000000000000003397)
2019-12-03 02:29:37,873 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3401 to namenode at http://um1:50070 in 0.01 seconds
2019-12-03 02:29:37,873 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 02:39:38,023 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 02:39:38,036 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3402&endTxId=3403&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 02:39:38,044 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-12-03 02:39:38,044 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003402-0000000000000003403_0000000000020364518 size 0 bytes.
2019-12-03 02:39:38,044 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 02:39:38,044 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003402-0000000000000003403 expecting start txid #3402
2019-12-03 02:39:38,044 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003402-0000000000000003403
2019-12-03 02:39:38,044 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003402-0000000000000003403 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 02:39:38,045 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003403 using no compression
2019-12-03 02:39:38,049 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003403 of size 53306 bytes saved in 0 seconds.
2019-12-03 02:39:38,083 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3401
2019-12-03 02:39:38,084 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003399, cpktTxId=0000000000000003399)
2019-12-03 02:39:38,147 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3403 to namenode at http://um1:50070 in 0.044 seconds
2019-12-03 02:39:38,147 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 02:49:38,334 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 02:49:38,336 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3404&endTxId=3405&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 02:49:38,349 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-12-03 02:49:38,350 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003404-0000000000000003405_0000000000020964819 size 0 bytes.
2019-12-03 02:49:38,350 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 02:49:38,350 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003404-0000000000000003405 expecting start txid #3404
2019-12-03 02:49:38,350 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003404-0000000000000003405
2019-12-03 02:49:38,350 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003404-0000000000000003405 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 02:49:38,351 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003405 using no compression
2019-12-03 02:49:38,353 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003405 of size 53306 bytes saved in 0 seconds.
2019-12-03 02:49:38,374 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3403
2019-12-03 02:49:38,374 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003401, cpktTxId=0000000000000003401)
2019-12-03 02:49:38,395 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3405 to namenode at http://um1:50070 in 0.012 seconds
2019-12-03 02:49:38,395 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 02:59:38,498 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 02:59:38,498 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3406&endTxId=3407&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 02:59:38,502 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 02:59:38,502 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003406-0000000000000003407_0000000000021564981 size 0 bytes.
2019-12-03 02:59:38,502 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 02:59:38,502 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003406-0000000000000003407 expecting start txid #3406
2019-12-03 02:59:38,502 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003406-0000000000000003407
2019-12-03 02:59:38,503 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003406-0000000000000003407 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 02:59:38,503 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003407 using no compression
2019-12-03 02:59:38,507 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003407 of size 53306 bytes saved in 0 seconds.
2019-12-03 02:59:38,509 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3405
2019-12-03 02:59:38,509 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003403, cpktTxId=0000000000000003403)
2019-12-03 02:59:38,525 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3407 to namenode at http://um1:50070 in 0.009 seconds
2019-12-03 02:59:38,525 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 03:09:38,668 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 03:09:38,668 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3408&endTxId=3409&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 03:09:38,673 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 03:09:38,673 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003408-0000000000000003409_0000000000022165150 size 0 bytes.
2019-12-03 03:09:38,673 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 03:09:38,673 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003408-0000000000000003409 expecting start txid #3408
2019-12-03 03:09:38,673 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003408-0000000000000003409
2019-12-03 03:09:38,673 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003408-0000000000000003409 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 03:09:38,674 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003409 using no compression
2019-12-03 03:09:38,676 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003409 of size 53306 bytes saved in 0 seconds.
2019-12-03 03:09:38,678 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3407
2019-12-03 03:09:38,678 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003405, cpktTxId=0000000000000003405)
2019-12-03 03:09:38,693 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3409 to namenode at http://um1:50070 in 0.01 seconds
2019-12-03 03:09:38,693 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 03:19:38,866 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 03:19:38,866 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3410&endTxId=3411&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 03:19:38,870 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 03:19:38,870 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003410-0000000000000003411_0000000000022765348 size 0 bytes.
2019-12-03 03:19:38,870 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 03:19:38,870 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003410-0000000000000003411 expecting start txid #3410
2019-12-03 03:19:38,870 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003410-0000000000000003411
2019-12-03 03:19:38,871 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003410-0000000000000003411 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 03:19:38,871 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003411 using no compression
2019-12-03 03:19:38,874 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003411 of size 53306 bytes saved in 0 seconds.
2019-12-03 03:19:38,877 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3409
2019-12-03 03:19:38,877 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003407, cpktTxId=0000000000000003407)
2019-12-03 03:19:38,892 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3411 to namenode at http://um1:50070 in 0.01 seconds
2019-12-03 03:19:38,893 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 03:29:39,044 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 03:29:39,044 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3412&endTxId=3413&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 03:29:39,050 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 03:29:39,050 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003412-0000000000000003413_0000000000023365527 size 0 bytes.
2019-12-03 03:29:39,050 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 03:29:39,050 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003412-0000000000000003413 expecting start txid #3412
2019-12-03 03:29:39,050 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003412-0000000000000003413
2019-12-03 03:29:39,050 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003412-0000000000000003413 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 03:29:39,051 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003413 using no compression
2019-12-03 03:29:39,054 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003413 of size 53306 bytes saved in 0 seconds.
2019-12-03 03:29:39,056 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3411
2019-12-03 03:29:39,056 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003409, cpktTxId=0000000000000003409)
2019-12-03 03:29:39,086 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3413 to namenode at http://um1:50070 in 0.022 seconds
2019-12-03 03:29:39,086 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 03:39:40,745 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 03:39:40,745 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3414&endTxId=3415&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 03:39:40,797 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 03:39:40,797 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003414-0000000000000003415_0000000000023967227 size 0 bytes.
2019-12-03 03:39:40,797 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 03:39:40,797 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003414-0000000000000003415 expecting start txid #3414
2019-12-03 03:39:40,798 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003414-0000000000000003415
2019-12-03 03:39:40,798 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003414-0000000000000003415 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 03:39:40,799 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003415 using no compression
2019-12-03 03:39:40,802 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003415 of size 53306 bytes saved in 0 seconds.
2019-12-03 03:39:40,805 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3413
2019-12-03 03:39:40,805 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003411, cpktTxId=0000000000000003411)
2019-12-03 03:39:40,839 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3415 to namenode at http://um1:50070 in 0.028 seconds
2019-12-03 03:39:40,839 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 03:49:41,024 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 03:49:41,024 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3416&endTxId=3417&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 03:49:41,028 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 03:49:41,028 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003416-0000000000000003417_0000000000024567506 size 0 bytes.
2019-12-03 03:49:41,028 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 03:49:41,028 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003416-0000000000000003417 expecting start txid #3416
2019-12-03 03:49:41,028 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003416-0000000000000003417
2019-12-03 03:49:41,028 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003416-0000000000000003417 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 03:49:41,029 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003417 using no compression
2019-12-03 03:49:41,031 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003417 of size 53306 bytes saved in 0 seconds.
2019-12-03 03:49:41,035 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3415
2019-12-03 03:49:41,035 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003413, cpktTxId=0000000000000003413)
2019-12-03 03:49:41,063 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3417 to namenode at http://um1:50070 in 0.02 seconds
2019-12-03 03:49:41,063 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 03:59:41,289 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 03:59:41,289 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3418&endTxId=3419&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 03:59:41,294 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 03:59:41,294 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003418-0000000000000003419_0000000000025167771 size 0 bytes.
2019-12-03 03:59:41,294 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 03:59:41,294 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003418-0000000000000003419 expecting start txid #3418
2019-12-03 03:59:41,294 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003418-0000000000000003419
2019-12-03 03:59:41,294 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003418-0000000000000003419 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 03:59:41,295 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003419 using no compression
2019-12-03 03:59:41,297 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003419 of size 53306 bytes saved in 0 seconds.
2019-12-03 03:59:41,300 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3417
2019-12-03 03:59:41,300 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003415, cpktTxId=0000000000000003415)
2019-12-03 03:59:41,319 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3419 to namenode at http://um1:50070 in 0.015 seconds
2019-12-03 03:59:41,319 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 04:09:41,479 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 04:09:41,479 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3420&endTxId=3421&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 04:09:41,485 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 04:09:41,485 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003420-0000000000000003421_0000000000025767962 size 0 bytes.
2019-12-03 04:09:41,485 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 04:09:41,485 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003420-0000000000000003421 expecting start txid #3420
2019-12-03 04:09:41,485 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003420-0000000000000003421
2019-12-03 04:09:41,485 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003420-0000000000000003421 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 04:09:41,486 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003421 using no compression
2019-12-03 04:09:41,488 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003421 of size 53306 bytes saved in 0 seconds.
2019-12-03 04:09:41,490 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3419
2019-12-03 04:09:41,490 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003417, cpktTxId=0000000000000003417)
2019-12-03 04:09:41,519 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3421 to namenode at http://um1:50070 in 0.024 seconds
2019-12-03 04:09:41,520 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 04:19:41,769 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 04:19:41,769 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3422&endTxId=3423&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 04:19:41,773 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 04:19:41,773 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003422-0000000000000003423_0000000000026368251 size 0 bytes.
2019-12-03 04:19:41,773 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 04:19:41,773 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003422-0000000000000003423 expecting start txid #3422
2019-12-03 04:19:41,773 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003422-0000000000000003423
2019-12-03 04:19:41,773 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003422-0000000000000003423 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 04:19:41,774 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003423 using no compression
2019-12-03 04:19:41,776 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003423 of size 53306 bytes saved in 0 seconds.
2019-12-03 04:19:41,778 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3421
2019-12-03 04:19:41,778 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003419, cpktTxId=0000000000000003419)
2019-12-03 04:19:41,863 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3423 to namenode at http://um1:50070 in 0.079 seconds
2019-12-03 04:19:41,863 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 04:29:42,224 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 04:29:42,224 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3424&endTxId=3425&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 04:29:42,234 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 04:29:42,234 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003424-0000000000000003425_0000000000026968706 size 0 bytes.
2019-12-03 04:29:42,234 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 04:29:42,234 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003424-0000000000000003425 expecting start txid #3424
2019-12-03 04:29:42,234 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003424-0000000000000003425
2019-12-03 04:29:42,234 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003424-0000000000000003425 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 04:29:42,235 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003425 using no compression
2019-12-03 04:29:42,237 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003425 of size 53306 bytes saved in 0 seconds.
2019-12-03 04:29:42,239 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3423
2019-12-03 04:29:42,239 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003421, cpktTxId=0000000000000003421)
2019-12-03 04:29:42,363 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3425 to namenode at http://um1:50070 in 0.118 seconds
2019-12-03 04:29:42,363 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 04:39:42,534 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 04:39:42,534 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3426&endTxId=3427&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 04:39:42,541 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 04:39:42,541 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003426-0000000000000003427_0000000000027569017 size 0 bytes.
2019-12-03 04:39:42,541 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 04:39:42,541 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003426-0000000000000003427 expecting start txid #3426
2019-12-03 04:39:42,541 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003426-0000000000000003427
2019-12-03 04:39:42,541 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003426-0000000000000003427 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 04:39:42,542 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003427 using no compression
2019-12-03 04:39:42,544 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003427 of size 53306 bytes saved in 0 seconds.
2019-12-03 04:39:42,546 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3425
2019-12-03 04:39:42,546 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003423, cpktTxId=0000000000000003423)
2019-12-03 04:39:42,633 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3427 to namenode at http://um1:50070 in 0.083 seconds
2019-12-03 04:39:42,633 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 04:49:42,881 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 04:49:42,881 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3428&endTxId=3429&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 04:49:42,884 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 04:49:42,884 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003428-0000000000000003429_0000000000028169363 size 0 bytes.
2019-12-03 04:49:42,884 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 04:49:42,884 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003428-0000000000000003429 expecting start txid #3428
2019-12-03 04:49:42,885 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003428-0000000000000003429
2019-12-03 04:49:42,885 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003428-0000000000000003429 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 04:49:42,885 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003429 using no compression
2019-12-03 04:49:42,887 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003429 of size 53306 bytes saved in 0 seconds.
2019-12-03 04:49:42,889 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3427
2019-12-03 04:49:42,889 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003425, cpktTxId=0000000000000003425)
2019-12-03 04:49:42,938 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3429 to namenode at http://um1:50070 in 0.044 seconds
2019-12-03 04:49:42,938 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 04:59:43,851 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 04:59:43,851 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3430&endTxId=3431&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 04:59:43,857 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 04:59:43,857 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003430-0000000000000003431_0000000000028770334 size 0 bytes.
2019-12-03 04:59:43,857 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 04:59:43,857 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003430-0000000000000003431 expecting start txid #3430
2019-12-03 04:59:43,858 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003430-0000000000000003431
2019-12-03 04:59:43,858 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003430-0000000000000003431 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 04:59:43,858 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003431 using no compression
2019-12-03 04:59:43,860 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003431 of size 53306 bytes saved in 0 seconds.
2019-12-03 04:59:43,863 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3429
2019-12-03 04:59:43,863 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003427, cpktTxId=0000000000000003427)
2019-12-03 04:59:43,886 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3431 to namenode at http://um1:50070 in 0.018 seconds
2019-12-03 04:59:43,886 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 05:09:44,243 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 05:09:44,243 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3432&endTxId=3433&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 05:09:44,337 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-12-03 05:09:44,338 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003432-0000000000000003433_0000000000029370726 size 0 bytes.
2019-12-03 05:09:44,338 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 05:09:44,338 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003432-0000000000000003433 expecting start txid #3432
2019-12-03 05:09:44,338 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003432-0000000000000003433
2019-12-03 05:09:44,338 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003432-0000000000000003433 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 05:09:44,338 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003433 using no compression
2019-12-03 05:09:44,343 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003433 of size 53306 bytes saved in 0 seconds.
2019-12-03 05:09:44,347 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3431
2019-12-03 05:09:44,347 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003429, cpktTxId=0000000000000003429)
2019-12-03 05:09:44,375 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3433 to namenode at http://um1:50070 in 0.022 seconds
2019-12-03 05:09:44,375 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 05:19:46,035 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 05:19:46,035 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3434&endTxId=3435&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 05:19:46,089 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 05:19:46,089 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003434-0000000000000003435_0000000000029972517 size 0 bytes.
2019-12-03 05:19:46,089 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 05:19:46,089 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003434-0000000000000003435 expecting start txid #3434
2019-12-03 05:19:46,090 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003434-0000000000000003435
2019-12-03 05:19:46,090 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003434-0000000000000003435 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 05:19:46,091 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003435 using no compression
2019-12-03 05:19:46,097 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003435 of size 53306 bytes saved in 0 seconds.
2019-12-03 05:19:46,134 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3433
2019-12-03 05:19:46,134 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003431, cpktTxId=0000000000000003431)
2019-12-03 05:19:46,184 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3435 to namenode at http://um1:50070 in 0.042 seconds
2019-12-03 05:19:46,184 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 05:29:50,874 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 05:29:50,875 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3436&endTxId=3437&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 05:29:50,922 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 05:29:50,922 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003436-0000000000000003437_0000000000030577357 size 0 bytes.
2019-12-03 05:29:50,922 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 05:29:50,923 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003436-0000000000000003437 expecting start txid #3436
2019-12-03 05:29:50,923 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003436-0000000000000003437
2019-12-03 05:29:50,923 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003436-0000000000000003437 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 05:29:50,923 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003437 using no compression
2019-12-03 05:29:50,927 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003437 of size 53306 bytes saved in 0 seconds.
2019-12-03 05:29:50,932 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3435
2019-12-03 05:29:50,932 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003433, cpktTxId=0000000000000003433)
2019-12-03 05:29:52,387 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3437 to namenode at http://um1:50070 in 1.447 seconds
2019-12-03 05:29:52,388 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 05:40:07,826 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 05:40:07,826 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3438&endTxId=3439&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 05:40:07,842 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-12-03 05:40:07,842 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003438-0000000000000003439_0000000000031194308 size 0 bytes.
2019-12-03 05:40:07,842 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 05:40:07,842 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003438-0000000000000003439 expecting start txid #3438
2019-12-03 05:40:07,842 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003438-0000000000000003439
2019-12-03 05:40:07,842 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003438-0000000000000003439 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 05:40:07,843 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003439 using no compression
2019-12-03 05:40:07,847 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003439 of size 53306 bytes saved in 0 seconds.
2019-12-03 05:40:07,887 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3437
2019-12-03 05:40:07,887 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003435, cpktTxId=0000000000000003435)
2019-12-03 05:40:08,790 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3439 to namenode at http://um1:50070 in 0.894 seconds
2019-12-03 05:40:08,791 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 05:50:20,985 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 05:50:20,985 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3440&endTxId=3441&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 05:50:21,078 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-12-03 05:50:21,079 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003440-0000000000000003441_0000000000031807467 size 0 bytes.
2019-12-03 05:50:21,079 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 05:50:21,079 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003440-0000000000000003441 expecting start txid #3440
2019-12-03 05:50:21,079 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003440-0000000000000003441
2019-12-03 05:50:21,080 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003440-0000000000000003441 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 05:50:21,088 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003441 using no compression
2019-12-03 05:50:21,093 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003441 of size 53306 bytes saved in 0 seconds.
2019-12-03 05:50:21,139 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3439
2019-12-03 05:50:21,139 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003437, cpktTxId=0000000000000003437)
2019-12-03 05:50:22,344 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3441 to namenode at http://um1:50070 in 1.198 seconds
2019-12-03 05:50:22,344 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 06:00:26,067 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 06:00:26,067 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3442&endTxId=3443&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 06:00:26,148 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-12-03 06:00:26,148 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003442-0000000000000003443_0000000000032412550 size 0 bytes.
2019-12-03 06:00:26,148 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 06:00:26,148 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003442-0000000000000003443 expecting start txid #3442
2019-12-03 06:00:26,148 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003442-0000000000000003443
2019-12-03 06:00:26,148 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003442-0000000000000003443 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 06:00:26,149 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003443 using no compression
2019-12-03 06:00:26,151 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003443 of size 53306 bytes saved in 0 seconds.
2019-12-03 06:00:26,171 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3441
2019-12-03 06:00:26,171 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003439, cpktTxId=0000000000000003439)
2019-12-03 06:00:27,129 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3443 to namenode at http://um1:50070 in 0.936 seconds
2019-12-03 06:00:27,129 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 06:10:28,176 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 06:10:28,178 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3444&endTxId=3445&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 06:10:28,188 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2019-12-03 06:10:28,188 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003444-0000000000000003445_0000000000033014661 size 0 bytes.
2019-12-03 06:10:28,189 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 06:10:28,189 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003444-0000000000000003445 expecting start txid #3444
2019-12-03 06:10:28,189 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003444-0000000000000003445
2019-12-03 06:10:28,189 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003444-0000000000000003445 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 06:10:28,190 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003445 using no compression
2019-12-03 06:10:28,192 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003445 of size 53306 bytes saved in 0 seconds.
2019-12-03 06:10:28,222 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3443
2019-12-03 06:10:28,222 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003441, cpktTxId=0000000000000003441)
2019-12-03 06:10:28,348 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3445 to namenode at http://um1:50070 in 0.015 seconds
2019-12-03 06:10:28,348 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 10:48:08,241 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 10:48:08,247 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3446&endTxId=3447&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 10:48:08,305 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 0.00 KB/s
2019-12-03 10:48:08,305 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003446-0000000000000003447_0000000000033615216 size 0 bytes.
2019-12-03 10:48:08,305 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 10:48:08,305 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003446-0000000000000003447 expecting start txid #3446
2019-12-03 10:48:08,305 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003446-0000000000000003447
2019-12-03 10:48:08,307 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003446-0000000000000003447 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 10:48:08,318 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003447 using no compression
2019-12-03 10:48:08,369 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003447 of size 53306 bytes saved in 0 seconds.
2019-12-03 10:48:08,389 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3445
2019-12-03 10:48:08,389 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003443, cpktTxId=0000000000000003443)
2019-12-03 10:48:08,637 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3447 to namenode at http://um1:50070 in 0.064 seconds
2019-12-03 10:48:08,637 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 10:58:08,940 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 10:58:08,941 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3448&endTxId=3449&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 10:58:08,944 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 10:58:08,944 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003448-0000000000000003449_0000000000034215910 size 0 bytes.
2019-12-03 10:58:08,945 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 10:58:08,945 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003448-0000000000000003449 expecting start txid #3448
2019-12-03 10:58:08,945 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003448-0000000000000003449
2019-12-03 10:58:08,945 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003448-0000000000000003449 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 10:58:08,945 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003449 using no compression
2019-12-03 10:58:08,948 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003449 of size 53306 bytes saved in 0 seconds.
2019-12-03 10:58:08,951 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3447
2019-12-03 10:58:08,951 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003445, cpktTxId=0000000000000003445)
2019-12-03 10:58:08,971 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3449 to namenode at http://um1:50070 in 0.014 seconds
2019-12-03 10:58:08,971 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 11:08:09,100 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 11:08:09,100 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3450&endTxId=3451&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 11:08:09,104 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 11:08:09,104 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003450-0000000000000003451_0000000000034816069 size 0 bytes.
2019-12-03 11:08:09,104 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 11:08:09,104 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003450-0000000000000003451 expecting start txid #3450
2019-12-03 11:08:09,104 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003450-0000000000000003451
2019-12-03 11:08:09,104 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003450-0000000000000003451 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 11:08:09,104 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003451 using no compression
2019-12-03 11:08:09,109 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003451 of size 53306 bytes saved in 0 seconds.
2019-12-03 11:08:09,111 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3449
2019-12-03 11:08:09,111 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003447, cpktTxId=0000000000000003447)
2019-12-03 11:08:09,144 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3451 to namenode at http://um1:50070 in 0.027 seconds
2019-12-03 11:08:09,144 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 11:18:09,284 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 11:18:09,284 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3452&endTxId=3453&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 11:18:09,288 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 11:18:09,288 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003452-0000000000000003453_0000000000035416254 size 0 bytes.
2019-12-03 11:18:09,288 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 11:18:09,288 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003452-0000000000000003453 expecting start txid #3452
2019-12-03 11:18:09,288 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003452-0000000000000003453
2019-12-03 11:18:09,288 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003452-0000000000000003453 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 11:18:09,289 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003453 using no compression
2019-12-03 11:18:09,291 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003453 of size 53306 bytes saved in 0 seconds.
2019-12-03 11:18:09,293 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3451
2019-12-03 11:18:09,293 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003449, cpktTxId=0000000000000003449)
2019-12-03 11:18:09,316 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3453 to namenode at http://um1:50070 in 0.019 seconds
2019-12-03 11:18:09,316 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 11:28:09,416 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 11:28:09,416 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3454&endTxId=3455&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 11:28:09,421 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 11:28:09,421 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003454-0000000000000003455_0000000000036016386 size 0 bytes.
2019-12-03 11:28:09,421 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 11:28:09,421 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003454-0000000000000003455 expecting start txid #3454
2019-12-03 11:28:09,421 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003454-0000000000000003455
2019-12-03 11:28:09,421 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003454-0000000000000003455 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 11:28:09,423 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003455 using no compression
2019-12-03 11:28:09,428 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003455 of size 53306 bytes saved in 0 seconds.
2019-12-03 11:28:09,435 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3453
2019-12-03 11:28:09,435 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003451, cpktTxId=0000000000000003451)
2019-12-03 11:28:09,453 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3455 to namenode at http://um1:50070 in 0.011 seconds
2019-12-03 11:28:09,453 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 11:38:09,613 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 11:38:09,613 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3456&endTxId=3457&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 11:38:09,620 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 11:38:09,620 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003456-0000000000000003457_0000000000036616583 size 0 bytes.
2019-12-03 11:38:09,620 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 11:38:09,620 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003456-0000000000000003457 expecting start txid #3456
2019-12-03 11:38:09,620 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003456-0000000000000003457
2019-12-03 11:38:09,620 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003456-0000000000000003457 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 11:38:09,621 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003457 using no compression
2019-12-03 11:38:09,625 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003457 of size 53306 bytes saved in 0 seconds.
2019-12-03 11:38:09,629 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3455
2019-12-03 11:38:09,629 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003453, cpktTxId=0000000000000003453)
2019-12-03 11:38:09,654 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3457 to namenode at http://um1:50070 in 0.017 seconds
2019-12-03 11:38:09,655 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 11:48:09,862 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 11:48:09,862 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3458&endTxId=3459&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 11:48:09,865 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 11:48:09,865 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003458-0000000000000003459_0000000000037216831 size 0 bytes.
2019-12-03 11:48:09,865 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 11:48:09,865 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003458-0000000000000003459 expecting start txid #3458
2019-12-03 11:48:09,865 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003458-0000000000000003459
2019-12-03 11:48:09,865 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003458-0000000000000003459 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 11:48:09,866 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003459 using no compression
2019-12-03 11:48:09,868 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003459 of size 53306 bytes saved in 0 seconds.
2019-12-03 11:48:09,871 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3457
2019-12-03 11:48:09,871 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003455, cpktTxId=0000000000000003455)
2019-12-03 11:48:09,890 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3459 to namenode at http://um1:50070 in 0.015 seconds
2019-12-03 11:48:09,890 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 11:58:10,088 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 11:58:10,089 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3460&endTxId=3461&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 11:58:10,093 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 11:58:10,093 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003460-0000000000000003461_0000000000037817058 size 0 bytes.
2019-12-03 11:58:10,094 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 11:58:10,094 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003460-0000000000000003461 expecting start txid #3460
2019-12-03 11:58:10,094 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003460-0000000000000003461
2019-12-03 11:58:10,094 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003460-0000000000000003461 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 11:58:10,094 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003461 using no compression
2019-12-03 11:58:10,096 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003461 of size 53306 bytes saved in 0 seconds.
2019-12-03 11:58:10,098 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3459
2019-12-03 11:58:10,098 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003457, cpktTxId=0000000000000003457)
2019-12-03 11:58:10,151 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3461 to namenode at http://um1:50070 in 0.046 seconds
2019-12-03 11:58:10,151 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 12:08:10,263 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 12:08:10,263 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3462&endTxId=3463&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 12:08:10,268 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 12:08:10,268 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003462-0000000000000003463_0000000000038417233 size 0 bytes.
2019-12-03 12:08:10,268 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 12:08:10,268 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003462-0000000000000003463 expecting start txid #3462
2019-12-03 12:08:10,268 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003462-0000000000000003463
2019-12-03 12:08:10,268 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003462-0000000000000003463 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 12:08:10,269 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003463 using no compression
2019-12-03 12:08:10,274 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003463 of size 53306 bytes saved in 0 seconds.
2019-12-03 12:08:10,277 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3461
2019-12-03 12:08:10,277 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003459, cpktTxId=0000000000000003459)
2019-12-03 12:08:10,303 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3463 to namenode at http://um1:50070 in 0.018 seconds
2019-12-03 12:08:10,303 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 12:18:10,452 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 12:18:10,452 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3464&endTxId=3465&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 12:18:10,456 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 12:18:10,456 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003464-0000000000000003465_0000000000039017422 size 0 bytes.
2019-12-03 12:18:10,456 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 12:18:10,456 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003464-0000000000000003465 expecting start txid #3464
2019-12-03 12:18:10,456 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003464-0000000000000003465
2019-12-03 12:18:10,457 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003464-0000000000000003465 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 12:18:10,457 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003465 using no compression
2019-12-03 12:18:10,472 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003465 of size 53306 bytes saved in 0 seconds.
2019-12-03 12:18:10,483 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3463
2019-12-03 12:18:10,483 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003461, cpktTxId=0000000000000003461)
2019-12-03 12:18:10,605 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3465 to namenode at http://um1:50070 in 0.057 seconds
2019-12-03 12:18:10,832 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 12:28:11,027 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 12:28:11,027 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3466&endTxId=3467&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 12:28:11,033 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 12:28:11,033 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003466-0000000000000003467_0000000000039617997 size 0 bytes.
2019-12-03 12:28:11,034 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 12:28:11,034 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003466-0000000000000003467 expecting start txid #3466
2019-12-03 12:28:11,034 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003466-0000000000000003467
2019-12-03 12:28:11,034 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003466-0000000000000003467 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 12:28:11,034 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003467 using no compression
2019-12-03 12:28:11,037 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003467 of size 53306 bytes saved in 0 seconds.
2019-12-03 12:28:11,043 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3465
2019-12-03 12:28:11,043 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003463, cpktTxId=0000000000000003463)
2019-12-03 12:28:11,159 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3467 to namenode at http://um1:50070 in 0.028 seconds
2019-12-03 12:28:11,159 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 12:38:11,311 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 12:38:11,312 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3468&endTxId=3469&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 12:38:11,320 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 12:38:11,320 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003468-0000000000000003469_0000000000040218282 size 0 bytes.
2019-12-03 12:38:11,320 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 12:38:11,320 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003468-0000000000000003469 expecting start txid #3468
2019-12-03 12:38:11,320 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003468-0000000000000003469
2019-12-03 12:38:11,320 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003468-0000000000000003469 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 12:38:11,323 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003469 using no compression
2019-12-03 12:38:11,326 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003469 of size 53306 bytes saved in 0 seconds.
2019-12-03 12:38:11,339 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3467
2019-12-03 12:38:11,339 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003465, cpktTxId=0000000000000003465)
2019-12-03 12:38:11,383 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3469 to namenode at http://um1:50070 in 0.03 seconds
2019-12-03 12:38:11,383 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 12:48:11,543 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 12:48:11,543 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3470&endTxId=3471&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 12:48:11,549 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 12:48:11,549 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003470-0000000000000003471_0000000000040818512 size 0 bytes.
2019-12-03 12:48:11,549 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 12:48:11,549 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003470-0000000000000003471 expecting start txid #3470
2019-12-03 12:48:11,549 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003470-0000000000000003471
2019-12-03 12:48:11,550 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003470-0000000000000003471 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 12:48:11,550 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003471 using no compression
2019-12-03 12:48:11,553 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003471 of size 53306 bytes saved in 0 seconds.
2019-12-03 12:48:11,556 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3469
2019-12-03 12:48:11,556 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003467, cpktTxId=0000000000000003467)
2019-12-03 12:48:11,574 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3471 to namenode at http://um1:50070 in 0.014 seconds
2019-12-03 12:48:11,574 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 12:58:11,680 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 12:58:11,680 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3472&endTxId=3473&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 12:58:11,685 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 12:58:11,686 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003472-0000000000000003473_0000000000041418650 size 0 bytes.
2019-12-03 12:58:11,686 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 12:58:11,686 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003472-0000000000000003473 expecting start txid #3472
2019-12-03 12:58:11,686 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003472-0000000000000003473
2019-12-03 12:58:11,686 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003472-0000000000000003473 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 12:58:11,686 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003473 using no compression
2019-12-03 12:58:11,688 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003473 of size 53306 bytes saved in 0 seconds.
2019-12-03 12:58:11,691 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3471
2019-12-03 12:58:11,691 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003469, cpktTxId=0000000000000003469)
2019-12-03 12:58:11,710 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3473 to namenode at http://um1:50070 in 0.011 seconds
2019-12-03 12:58:11,710 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 13:08:11,890 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 13:08:11,890 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3474&endTxId=3475&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 13:08:11,894 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 13:08:11,894 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003474-0000000000000003475_0000000000042018860 size 0 bytes.
2019-12-03 13:08:11,894 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 13:08:11,894 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003474-0000000000000003475 expecting start txid #3474
2019-12-03 13:08:11,894 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003474-0000000000000003475
2019-12-03 13:08:11,894 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003474-0000000000000003475 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 13:08:11,895 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003475 using no compression
2019-12-03 13:08:11,897 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003475 of size 53306 bytes saved in 0 seconds.
2019-12-03 13:08:11,902 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3473
2019-12-03 13:08:11,902 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003471, cpktTxId=0000000000000003471)
2019-12-03 13:08:11,976 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3475 to namenode at http://um1:50070 in 0.067 seconds
2019-12-03 13:08:11,976 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 13:18:12,129 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 13:18:12,129 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3476&endTxId=3477&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 13:18:12,135 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 13:18:12,135 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003476-0000000000000003477_0000000000042619098 size 0 bytes.
2019-12-03 13:18:12,135 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 13:18:12,135 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003476-0000000000000003477 expecting start txid #3476
2019-12-03 13:18:12,135 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003476-0000000000000003477
2019-12-03 13:18:12,136 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003476-0000000000000003477 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 13:18:12,136 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003477 using no compression
2019-12-03 13:18:12,138 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003477 of size 53306 bytes saved in 0 seconds.
2019-12-03 13:18:12,141 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3475
2019-12-03 13:18:12,141 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003473, cpktTxId=0000000000000003473)
2019-12-03 13:18:12,183 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3477 to namenode at http://um1:50070 in 0.03 seconds
2019-12-03 13:18:12,183 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-03 13:28:12,437 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-03 13:28:12,437 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3478&endTxId=3479&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-03 13:28:12,441 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-03 13:28:12,441 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003478-0000000000000003479_0000000000043219407 size 0 bytes.
2019-12-03 13:28:12,441 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-03 13:28:12,441 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003478-0000000000000003479 expecting start txid #3478
2019-12-03 13:28:12,441 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003478-0000000000000003479
2019-12-03 13:28:12,441 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003478-0000000000000003479 of size 42 edits # 2 loaded in 0 seconds
2019-12-03 13:28:12,441 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003479 using no compression
2019-12-03 13:28:12,443 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003479 of size 53306 bytes saved in 0 seconds.
2019-12-03 13:28:12,446 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3477
2019-12-03 13:28:12,446 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003475, cpktTxId=0000000000000003475)
2019-12-03 13:28:12,550 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3479 to namenode at http://um1:50070 in 0.099 seconds
2019-12-03 13:28:12,550 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-14 17:51:29,790 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.251.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2019-12-14 17:51:29,835 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-12-14 17:51:31,885 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-12-14 17:51:32,207 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2019-12-14 17:51:32,207 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2019-12-14 17:51:32,708 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2019-12-14 17:51:32,709 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2019-12-14 17:51:33,034 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 2858@um2
2019-12-14 17:51:33,257 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 2858@um2
2019-12-14 17:51:33,364 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2019-12-14 17:51:33,432 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2019-12-14 17:51:33,677 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2019-12-14 17:51:33,677 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-12-14 17:51:33,679 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-12-14 17:51:33,682 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Dec 14 17:51:33
2019-12-14 17:51:33,700 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-12-14 17:51:33,701 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-12-14 17:51:33,712 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-12-14 17:51:33,712 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-12-14 17:51:33,766 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-12-14 17:51:33,766 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2019-12-14 17:51:33,766 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-12-14 17:51:33,766 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-12-14 17:51:33,767 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-12-14 17:51:33,767 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-12-14 17:51:33,767 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-12-14 17:51:33,767 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-12-14 17:51:33,768 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2019-12-14 17:51:33,768 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-12-14 17:51:33,768 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-12-14 17:51:33,768 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-12-14 17:51:33,791 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-12-14 17:51:35,303 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-12-14 17:51:35,303 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-12-14 17:51:35,303 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-12-14 17:51:35,303 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-12-14 17:51:35,305 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2019-12-14 17:51:35,315 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-12-14 17:51:35,315 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-12-14 17:51:35,315 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-12-14 17:51:35,315 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-12-14 17:51:35,318 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-12-14 17:51:35,318 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2019-12-14 17:51:35,318 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2019-12-14 17:51:35,320 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2019-12-14 17:51:35,321 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2019-12-14 17:51:35,321 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2019-12-14 17:51:35,363 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2019-12-14 17:51:35,591 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-12-14 17:51:35,604 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2019-12-14 17:51:35,625 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-12-14 17:51:35,641 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2019-12-14 17:51:35,641 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-12-14 17:51:35,641 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-12-14 17:51:35,688 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2019-12-14 17:51:35,688 INFO org.mortbay.log: jetty-6.1.26
2019-12-14 17:51:36,252 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2019-12-14 17:51:36,252 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2019-12-14 17:51:36,253 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2019-12-14 17:51:36,253 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2019-12-14 18:00:36,507 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2019-12-14 18:00:36,704 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=3480&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-14 18:00:36,759 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2019-12-14 18:00:37,052 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 2736.84 KB/s
2019-12-14 18:00:37,053 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000003480 size 53306 bytes.
2019-12-14 18:00:37,062 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3481&endTxId=3482&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-14 18:00:37,068 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-14 18:00:37,068 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003481-0000000000000003482_0000000000000644159 size 0 bytes.
2019-12-14 18:00:37,128 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 565 INodes.
2019-12-14 18:00:37,213 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-12-14 18:00:37,213 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 3480 from /orgz/snnfsi/current/fsimage_0000000000000003480
2019-12-14 18:00:37,213 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 1 entries 205 lookups
2019-12-14 18:00:37,220 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-14 18:00:37,224 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003481-0000000000000003482 expecting start txid #3481
2019-12-14 18:00:37,224 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003481-0000000000000003482
2019-12-14 18:00:37,249 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003481-0000000000000003482 of size 42 edits # 2 loaded in 0 seconds
2019-12-14 18:00:37,257 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003482 using no compression
2019-12-14 18:00:37,360 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003482 of size 53306 bytes saved in 0 seconds.
2019-12-14 18:00:37,379 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3480
2019-12-14 18:00:37,379 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003477, cpktTxId=0000000000000003477)
2019-12-14 18:00:37,381 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003479, cpktTxId=0000000000000003479)
2019-12-14 18:00:37,503 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3482 to namenode at http://um1:50070 in 0.04 seconds
2019-12-14 18:00:37,503 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-14 18:10:37,677 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-14 18:10:37,677 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3483&endTxId=3484&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-14 18:10:37,683 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-14 18:10:37,683 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003483-0000000000000003484_0000000000001244775 size 0 bytes.
2019-12-14 18:10:37,683 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-14 18:10:37,683 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003483-0000000000000003484 expecting start txid #3483
2019-12-14 18:10:37,683 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003483-0000000000000003484
2019-12-14 18:10:37,684 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003483-0000000000000003484 of size 42 edits # 2 loaded in 0 seconds
2019-12-14 18:10:37,685 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003484 using no compression
2019-12-14 18:10:37,706 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003484 of size 53306 bytes saved in 0 seconds.
2019-12-14 18:10:37,710 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3482
2019-12-14 18:10:37,710 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003480, cpktTxId=0000000000000003480)
2019-12-14 18:10:37,747 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3484 to namenode at http://um1:50070 in 0.017 seconds
2019-12-14 18:10:37,747 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-14 18:20:37,880 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-14 18:20:37,880 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3485&endTxId=3486&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-14 18:20:37,885 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-14 18:20:37,885 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003485-0000000000000003486_0000000000001844977 size 0 bytes.
2019-12-14 18:20:37,885 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-14 18:20:37,886 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003485-0000000000000003486 expecting start txid #3485
2019-12-14 18:20:37,886 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003485-0000000000000003486
2019-12-14 18:20:37,886 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003485-0000000000000003486 of size 42 edits # 2 loaded in 0 seconds
2019-12-14 18:20:37,889 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003486 using no compression
2019-12-14 18:20:37,918 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003486 of size 53306 bytes saved in 0 seconds.
2019-12-14 18:20:37,924 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3484
2019-12-14 18:20:37,924 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003482, cpktTxId=0000000000000003482)
2019-12-14 18:20:37,961 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3486 to namenode at http://um1:50070 in 0.026 seconds
2019-12-14 18:20:37,961 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
2019-12-14 18:30:38,075 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2019-12-14 18:30:38,075 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3487&endTxId=3488&storageInfo=-60:811552738:0:CID-52b20ea5-265a-4894-9ae4-b6de307aaed4
2019-12-14 18:30:38,080 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2019-12-14 18:30:38,081 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003487-0000000000000003488_0000000000002445173 size 0 bytes.
2019-12-14 18:30:38,081 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2019-12-14 18:30:38,081 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000003487-0000000000000003488 expecting start txid #3487
2019-12-14 18:30:38,081 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000003487-0000000000000003488
2019-12-14 18:30:38,081 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000003487-0000000000000003488 of size 42 edits # 2 loaded in 0 seconds
2019-12-14 18:30:38,082 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003488 using no compression
2019-12-14 18:30:38,092 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000003488 of size 53306 bytes saved in 0 seconds.
2019-12-14 18:30:38,096 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3486
2019-12-14 18:30:38,096 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000003484, cpktTxId=0000000000000003484)
2019-12-14 18:30:38,140 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3488 to namenode at http://um1:50070 in 0.015 seconds
2019-12-14 18:30:38,140 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 53306
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    2020-01-06 11:37:20,735 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.251.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2020-01-06 11:37:20,746 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-01-06 11:37:21,277 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-01-06 11:37:21,361 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-01-06 11:37:21,361 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2020-01-06 11:37:21,523 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2020-01-06 11:37:21,523 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2020-01-06 11:37:21,611 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 3585@um2
2020-01-06 11:37:21,614 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 3585@um2
2020-01-06 11:37:21,617 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2020-01-06 11:37:21,625 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2020-01-06 11:37:21,670 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2020-01-06 11:37:21,670 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2020-01-06 11:37:21,672 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-01-06 11:37:21,673 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2020 Jan 06 11:37:21
2020-01-06 11:37:21,674 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2020-01-06 11:37:21,674 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-01-06 11:37:21,675 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2020-01-06 11:37:21,675 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2020-01-06 11:37:21,684 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2020-01-06 11:37:21,684 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2020-01-06 11:37:21,684 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2020-01-06 11:37:21,684 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2020-01-06 11:37:21,684 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2020-01-06 11:37:21,684 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2020-01-06 11:37:21,684 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2020-01-06 11:37:21,684 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2020-01-06 11:37:21,685 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2020-01-06 11:37:21,685 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2020-01-06 11:37:21,685 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2020-01-06 11:37:21,685 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2020-01-06 11:37:21,687 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2020-01-06 11:37:22,022 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2020-01-06 11:37:22,022 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-01-06 11:37:22,023 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2020-01-06 11:37:22,023 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2020-01-06 11:37:22,027 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2020-01-06 11:37:22,038 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2020-01-06 11:37:22,038 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-01-06 11:37:22,038 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2020-01-06 11:37:22,038 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2020-01-06 11:37:22,039 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-01-06 11:37:22,039 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2020-01-06 11:37:22,039 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2020-01-06 11:37:22,042 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2020-01-06 11:37:22,042 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2020-01-06 11:37:22,042 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2020-01-06 11:37:22,053 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2020-01-06 11:37:22,105 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-01-06 11:37:22,107 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2020-01-06 11:37:22,115 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-01-06 11:37:22,118 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2020-01-06 11:37:22,120 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-01-06 11:37:22,120 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-01-06 11:37:22,145 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2020-01-06 11:37:22,145 INFO org.mortbay.log: jetty-6.1.26
2020-01-06 11:37:22,429 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2020-01-06 11:37:22,430 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2020-01-06 11:37:22,430 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2020-01-06 11:37:22,430 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2020-01-06 11:38:22,560 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2020-01-06 11:38:22,708 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=0&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-06 11:38:22,758 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2020-01-06 11:38:23,056 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 0.00 KB/s
2020-01-06 11:38:23,057 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 320 bytes.
2020-01-06 11:38:23,066 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1&endTxId=2&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-06 11:38:23,073 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-01-06 11:38:23,073 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000002_0000000000000665429 size 0 bytes.
2020-01-06 11:38:23,135 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2020-01-06 11:38:23,154 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2020-01-06 11:38:23,154 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /orgz/snnfsi/current/fsimage_0000000000000000000
2020-01-06 11:38:23,154 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2020-01-06 11:38:23,160 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-01-06 11:38:23,163 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000001-0000000000000000002 expecting start txid #1
2020-01-06 11:38:23,163 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000001-0000000000000000002
2020-01-06 11:38:23,177 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000001-0000000000000000002 of size 42 edits # 2 loaded in 0 seconds
2020-01-06 11:38:23,181 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000002 using no compression
2020-01-06 11:38:23,215 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000002 of size 320 bytes saved in 0 seconds.
2020-01-06 11:38:23,226 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /orgz/snnfsi
2020-01-06 11:38:23,227 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /orgz/snnedits
2020-01-06 11:38:23,264 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2 to namenode at http://um1:50070 in 0.027 seconds
2020-01-06 11:38:23,265 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 320
2020-01-06 11:48:23,443 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-01-06 11:48:23,443 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3&endTxId=11&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-06 11:48:23,454 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2020-01-06 11:48:23,454 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000003-0000000000000000011_0000000000001265807 size 0 bytes.
2020-01-06 11:48:23,455 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-01-06 11:48:23,455 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000003-0000000000000000011 expecting start txid #3
2020-01-06 11:48:23,455 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000003-0000000000000000011
2020-01-06 11:48:23,479 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000003-0000000000000000011 of size 656 edits # 9 loaded in 0 seconds
2020-01-06 11:48:23,480 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000011 using no compression
2020-01-06 11:48:23,488 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000011 of size 479 bytes saved in 0 seconds.
2020-01-06 11:48:23,512 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2
2020-01-06 11:48:23,513 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-01-06 11:48:23,532 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 11 to namenode at http://um1:50070 in 0.016 seconds
2020-01-06 11:48:23,533 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 479
2020-01-06 16:31:52,569 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.251.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2020-01-06 16:31:52,579 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-01-06 16:31:53,094 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-01-06 16:31:53,155 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-01-06 16:31:53,155 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2020-01-06 16:31:53,256 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2020-01-06 16:31:53,256 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2020-01-06 16:31:53,327 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 2521@um2
2020-01-06 16:31:53,377 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 2521@um2
2020-01-06 16:31:53,382 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2020-01-06 16:31:53,407 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2020-01-06 16:31:53,463 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2020-01-06 16:31:53,463 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2020-01-06 16:31:53,466 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-01-06 16:31:53,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2020 Jan 06 16:31:53
2020-01-06 16:31:53,471 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2020-01-06 16:31:53,471 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-01-06 16:31:53,473 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2020-01-06 16:31:53,473 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2020-01-06 16:31:53,483 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2020-01-06 16:31:53,484 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2020-01-06 16:31:53,484 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2020-01-06 16:31:53,484 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2020-01-06 16:31:53,484 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2020-01-06 16:31:53,484 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2020-01-06 16:31:53,484 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2020-01-06 16:31:53,484 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2020-01-06 16:31:53,485 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2020-01-06 16:31:53,485 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2020-01-06 16:31:53,485 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2020-01-06 16:31:53,485 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2020-01-06 16:31:53,487 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2020-01-06 16:31:53,795 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2020-01-06 16:31:53,795 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-01-06 16:31:53,795 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2020-01-06 16:31:53,795 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2020-01-06 16:31:53,800 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2020-01-06 16:31:53,809 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2020-01-06 16:31:53,809 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-01-06 16:31:53,810 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2020-01-06 16:31:53,810 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2020-01-06 16:31:53,811 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-01-06 16:31:53,811 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2020-01-06 16:31:53,811 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2020-01-06 16:31:53,814 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2020-01-06 16:31:53,814 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2020-01-06 16:31:53,814 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2020-01-06 16:31:53,824 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2020-01-06 16:31:53,935 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-01-06 16:31:53,937 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2020-01-06 16:31:53,944 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-01-06 16:31:53,946 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2020-01-06 16:31:53,946 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-01-06 16:31:53,946 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-01-06 16:31:53,957 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2020-01-06 16:31:53,957 INFO org.mortbay.log: jetty-6.1.26
2020-01-06 16:31:54,179 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2020-01-06 16:31:54,179 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2020-01-06 16:31:54,180 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2020-01-06 16:31:54,180 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2020-01-06 16:32:54,326 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2020-01-06 16:32:54,556 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=23&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-06 16:32:54,588 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2020-01-06 16:32:54,802 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2020-01-06 16:32:54,803 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000023 size 982 bytes.
2020-01-06 16:32:54,820 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=24&endTxId=25&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-06 16:32:54,827 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-01-06 16:32:54,827 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000024-0000000000000000025_0000000000001841238 size 0 bytes.
2020-01-06 16:32:54,867 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 11 INodes.
2020-01-06 16:32:54,892 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2020-01-06 16:32:54,892 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 23 from /orgz/snnfsi/current/fsimage_0000000000000000023
2020-01-06 16:32:54,892 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2020-01-06 16:32:54,901 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-01-06 16:32:54,904 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000024-0000000000000000025 expecting start txid #24
2020-01-06 16:32:54,904 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000024-0000000000000000025
2020-01-06 16:32:54,918 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000024-0000000000000000025 of size 42 edits # 2 loaded in 0 seconds
2020-01-06 16:32:54,922 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000025 using no compression
2020-01-06 16:32:54,980 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000025 of size 982 bytes saved in 0 seconds.
2020-01-06 16:32:54,994 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 23
2020-01-06 16:32:54,994 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000002, cpktTxId=0000000000000000002)
2020-01-06 16:32:54,994 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000011, cpktTxId=0000000000000000011)
2020-01-06 16:32:55,021 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 25 to namenode at http://um1:50070 in 0.02 seconds
2020-01-06 16:32:55,022 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 982
2020-01-06 16:42:55,190 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-01-06 16:42:55,190 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=26&endTxId=30&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-06 16:42:55,197 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-01-06 16:42:55,197 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000026-0000000000000000030_0000000000002441609 size 0 bytes.
2020-01-06 16:42:55,198 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-01-06 16:42:55,198 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000026-0000000000000000030 expecting start txid #26
2020-01-06 16:42:55,198 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000026-0000000000000000030
2020-01-06 16:42:55,213 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000026-0000000000000000030 of size 385 edits # 5 loaded in 0 seconds
2020-01-06 16:42:55,214 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000030 using no compression
2020-01-06 16:42:55,217 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000030 of size 982 bytes saved in 0 seconds.
2020-01-06 16:42:55,220 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 25
2020-01-06 16:42:55,220 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000023, cpktTxId=0000000000000000023)
2020-01-06 16:42:55,234 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 30 to namenode at http://um1:50070 in 0.011 seconds
2020-01-06 16:42:55,234 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 982
2020-01-06 16:52:55,367 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-01-06 16:52:55,368 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=31&endTxId=140&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-06 16:52:55,374 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 7000.00 KB/s
2020-01-06 16:52:55,374 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000031-0000000000000000140_0000000000003041787 size 0 bytes.
2020-01-06 16:52:55,375 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-01-06 16:52:55,375 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000031-0000000000000000140 expecting start txid #31
2020-01-06 16:52:55,375 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000031-0000000000000000140
2020-01-06 16:52:55,422 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000031-0000000000000000140 of size 14697 edits # 110 loaded in 0 seconds
2020-01-06 16:52:55,423 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000140 using no compression
2020-01-06 16:52:55,426 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000140 of size 2021 bytes saved in 0 seconds.
2020-01-06 16:52:55,430 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 30
2020-01-06 16:52:55,431 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000025, cpktTxId=0000000000000000025)
2020-01-06 16:52:55,450 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 140 to namenode at http://um1:50070 in 0.016 seconds
2020-01-06 16:52:55,450 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2021
2020-01-11 17:01:23,580 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.251.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2020-01-11 17:01:23,635 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-01-11 17:01:24,958 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-01-11 17:01:25,129 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-01-11 17:01:25,129 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2020-01-11 17:01:25,538 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2020-01-11 17:01:25,539 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2020-01-11 17:01:25,693 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 18540@um2
2020-01-11 17:01:25,805 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 18540@um2
2020-01-11 17:01:25,819 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2020-01-11 17:01:25,832 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2020-01-11 17:01:25,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2020-01-11 17:01:25,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2020-01-11 17:01:25,935 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-01-11 17:01:25,948 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2020 Jan 11 17:01:25
2020-01-11 17:01:25,951 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2020-01-11 17:01:25,951 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-01-11 17:01:25,954 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2020-01-11 17:01:25,955 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2020-01-11 17:01:25,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2020-01-11 17:01:25,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2020-01-11 17:01:25,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2020-01-11 17:01:25,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2020-01-11 17:01:25,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2020-01-11 17:01:25,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2020-01-11 17:01:25,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2020-01-11 17:01:25,975 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2020-01-11 17:01:25,976 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2020-01-11 17:01:25,976 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2020-01-11 17:01:25,977 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2020-01-11 17:01:25,977 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2020-01-11 17:01:25,982 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2020-01-11 17:01:26,953 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2020-01-11 17:01:26,953 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-01-11 17:01:26,954 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2020-01-11 17:01:26,954 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2020-01-11 17:01:26,970 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2020-01-11 17:01:27,017 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2020-01-11 17:01:27,017 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-01-11 17:01:27,018 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2020-01-11 17:01:27,018 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2020-01-11 17:01:27,030 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-01-11 17:01:27,030 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2020-01-11 17:01:27,030 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2020-01-11 17:01:27,035 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2020-01-11 17:01:27,035 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2020-01-11 17:01:27,035 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2020-01-11 17:01:27,079 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2020-01-11 17:01:27,293 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-01-11 17:01:27,305 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2020-01-11 17:01:27,363 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-01-11 17:01:27,373 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2020-01-11 17:01:27,374 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-01-11 17:01:27,374 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-01-11 17:01:27,657 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2020-01-11 17:01:27,657 INFO org.mortbay.log: jetty-6.1.26
2020-01-11 17:01:28,298 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2020-01-11 17:01:28,298 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2020-01-11 17:01:28,299 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2020-01-11 17:01:28,299 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2020-01-11 17:06:28,557 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2020-01-11 17:06:28,764 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=209&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-11 17:06:28,817 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2020-01-11 17:06:29,065 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 60.61 KB/s
2020-01-11 17:06:29,067 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000209 size 2618 bytes.
2020-01-11 17:06:29,078 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=210&endTxId=211&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-11 17:06:29,083 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-01-11 17:06:29,083 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000210-0000000000000000211_0000000000000626545 size 0 bytes.
2020-01-11 17:06:29,124 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 35 INodes.
2020-01-11 17:06:29,151 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2020-01-11 17:06:29,152 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 209 from /orgz/snnfsi/current/fsimage_0000000000000000209
2020-01-11 17:06:29,152 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2020-01-11 17:06:29,155 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-01-11 17:06:29,158 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000210-0000000000000000211 expecting start txid #210
2020-01-11 17:06:29,159 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000210-0000000000000000211
2020-01-11 17:06:29,182 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000210-0000000000000000211 of size 42 edits # 2 loaded in 0 seconds
2020-01-11 17:06:29,194 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000211 using no compression
2020-01-11 17:06:29,259 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000211 of size 2618 bytes saved in 0 seconds.
2020-01-11 17:06:29,272 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 209
2020-01-11 17:06:29,272 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000140, cpktTxId=0000000000000000140)
2020-01-11 17:06:29,273 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000030, cpktTxId=0000000000000000030)
2020-01-11 17:06:29,299 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 211 to namenode at http://um1:50070 in 0.019 seconds
2020-01-11 17:06:29,300 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 2618
2020-01-11 17:16:29,413 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-01-11 17:16:29,414 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=212&endTxId=302&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-11 17:16:29,425 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 2750.00 KB/s
2020-01-11 17:16:29,425 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000212-0000000000000000302_0000000000001226881 size 0 bytes.
2020-01-11 17:16:29,425 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-01-11 17:16:29,426 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000212-0000000000000000302 expecting start txid #212
2020-01-11 17:16:29,426 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000212-0000000000000000302
2020-01-11 17:16:29,467 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000212-0000000000000000302 of size 11602 edits # 91 loaded in 0 seconds
2020-01-11 17:16:29,469 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000302 using no compression
2020-01-11 17:16:29,481 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000302 of size 3382 bytes saved in 0 seconds.
2020-01-11 17:16:29,485 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 211
2020-01-11 17:16:29,485 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000209, cpktTxId=0000000000000000209)
2020-01-11 17:16:29,501 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 302 to namenode at http://um1:50070 in 0.014 seconds
2020-01-11 17:16:29,501 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 3382
2020-01-11 17:26:29,644 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-01-11 17:26:29,645 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=303&endTxId=479&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-11 17:26:29,650 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 11000.00 KB/s
2020-01-11 17:26:29,650 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000303-0000000000000000479_0000000000001827112 size 0 bytes.
2020-01-11 17:26:29,650 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-01-11 17:26:29,650 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000303-0000000000000000479 expecting start txid #303
2020-01-11 17:26:29,650 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000303-0000000000000000479
2020-01-11 17:26:29,682 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000303-0000000000000000479 of size 23069 edits # 177 loaded in 0 seconds
2020-01-11 17:26:29,683 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000479 using no compression
2020-01-11 17:26:29,688 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000479 of size 4356 bytes saved in 0 seconds.
2020-01-11 17:26:29,691 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 302
2020-01-11 17:26:29,691 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000211, cpktTxId=0000000000000000211)
2020-01-11 17:26:29,705 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 479 to namenode at http://um1:50070 in 0.01 seconds
2020-01-11 17:26:29,705 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4356
2020-01-11 17:36:29,858 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-01-11 17:36:29,859 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=480&endTxId=515&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-11 17:36:29,864 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1500.00 KB/s
2020-01-11 17:36:29,864 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000480-0000000000000000515_0000000000002427326 size 0 bytes.
2020-01-11 17:36:29,865 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-01-11 17:36:29,865 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000480-0000000000000000515 expecting start txid #480
2020-01-11 17:36:29,865 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000480-0000000000000000515
2020-01-11 17:36:29,867 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000480-0000000000000000515 of size 3396 edits # 36 loaded in 0 seconds
2020-01-11 17:36:29,868 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000515 using no compression
2020-01-11 17:36:29,881 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000515 of size 4924 bytes saved in 0 seconds.
2020-01-11 17:36:29,883 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 479
2020-01-11 17:36:29,884 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000302, cpktTxId=0000000000000000302)
2020-01-11 17:36:29,897 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 515 to namenode at http://um1:50070 in 0.011 seconds
2020-01-11 17:36:29,897 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4924
2020-01-11 17:44:06,072 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2020-01-11 17:44:06,075 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.251.4
************************************************************/
2020-01-11 17:46:57,495 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.251.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2020-01-11 17:46:57,506 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-01-11 17:46:58,204 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-01-11 17:46:58,353 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-01-11 17:46:58,353 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2020-01-11 17:46:58,554 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2020-01-11 17:46:58,555 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2020-01-11 17:46:58,645 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 21861@um2
2020-01-11 17:46:58,724 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 21861@um2
2020-01-11 17:46:58,738 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2020-01-11 17:46:58,747 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2020-01-11 17:46:58,817 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2020-01-11 17:46:58,817 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2020-01-11 17:46:58,820 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-01-11 17:46:58,824 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2020 Jan 11 17:46:58
2020-01-11 17:46:58,827 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2020-01-11 17:46:58,827 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-01-11 17:46:58,830 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2020-01-11 17:46:58,830 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2020-01-11 17:46:58,877 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2020-01-11 17:46:58,878 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2020-01-11 17:46:58,878 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2020-01-11 17:46:58,878 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2020-01-11 17:46:58,878 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2020-01-11 17:46:58,878 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2020-01-11 17:46:58,878 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2020-01-11 17:46:58,878 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2020-01-11 17:46:58,879 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2020-01-11 17:46:58,879 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2020-01-11 17:46:58,879 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2020-01-11 17:46:58,880 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2020-01-11 17:46:58,882 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2020-01-11 17:46:59,463 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2020-01-11 17:46:59,464 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-01-11 17:46:59,464 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2020-01-11 17:46:59,464 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2020-01-11 17:46:59,465 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2020-01-11 17:46:59,476 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2020-01-11 17:46:59,476 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-01-11 17:46:59,477 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2020-01-11 17:46:59,477 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2020-01-11 17:46:59,514 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-01-11 17:46:59,514 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2020-01-11 17:46:59,517 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2020-01-11 17:46:59,519 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2020-01-11 17:46:59,519 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2020-01-11 17:46:59,520 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2020-01-11 17:46:59,529 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2020-01-11 17:46:59,583 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-01-11 17:46:59,586 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2020-01-11 17:46:59,599 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-01-11 17:46:59,611 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2020-01-11 17:46:59,611 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-01-11 17:46:59,611 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-01-11 17:46:59,631 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2020-01-11 17:46:59,632 INFO org.mortbay.log: jetty-6.1.26
2020-01-11 17:46:59,809 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2020-01-11 17:46:59,809 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2020-01-11 17:46:59,809 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2020-01-11 17:46:59,809 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2020-01-11 17:48:00,071 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2020-01-11 17:48:00,245 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=515&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-11 17:48:00,288 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2020-01-11 17:48:00,472 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 1000.00 KB/s
2020-01-11 17:48:00,474 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000515 size 4924 bytes.
2020-01-11 17:48:00,481 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=516&endTxId=577&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-11 17:48:00,507 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 51200.00 KB/s
2020-01-11 17:48:00,507 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000516-0000000000000000577_0000000000003117947 size 0 bytes.
2020-01-11 17:48:00,508 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=578&endTxId=579&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-11 17:48:00,518 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-01-11 17:48:00,518 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000578-0000000000000000579_0000000000003117975 size 0 bytes.
2020-01-11 17:48:00,562 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 64 INodes.
2020-01-11 17:48:00,588 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2020-01-11 17:48:00,588 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 515 from /orgz/snnfsi/current/fsimage_0000000000000000515
2020-01-11 17:48:00,588 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2020-01-11 17:48:00,592 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2020-01-11 17:48:00,594 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000516-0000000000000000577 expecting start txid #516
2020-01-11 17:48:00,595 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000516-0000000000000000577
2020-01-11 17:48:00,637 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000516-0000000000000000577 of size 1048576 edits # 62 loaded in 0 seconds
2020-01-11 17:48:00,637 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000578-0000000000000000579 expecting start txid #578
2020-01-11 17:48:00,637 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000578-0000000000000000579
2020-01-11 17:48:00,637 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000578-0000000000000000579 of size 42 edits # 2 loaded in 0 seconds
2020-01-11 17:48:00,641 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000579 using no compression
2020-01-11 17:48:00,701 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000579 of size 5770 bytes saved in 0 seconds.
2020-01-11 17:48:00,708 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 515
2020-01-11 17:48:00,708 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000479, cpktTxId=0000000000000000479)
2020-01-11 17:48:00,783 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 579 to namenode at http://um1:50070 in 0.061 seconds
2020-01-11 17:48:00,784 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5770
2020-01-11 17:56:24,519 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2020-01-11 17:56:24,521 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.251.4
************************************************************/
2020-01-11 17:58:47,998 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.251.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2020-01-11 17:58:48,018 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-01-11 17:58:48,717 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-01-11 17:58:48,775 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-01-11 17:58:48,776 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2020-01-11 17:58:48,881 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2020-01-11 17:58:48,881 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2020-01-11 17:58:48,923 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 23300@um2
2020-01-11 17:58:48,964 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 23300@um2
2020-01-11 17:58:48,968 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2020-01-11 17:58:48,973 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2020-01-11 17:58:49,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2020-01-11 17:58:49,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2020-01-11 17:58:49,012 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-01-11 17:58:49,014 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2020 Jan 11 17:58:49
2020-01-11 17:58:49,015 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2020-01-11 17:58:49,016 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-01-11 17:58:49,017 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2020-01-11 17:58:49,017 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2020-01-11 17:58:49,033 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2020-01-11 17:58:49,034 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2020-01-11 17:58:49,034 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2020-01-11 17:58:49,034 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2020-01-11 17:58:49,034 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2020-01-11 17:58:49,034 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2020-01-11 17:58:49,034 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2020-01-11 17:58:49,034 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2020-01-11 17:58:49,034 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2020-01-11 17:58:49,034 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2020-01-11 17:58:49,035 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2020-01-11 17:58:49,035 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2020-01-11 17:58:49,037 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2020-01-11 17:58:49,385 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2020-01-11 17:58:49,385 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-01-11 17:58:49,385 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2020-01-11 17:58:49,385 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2020-01-11 17:58:49,386 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2020-01-11 17:58:49,391 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2020-01-11 17:58:49,392 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-01-11 17:58:49,392 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2020-01-11 17:58:49,392 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2020-01-11 17:58:49,406 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-01-11 17:58:49,406 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2020-01-11 17:58:49,406 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2020-01-11 17:58:49,407 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2020-01-11 17:58:49,408 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2020-01-11 17:58:49,408 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2020-01-11 17:58:49,417 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2020-01-11 17:58:49,462 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-01-11 17:58:49,465 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2020-01-11 17:58:49,473 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-01-11 17:58:49,475 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2020-01-11 17:58:49,476 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-01-11 17:58:49,476 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-01-11 17:58:49,489 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2020-01-11 17:58:49,489 INFO org.mortbay.log: jetty-6.1.26
2020-01-11 17:58:49,657 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2020-01-11 17:58:49,657 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2020-01-11 17:58:49,657 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2020-01-11 17:58:49,657 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2020-01-11 17:59:49,909 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2020-01-11 17:59:50,037 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=579&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-11 17:59:50,078 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2020-01-11 17:59:50,257 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 500.00 KB/s
2020-01-11 17:59:50,257 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000579 size 5770 bytes.
2020-01-11 17:59:50,272 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=580&endTxId=638&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-11 17:59:50,293 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 73142.86 KB/s
2020-01-11 17:59:50,293 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000580-0000000000000000638_0000000000003827738 size 0 bytes.
2020-01-11 17:59:50,294 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=639&endTxId=640&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-11 17:59:50,305 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-01-11 17:59:50,305 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000639-0000000000000000640_0000000000003827762 size 0 bytes.
2020-01-11 17:59:50,339 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 76 INodes.
2020-01-11 17:59:50,371 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2020-01-11 17:59:50,371 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 579 from /orgz/snnfsi/current/fsimage_0000000000000000579
2020-01-11 17:59:50,371 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2020-01-11 17:59:50,375 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2020-01-11 17:59:50,378 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000580-0000000000000000638 expecting start txid #580
2020-01-11 17:59:50,378 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000580-0000000000000000638
2020-01-11 17:59:50,423 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000580-0000000000000000638 of size 1048576 edits # 59 loaded in 0 seconds
2020-01-11 17:59:50,423 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000639-0000000000000000640 expecting start txid #639
2020-01-11 17:59:50,424 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000639-0000000000000000640
2020-01-11 17:59:50,424 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000639-0000000000000000640 of size 42 edits # 2 loaded in 0 seconds
2020-01-11 17:59:50,429 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000640 using no compression
2020-01-11 17:59:50,502 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000640 of size 6541 bytes saved in 0 seconds.
2020-01-11 17:59:50,511 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 579
2020-01-11 17:59:50,511 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000515, cpktTxId=0000000000000000515)
2020-01-11 17:59:50,545 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 640 to namenode at http://um1:50070 in 0.024 seconds
2020-01-11 17:59:50,545 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 6541
2020-01-11 18:09:50,693 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-01-11 18:09:50,693 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=641&endTxId=741&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-11 18:09:50,700 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 4000.00 KB/s
2020-01-11 18:09:50,701 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000641-0000000000000000741_0000000000004428161 size 0 bytes.
2020-01-11 18:09:50,701 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-01-11 18:09:50,701 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000641-0000000000000000741 expecting start txid #641
2020-01-11 18:09:50,701 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000641-0000000000000000741
2020-01-11 18:09:50,742 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000641-0000000000000000741 of size 13120 edits # 101 loaded in 0 seconds
2020-01-11 18:09:50,743 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000741 using no compression
2020-01-11 18:09:50,757 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000741 of size 7615 bytes saved in 0 seconds.
2020-01-11 18:09:50,803 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 640
2020-01-11 18:09:50,803 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000579, cpktTxId=0000000000000000579)
2020-01-11 18:09:50,830 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 741 to namenode at http://um1:50070 in 0.016 seconds
2020-01-11 18:09:50,830 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 7615
2020-01-11 18:33:26,998 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.251.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2020-01-11 18:33:27,044 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-01-11 18:33:27,721 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-01-11 18:33:27,814 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-01-11 18:33:27,814 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2020-01-11 18:33:27,980 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2020-01-11 18:33:27,983 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2020-01-11 18:33:28,077 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 3024@um2
2020-01-11 18:33:28,135 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 3024@um2
2020-01-11 18:33:28,141 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2020-01-11 18:33:28,148 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2020-01-11 18:33:28,190 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2020-01-11 18:33:28,190 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2020-01-11 18:33:28,192 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-01-11 18:33:28,193 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2020 Jan 11 18:33:28
2020-01-11 18:33:28,195 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2020-01-11 18:33:28,195 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-01-11 18:33:28,196 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2020-01-11 18:33:28,196 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2020-01-11 18:33:28,207 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2020-01-11 18:33:28,207 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2020-01-11 18:33:28,207 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2020-01-11 18:33:28,207 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2020-01-11 18:33:28,207 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2020-01-11 18:33:28,207 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2020-01-11 18:33:28,207 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2020-01-11 18:33:28,207 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2020-01-11 18:33:28,208 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2020-01-11 18:33:28,208 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2020-01-11 18:33:28,209 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2020-01-11 18:33:28,209 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2020-01-11 18:33:28,210 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2020-01-11 18:33:28,617 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2020-01-11 18:33:28,617 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-01-11 18:33:28,618 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2020-01-11 18:33:28,618 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2020-01-11 18:33:28,639 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2020-01-11 18:33:28,649 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2020-01-11 18:33:28,649 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-01-11 18:33:28,649 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2020-01-11 18:33:28,649 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2020-01-11 18:33:28,651 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-01-11 18:33:28,651 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2020-01-11 18:33:28,662 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2020-01-11 18:33:28,663 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2020-01-11 18:33:28,664 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2020-01-11 18:33:28,664 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2020-01-11 18:33:28,673 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2020-01-11 18:33:28,726 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-01-11 18:33:28,730 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2020-01-11 18:33:28,746 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-01-11 18:33:28,747 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2020-01-11 18:33:28,749 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-01-11 18:33:28,749 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-01-11 18:33:28,877 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2020-01-11 18:33:28,877 INFO org.mortbay.log: jetty-6.1.26
2020-01-11 18:33:29,282 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2020-01-11 18:33:29,282 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2020-01-11 18:33:29,283 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2020-01-11 18:33:29,283 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2020-01-11 18:34:29,551 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2020-01-11 18:34:29,702 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=741&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-11 18:34:29,753 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2020-01-11 18:34:30,012 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 1000.00 KB/s
2020-01-11 18:34:30,014 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000741 size 7615 bytes.
2020-01-11 18:34:30,026 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=742&endTxId=977&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-11 18:34:30,065 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 31030.30 KB/s
2020-01-11 18:34:30,065 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000742-0000000000000000977_0000000000000977489 size 0 bytes.
2020-01-11 18:34:30,067 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=978&endTxId=979&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-11 18:34:30,078 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-01-11 18:34:30,078 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000978-0000000000000000979_0000000000000977534 size 0 bytes.
2020-01-11 18:34:30,170 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 99 INodes.
2020-01-11 18:34:30,230 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2020-01-11 18:34:30,230 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 741 from /orgz/snnfsi/current/fsimage_0000000000000000741
2020-01-11 18:34:30,230 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2020-01-11 18:34:30,235 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2020-01-11 18:34:30,240 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000742-0000000000000000977 expecting start txid #742
2020-01-11 18:34:30,240 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000742-0000000000000000977
2020-01-11 18:34:30,358 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000742-0000000000000000977 of size 1048576 edits # 236 loaded in 0 seconds
2020-01-11 18:34:30,358 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000978-0000000000000000979 expecting start txid #978
2020-01-11 18:34:30,358 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000978-0000000000000000979
2020-01-11 18:34:30,359 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000978-0000000000000000979 of size 42 edits # 2 loaded in 0 seconds
2020-01-11 18:34:30,364 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000979 using no compression
2020-01-11 18:34:30,449 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000979 of size 8492 bytes saved in 0 seconds.
2020-01-11 18:34:30,464 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 741
2020-01-11 18:34:30,464 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000640, cpktTxId=0000000000000000640)
2020-01-11 18:34:30,522 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 979 to namenode at http://um1:50070 in 0.043 seconds
2020-01-11 18:34:30,522 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 8492
2020-01-11 18:44:30,663 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-01-11 18:44:30,664 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=980&endTxId=1455&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-11 18:44:30,671 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 19666.67 KB/s
2020-01-11 18:44:30,671 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000980-0000000000000001455_0000000000001578132 size 0 bytes.
2020-01-11 18:44:30,672 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-01-11 18:44:30,672 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000980-0000000000000001455 expecting start txid #980
2020-01-11 18:44:30,672 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000980-0000000000000001455
2020-01-11 18:44:30,725 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000980-0000000000000001455 of size 61138 edits # 476 loaded in 0 seconds
2020-01-11 18:44:30,726 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001455 using no compression
2020-01-11 18:44:30,736 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001455 of size 11745 bytes saved in 0 seconds.
2020-01-11 18:44:30,739 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 979
2020-01-11 18:44:30,739 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000741, cpktTxId=0000000000000000741)
2020-01-11 18:44:30,774 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1455 to namenode at http://um1:50070 in 0.029 seconds
2020-01-11 18:44:30,774 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 11745
2020-01-11 18:54:30,911 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-01-11 18:54:30,912 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1456&endTxId=1801&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-11 18:54:30,917 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 20000.00 KB/s
2020-01-11 18:54:30,917 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001456-0000000000000001801_0000000000002178380 size 0 bytes.
2020-01-11 18:54:30,917 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-01-11 18:54:30,917 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000001456-0000000000000001801 expecting start txid #1456
2020-01-11 18:54:30,917 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000001456-0000000000000001801
2020-01-11 18:54:30,937 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000001456-0000000000000001801 of size 40975 edits # 346 loaded in 0 seconds
2020-01-11 18:54:30,938 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001801 using no compression
2020-01-11 18:54:30,956 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001801 of size 14878 bytes saved in 0 seconds.
2020-01-11 18:54:30,959 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1455
2020-01-11 18:54:30,959 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000979, cpktTxId=0000000000000000979)
2020-01-11 18:54:30,976 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1801 to namenode at http://um1:50070 in 0.012 seconds
2020-01-11 18:54:30,976 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 14878
2020-01-11 19:04:31,087 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-01-11 19:04:31,087 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1802&endTxId=1803&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-11 19:04:31,091 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-01-11 19:04:31,091 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001802-0000000000000001803_0000000000002778555 size 0 bytes.
2020-01-11 19:04:31,091 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-01-11 19:04:31,091 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000001802-0000000000000001803 expecting start txid #1802
2020-01-11 19:04:31,091 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000001802-0000000000000001803
2020-01-11 19:04:31,092 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000001802-0000000000000001803 of size 42 edits # 2 loaded in 0 seconds
2020-01-11 19:04:31,092 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001803 using no compression
2020-01-11 19:04:31,103 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001803 of size 14878 bytes saved in 0 seconds.
2020-01-11 19:04:31,106 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1801
2020-01-11 19:04:31,106 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000001455, cpktTxId=0000000000000001455)
2020-01-11 19:04:31,117 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1803 to namenode at http://um1:50070 in 0.009 seconds
2020-01-11 19:04:31,118 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 14878
2020-01-18 17:19:18,402 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.251.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2020-01-18 17:19:18,431 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-01-18 17:19:19,657 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-01-18 17:19:19,775 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-01-18 17:19:19,775 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2020-01-18 17:19:19,958 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2020-01-18 17:19:19,959 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2020-01-18 17:19:20,055 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 2951@um2
2020-01-18 17:19:20,135 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 2951@um2
2020-01-18 17:19:20,152 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2020-01-18 17:19:20,162 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2020-01-18 17:19:20,211 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2020-01-18 17:19:20,211 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2020-01-18 17:19:20,213 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-01-18 17:19:20,214 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2020 Jan 18 17:19:20
2020-01-18 17:19:20,216 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2020-01-18 17:19:20,216 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-01-18 17:19:20,217 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2020-01-18 17:19:20,217 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2020-01-18 17:19:20,229 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2020-01-18 17:19:20,229 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2020-01-18 17:19:20,229 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2020-01-18 17:19:20,229 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2020-01-18 17:19:20,229 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2020-01-18 17:19:20,229 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2020-01-18 17:19:20,229 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2020-01-18 17:19:20,229 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2020-01-18 17:19:20,230 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2020-01-18 17:19:20,230 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2020-01-18 17:19:20,230 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2020-01-18 17:19:20,230 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2020-01-18 17:19:20,233 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2020-01-18 17:19:20,622 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2020-01-18 17:19:20,622 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-01-18 17:19:20,622 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2020-01-18 17:19:20,622 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2020-01-18 17:19:20,632 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2020-01-18 17:19:20,647 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2020-01-18 17:19:20,647 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-01-18 17:19:20,647 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2020-01-18 17:19:20,647 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2020-01-18 17:19:20,650 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-01-18 17:19:20,650 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2020-01-18 17:19:20,650 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2020-01-18 17:19:20,657 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2020-01-18 17:19:20,657 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2020-01-18 17:19:20,658 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2020-01-18 17:19:20,669 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2020-01-18 17:19:20,726 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-01-18 17:19:20,729 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2020-01-18 17:19:20,744 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-01-18 17:19:20,747 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2020-01-18 17:19:20,748 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-01-18 17:19:20,748 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-01-18 17:19:20,832 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2020-01-18 17:19:20,832 INFO org.mortbay.log: jetty-6.1.26
2020-01-18 17:19:21,085 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2020-01-18 17:19:21,086 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2020-01-18 17:19:21,086 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2020-01-18 17:19:21,086 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2020-01-18 17:26:21,402 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2020-01-18 17:26:21,555 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=1804&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-18 17:26:21,624 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2020-01-18 17:26:21,881 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 1400.00 KB/s
2020-01-18 17:26:21,881 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001804 size 14878 bytes.
2020-01-18 17:26:21,904 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1805&endTxId=1808&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-18 17:26:21,915 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2020-01-18 17:26:21,915 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001805-0000000000000001808_0000000000000635915 size 0 bytes.
2020-01-18 17:26:21,967 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 185 INodes.
2020-01-18 17:26:22,042 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2020-01-18 17:26:22,042 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 1804 from /orgz/snnfsi/current/fsimage_0000000000000001804
2020-01-18 17:26:22,042 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 1 entries 13 lookups
2020-01-18 17:26:22,046 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-01-18 17:26:22,048 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000001805-0000000000000001808 expecting start txid #1805
2020-01-18 17:26:22,048 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000001805-0000000000000001808
2020-01-18 17:26:22,101 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000001805-0000000000000001808 of size 286 edits # 4 loaded in 0 seconds
2020-01-18 17:26:22,106 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001808 using no compression
2020-01-18 17:26:22,161 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001808 of size 15045 bytes saved in 0 seconds.
2020-01-18 17:26:22,175 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1804
2020-01-18 17:26:22,175 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000001801, cpktTxId=0000000000000001801)
2020-01-18 17:26:22,175 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000001803, cpktTxId=0000000000000001803)
2020-01-18 17:26:22,218 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1808 to namenode at http://um1:50070 in 0.032 seconds
2020-01-18 17:26:22,219 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 15045
2020-01-18 17:36:22,358 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-01-18 17:36:22,359 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1809&endTxId=1816&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-18 17:36:22,364 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-01-18 17:36:22,364 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001809-0000000000000001816_0000000000001236371 size 0 bytes.
2020-01-18 17:36:22,364 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-01-18 17:36:22,364 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000001809-0000000000000001816 expecting start txid #1809
2020-01-18 17:36:22,364 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000001809-0000000000000001816
2020-01-18 17:36:22,370 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000001809-0000000000000001816 of size 728 edits # 8 loaded in 0 seconds
2020-01-18 17:36:22,371 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001816 using no compression
2020-01-18 17:36:22,383 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001816 of size 15045 bytes saved in 0 seconds.
2020-01-18 17:36:22,387 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1808
2020-01-18 17:36:22,387 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000001804, cpktTxId=0000000000000001804)
2020-01-18 17:36:22,410 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1816 to namenode at http://um1:50070 in 0.014 seconds
2020-01-18 17:36:22,410 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 15045
2020-01-18 17:46:22,509 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-01-18 17:46:22,509 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1817&endTxId=1818&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-18 17:46:22,517 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-01-18 17:46:22,517 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001817-0000000000000001818_0000000000001836521 size 0 bytes.
2020-01-18 17:46:22,518 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-01-18 17:46:22,518 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000001817-0000000000000001818 expecting start txid #1817
2020-01-18 17:46:22,518 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000001817-0000000000000001818
2020-01-18 17:46:22,519 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000001817-0000000000000001818 of size 42 edits # 2 loaded in 0 seconds
2020-01-18 17:46:22,520 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001818 using no compression
2020-01-18 17:46:22,529 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001818 of size 15045 bytes saved in 0 seconds.
2020-01-18 17:46:22,532 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1816
2020-01-18 17:46:22,533 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000001808, cpktTxId=0000000000000001808)
2020-01-18 17:46:22,553 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1818 to namenode at http://um1:50070 in 0.013 seconds
2020-01-18 17:46:22,553 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 15045
2020-01-18 17:56:22,653 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-01-18 17:56:22,653 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1819&endTxId=1820&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-18 17:56:22,659 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-01-18 17:56:22,659 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001819-0000000000000001820_0000000000002436665 size 0 bytes.
2020-01-18 17:56:22,659 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-01-18 17:56:22,659 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000001819-0000000000000001820 expecting start txid #1819
2020-01-18 17:56:22,659 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000001819-0000000000000001820
2020-01-18 17:56:22,660 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000001819-0000000000000001820 of size 42 edits # 2 loaded in 0 seconds
2020-01-18 17:56:22,661 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001820 using no compression
2020-01-18 17:56:22,673 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001820 of size 15045 bytes saved in 0 seconds.
2020-01-18 17:56:22,676 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1818
2020-01-18 17:56:22,676 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000001816, cpktTxId=0000000000000001816)
2020-01-18 17:56:22,704 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1820 to namenode at http://um1:50070 in 0.024 seconds
2020-01-18 17:56:22,704 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 15045
2020-01-18 18:06:22,894 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-01-18 18:06:22,895 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1821&endTxId=1822&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-18 18:06:22,902 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-01-18 18:06:22,902 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001821-0000000000000001822_0000000000003036907 size 0 bytes.
2020-01-18 18:06:22,903 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-01-18 18:06:22,903 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000001821-0000000000000001822 expecting start txid #1821
2020-01-18 18:06:22,903 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000001821-0000000000000001822
2020-01-18 18:06:22,903 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000001821-0000000000000001822 of size 42 edits # 2 loaded in 0 seconds
2020-01-18 18:06:22,904 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001822 using no compression
2020-01-18 18:06:22,910 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001822 of size 15045 bytes saved in 0 seconds.
2020-01-18 18:06:22,914 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1820
2020-01-18 18:06:22,914 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000001818, cpktTxId=0000000000000001818)
2020-01-18 18:06:22,940 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1822 to namenode at http://um1:50070 in 0.014 seconds
2020-01-18 18:06:22,941 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 15045
2020-01-18 18:16:23,044 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-01-18 18:16:23,044 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1823&endTxId=1824&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-18 18:16:23,049 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-01-18 18:16:23,049 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001823-0000000000000001824_0000000000003637056 size 0 bytes.
2020-01-18 18:16:23,049 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-01-18 18:16:23,049 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000001823-0000000000000001824 expecting start txid #1823
2020-01-18 18:16:23,049 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000001823-0000000000000001824
2020-01-18 18:16:23,049 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000001823-0000000000000001824 of size 42 edits # 2 loaded in 0 seconds
2020-01-18 18:16:23,053 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001824 using no compression
2020-01-18 18:16:23,061 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001824 of size 15045 bytes saved in 0 seconds.
2020-01-18 18:16:23,067 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1822
2020-01-18 18:16:23,068 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000001820, cpktTxId=0000000000000001820)
2020-01-18 18:16:23,085 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1824 to namenode at http://um1:50070 in 0.013 seconds
2020-01-18 18:16:23,086 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 15045
2020-01-18 18:26:23,329 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-01-18 18:26:23,329 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1825&endTxId=1826&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-18 18:26:23,334 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-01-18 18:26:23,334 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001825-0000000000000001826_0000000000004237341 size 0 bytes.
2020-01-18 18:26:23,335 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-01-18 18:26:23,335 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000001825-0000000000000001826 expecting start txid #1825
2020-01-18 18:26:23,335 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000001825-0000000000000001826
2020-01-18 18:26:23,335 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000001825-0000000000000001826 of size 42 edits # 2 loaded in 0 seconds
2020-01-18 18:26:23,336 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001826 using no compression
2020-01-18 18:26:23,348 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001826 of size 15045 bytes saved in 0 seconds.
2020-01-18 18:26:23,351 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1824
2020-01-18 18:26:23,351 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000001822, cpktTxId=0000000000000001822)
2020-01-18 18:26:23,364 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1826 to namenode at http://um1:50070 in 0.009 seconds
2020-01-18 18:26:23,364 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 15045
2020-01-18 18:36:23,469 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-01-18 18:36:23,469 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1827&endTxId=1828&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-18 18:36:23,476 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-01-18 18:36:23,476 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001827-0000000000000001828_0000000000004837481 size 0 bytes.
2020-01-18 18:36:23,476 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-01-18 18:36:23,476 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000001827-0000000000000001828 expecting start txid #1827
2020-01-18 18:36:23,476 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000001827-0000000000000001828
2020-01-18 18:36:23,477 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000001827-0000000000000001828 of size 42 edits # 2 loaded in 0 seconds
2020-01-18 18:36:23,477 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001828 using no compression
2020-01-18 18:36:23,489 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001828 of size 15045 bytes saved in 0 seconds.
2020-01-18 18:36:23,491 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1826
2020-01-18 18:36:23,491 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000001824, cpktTxId=0000000000000001824)
2020-01-18 18:36:23,505 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1828 to namenode at http://um1:50070 in 0.01 seconds
2020-01-18 18:36:23,506 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 15045
2020-01-24 16:13:22,513 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.251.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2020-01-24 16:13:22,558 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-01-24 16:13:23,693 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-01-24 16:13:23,824 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-01-24 16:13:23,824 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2020-01-24 16:13:24,072 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2020-01-24 16:13:24,073 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2020-01-24 16:13:24,318 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 2896@um2
2020-01-24 16:13:24,401 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 2896@um2
2020-01-24 16:13:24,417 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2020-01-24 16:13:24,432 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2020-01-24 16:13:24,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2020-01-24 16:13:24,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2020-01-24 16:13:24,488 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-01-24 16:13:24,491 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2020 Jan 24 16:13:24
2020-01-24 16:13:24,494 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2020-01-24 16:13:24,494 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-01-24 16:13:24,496 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2020-01-24 16:13:24,496 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2020-01-24 16:13:24,510 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2020-01-24 16:13:24,510 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2020-01-24 16:13:24,510 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2020-01-24 16:13:24,510 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2020-01-24 16:13:24,510 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2020-01-24 16:13:24,511 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2020-01-24 16:13:24,511 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2020-01-24 16:13:24,511 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2020-01-24 16:13:24,512 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2020-01-24 16:13:24,512 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2020-01-24 16:13:24,512 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2020-01-24 16:13:24,512 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2020-01-24 16:13:24,515 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2020-01-24 16:13:25,001 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2020-01-24 16:13:25,002 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-01-24 16:13:25,002 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2020-01-24 16:13:25,002 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2020-01-24 16:13:25,025 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2020-01-24 16:13:25,058 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2020-01-24 16:13:25,078 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-01-24 16:13:25,079 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2020-01-24 16:13:25,079 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2020-01-24 16:13:25,087 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-01-24 16:13:25,087 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2020-01-24 16:13:25,088 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2020-01-24 16:13:25,094 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2020-01-24 16:13:25,094 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2020-01-24 16:13:25,094 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2020-01-24 16:13:25,117 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2020-01-24 16:13:25,204 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-01-24 16:13:25,209 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2020-01-24 16:13:25,221 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-01-24 16:13:25,224 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2020-01-24 16:13:25,224 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-01-24 16:13:25,224 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-01-24 16:13:25,342 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2020-01-24 16:13:25,342 INFO org.mortbay.log: jetty-6.1.26
2020-01-24 16:13:25,673 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2020-01-24 16:13:25,673 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2020-01-24 16:13:25,673 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2020-01-24 16:13:25,673 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2020-01-24 16:22:26,125 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2020-01-24 16:22:26,267 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=1829&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-24 16:22:26,309 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2020-01-24 16:22:26,583 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 1272.73 KB/s
2020-01-24 16:22:26,585 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001829 size 15045 bytes.
2020-01-24 16:22:26,600 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1830&endTxId=1831&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-24 16:22:26,606 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-01-24 16:22:26,606 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001830-0000000000000001831_0000000000000653110 size 0 bytes.
2020-01-24 16:22:26,643 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 187 INodes.
2020-01-24 16:22:26,674 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2020-01-24 16:22:26,674 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 1829 from /orgz/snnfsi/current/fsimage_0000000000000001829
2020-01-24 16:22:26,674 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 1 entries 13 lookups
2020-01-24 16:22:26,677 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-01-24 16:22:26,680 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000001830-0000000000000001831 expecting start txid #1830
2020-01-24 16:22:26,680 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000001830-0000000000000001831
2020-01-24 16:22:26,692 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000001830-0000000000000001831 of size 42 edits # 2 loaded in 0 seconds
2020-01-24 16:22:26,698 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001831 using no compression
2020-01-24 16:22:26,756 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001831 of size 15045 bytes saved in 0 seconds.
2020-01-24 16:22:26,768 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1829
2020-01-24 16:22:26,768 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000001828, cpktTxId=0000000000000001828)
2020-01-24 16:22:26,769 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000001826, cpktTxId=0000000000000001826)
2020-01-24 16:22:26,824 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1831 to namenode at http://um1:50070 in 0.042 seconds
2020-01-24 16:22:26,824 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 15045
2020-01-24 16:32:26,971 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-01-24 16:32:26,972 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1832&endTxId=1885&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-24 16:32:26,980 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 2000.00 KB/s
2020-01-24 16:32:26,980 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001832-0000000000000001885_0000000000001253482 size 0 bytes.
2020-01-24 16:32:26,981 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-01-24 16:32:26,981 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000001832-0000000000000001885 expecting start txid #1832
2020-01-24 16:32:26,981 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000001832-0000000000000001885
2020-01-24 16:32:27,027 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000001832-0000000000000001885 of size 8417 edits # 54 loaded in 0 seconds
2020-01-24 16:32:27,029 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001885 using no compression
2020-01-24 16:32:27,043 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001885 of size 15443 bytes saved in 0 seconds.
2020-01-24 16:32:27,046 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1831
2020-01-24 16:32:27,046 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000001829, cpktTxId=0000000000000001829)
2020-01-24 16:32:27,067 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1885 to namenode at http://um1:50070 in 0.015 seconds
2020-01-24 16:32:27,067 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 15443
2020-01-24 16:42:27,257 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-01-24 16:42:27,257 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1886&endTxId=1888&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-24 16:42:27,262 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-01-24 16:42:27,262 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001886-0000000000000001888_0000000000001853767 size 0 bytes.
2020-01-24 16:42:27,262 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-01-24 16:42:27,262 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000001886-0000000000000001888 expecting start txid #1886
2020-01-24 16:42:27,262 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000001886-0000000000000001888
2020-01-24 16:42:27,262 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000001886-0000000000000001888 of size 141 edits # 3 loaded in 0 seconds
2020-01-24 16:42:27,265 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001888 using no compression
2020-01-24 16:42:27,276 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001888 of size 15283 bytes saved in 0 seconds.
2020-01-24 16:42:27,279 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1885
2020-01-24 16:42:27,279 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000001831, cpktTxId=0000000000000001831)
2020-01-24 16:42:27,303 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1888 to namenode at http://um1:50070 in 0.02 seconds
2020-01-24 16:42:27,304 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 15283
2020-01-24 16:52:27,535 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-01-24 16:52:27,536 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1889&endTxId=1890&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-24 16:52:27,541 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-01-24 16:52:27,541 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001889-0000000000000001890_0000000000002454046 size 0 bytes.
2020-01-24 16:52:27,541 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-01-24 16:52:27,541 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000001889-0000000000000001890 expecting start txid #1889
2020-01-24 16:52:27,541 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000001889-0000000000000001890
2020-01-24 16:52:27,542 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000001889-0000000000000001890 of size 42 edits # 2 loaded in 0 seconds
2020-01-24 16:52:27,543 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001890 using no compression
2020-01-24 16:52:27,558 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001890 of size 15283 bytes saved in 0 seconds.
2020-01-24 16:52:27,560 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1888
2020-01-24 16:52:27,560 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000001885, cpktTxId=0000000000000001885)
2020-01-24 16:52:27,573 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1890 to namenode at http://um1:50070 in 0.008 seconds
2020-01-24 16:52:27,574 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 15283
2020-01-24 17:02:27,736 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-01-24 17:02:27,736 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1891&endTxId=1892&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-01-24 17:02:27,741 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-01-24 17:02:27,741 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001891-0000000000000001892_0000000000003054247 size 0 bytes.
2020-01-24 17:02:27,741 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-01-24 17:02:27,741 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000001891-0000000000000001892 expecting start txid #1891
2020-01-24 17:02:27,741 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000001891-0000000000000001892
2020-01-24 17:02:27,741 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000001891-0000000000000001892 of size 42 edits # 2 loaded in 0 seconds
2020-01-24 17:02:27,742 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001892 using no compression
2020-01-24 17:02:27,753 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001892 of size 15283 bytes saved in 0 seconds.
2020-01-24 17:02:27,757 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1890
2020-01-24 17:02:27,757 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000001888, cpktTxId=0000000000000001888)
2020-01-24 17:02:27,770 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1892 to namenode at http://um1:50070 in 0.009 seconds
2020-01-24 17:02:27,770 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 15283
2020-02-02 16:37:33,514 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.251.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2020-02-02 16:37:33,541 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-02-02 16:37:36,059 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-02-02 16:37:36,469 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-02-02 16:37:36,469 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2020-02-02 16:37:37,432 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2020-02-02 16:37:37,433 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2020-02-02 16:37:37,965 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 2886@um2
2020-02-02 16:37:38,188 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 2886@um2
2020-02-02 16:37:38,216 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2020-02-02 16:37:38,254 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2020-02-02 16:37:38,565 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2020-02-02 16:37:38,566 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2020-02-02 16:37:38,569 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-02-02 16:37:38,574 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2020 Feb 02 16:37:38
2020-02-02 16:37:38,577 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2020-02-02 16:37:38,578 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-02-02 16:37:38,580 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2020-02-02 16:37:38,581 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2020-02-02 16:37:38,620 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2020-02-02 16:37:38,621 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2020-02-02 16:37:38,621 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2020-02-02 16:37:38,621 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2020-02-02 16:37:38,622 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2020-02-02 16:37:38,622 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2020-02-02 16:37:38,622 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2020-02-02 16:37:38,623 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2020-02-02 16:37:38,624 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2020-02-02 16:37:38,625 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2020-02-02 16:37:38,633 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2020-02-02 16:37:38,633 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2020-02-02 16:37:38,645 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2020-02-02 16:37:40,834 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2020-02-02 16:37:40,835 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-02-02 16:37:40,836 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2020-02-02 16:37:40,836 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2020-02-02 16:37:40,933 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2020-02-02 16:37:41,007 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2020-02-02 16:37:41,007 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-02-02 16:37:41,008 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2020-02-02 16:37:41,008 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2020-02-02 16:37:41,056 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-02-02 16:37:41,059 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2020-02-02 16:37:41,059 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2020-02-02 16:37:41,075 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2020-02-02 16:37:41,075 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2020-02-02 16:37:41,075 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2020-02-02 16:37:41,127 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2020-02-02 16:37:41,671 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-02-02 16:37:41,785 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2020-02-02 16:37:41,828 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-02-02 16:37:41,833 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2020-02-02 16:37:41,835 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-02-02 16:37:41,835 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-02-02 16:37:42,090 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2020-02-02 16:37:42,091 INFO org.mortbay.log: jetty-6.1.26
2020-02-02 16:37:42,589 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2020-02-02 16:37:42,590 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2020-02-02 16:37:42,590 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2020-02-02 16:37:42,590 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2020-02-02 16:45:43,202 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2020-02-02 16:45:43,412 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=1893&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-02-02 16:45:43,453 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2020-02-02 16:45:43,631 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 1400.00 KB/s
2020-02-02 16:45:43,633 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001893 size 15283 bytes.
2020-02-02 16:45:43,642 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1894&endTxId=1895&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-02-02 16:45:43,646 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-02 16:45:43,646 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001894-0000000000000001895_0000000000000657505 size 0 bytes.
2020-02-02 16:45:43,694 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 190 INodes.
2020-02-02 16:45:43,746 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2020-02-02 16:45:43,746 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 1893 from /orgz/snnfsi/current/fsimage_0000000000000001893
2020-02-02 16:45:43,746 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 1 entries 14 lookups
2020-02-02 16:45:43,753 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-02 16:45:43,755 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000001894-0000000000000001895 expecting start txid #1894
2020-02-02 16:45:43,756 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000001894-0000000000000001895
2020-02-02 16:45:43,770 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000001894-0000000000000001895 of size 42 edits # 2 loaded in 0 seconds
2020-02-02 16:45:43,784 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001895 using no compression
2020-02-02 16:45:43,836 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001895 of size 15283 bytes saved in 0 seconds.
2020-02-02 16:45:43,849 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1893
2020-02-02 16:45:43,849 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000001892, cpktTxId=0000000000000001892)
2020-02-02 16:45:43,849 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000001890, cpktTxId=0000000000000001890)
2020-02-02 16:45:43,888 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1895 to namenode at http://um1:50070 in 0.027 seconds
2020-02-02 16:45:43,888 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 15283
2020-02-02 16:55:44,042 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-02 16:55:44,043 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1896&endTxId=1897&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-02-02 16:55:44,050 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-02 16:55:44,050 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001896-0000000000000001897_0000000000001257905 size 0 bytes.
2020-02-02 16:55:44,051 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-02 16:55:44,051 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000001896-0000000000000001897 expecting start txid #1896
2020-02-02 16:55:44,053 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000001896-0000000000000001897
2020-02-02 16:55:44,053 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000001896-0000000000000001897 of size 42 edits # 2 loaded in 0 seconds
2020-02-02 16:55:44,058 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001897 using no compression
2020-02-02 16:55:44,071 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001897 of size 15283 bytes saved in 0 seconds.
2020-02-02 16:55:44,074 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1895
2020-02-02 16:55:44,074 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000001893, cpktTxId=0000000000000001893)
2020-02-02 16:55:44,101 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1897 to namenode at http://um1:50070 in 0.011 seconds
2020-02-02 16:55:44,102 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 15283
2020-02-02 17:05:44,226 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-02 17:05:44,227 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1898&endTxId=1899&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-02-02 17:05:44,232 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-02 17:05:44,232 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001898-0000000000000001899_0000000000001858090 size 0 bytes.
2020-02-02 17:05:44,233 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-02 17:05:44,233 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000001898-0000000000000001899 expecting start txid #1898
2020-02-02 17:05:44,233 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000001898-0000000000000001899
2020-02-02 17:05:44,233 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000001898-0000000000000001899 of size 42 edits # 2 loaded in 0 seconds
2020-02-02 17:05:44,234 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001899 using no compression
2020-02-02 17:05:44,247 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001899 of size 15283 bytes saved in 0 seconds.
2020-02-02 17:05:44,251 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1897
2020-02-02 17:05:44,251 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000001895, cpktTxId=0000000000000001895)
2020-02-02 17:05:44,265 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1899 to namenode at http://um1:50070 in 0.009 seconds
2020-02-02 17:05:44,265 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 15283
2020-02-02 17:15:44,480 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-02 17:15:44,480 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1900&endTxId=1901&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-02-02 17:15:44,484 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-02 17:15:44,485 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001900-0000000000000001901_0000000000002458343 size 0 bytes.
2020-02-02 17:15:44,489 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-02 17:15:44,489 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000001900-0000000000000001901 expecting start txid #1900
2020-02-02 17:15:44,489 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000001900-0000000000000001901
2020-02-02 17:15:44,489 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000001900-0000000000000001901 of size 42 edits # 2 loaded in 0 seconds
2020-02-02 17:15:44,492 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001901 using no compression
2020-02-02 17:15:44,505 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001901 of size 15283 bytes saved in 0 seconds.
2020-02-02 17:15:44,508 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1899
2020-02-02 17:15:44,508 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000001897, cpktTxId=0000000000000001897)
2020-02-02 17:15:44,537 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1901 to namenode at http://um1:50070 in 0.023 seconds
2020-02-02 17:15:44,537 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 15283
2020-02-02 17:25:44,668 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-02 17:25:44,669 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1902&endTxId=1903&storageInfo=-60:1121220742:0:CID-d40beff8-3514-4fb0-91dd-06918f0ab065
2020-02-02 17:25:44,676 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-02 17:25:44,676 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001902-0000000000000001903_0000000000003058532 size 0 bytes.
2020-02-02 17:25:44,676 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-02 17:25:44,676 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000001902-0000000000000001903 expecting start txid #1902
2020-02-02 17:25:44,677 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000001902-0000000000000001903
2020-02-02 17:25:44,677 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000001902-0000000000000001903 of size 42 edits # 2 loaded in 0 seconds
2020-02-02 17:25:44,680 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001903 using no compression
2020-02-02 17:25:44,697 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000001903 of size 15283 bytes saved in 0 seconds.
2020-02-02 17:25:44,700 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1901
2020-02-02 17:25:44,700 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000001899, cpktTxId=0000000000000001899)
2020-02-02 17:25:44,723 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1903 to namenode at http://um1:50070 in 0.018 seconds
2020-02-02 17:25:44,723 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 15283
2020-02-02 17:35:12,329 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2020-02-02 17:35:12,331 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at um2/192.168.251.4
************************************************************/
2020-02-02 17:40:12,541 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.251.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2020-02-02 17:40:12,562 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-02-02 17:40:13,401 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-02-02 17:40:13,500 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-02-02 17:40:13,500 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2020-02-02 17:40:13,633 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2020-02-02 17:40:13,634 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2020-02-02 17:40:13,688 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 21801@um2
2020-02-02 17:40:13,690 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 21801@um2
2020-02-02 17:40:13,692 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2020-02-02 17:40:13,698 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2020-02-02 17:40:13,731 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2020-02-02 17:40:13,731 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2020-02-02 17:40:13,732 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-02-02 17:40:13,734 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2020 Feb 02 17:40:13
2020-02-02 17:40:13,735 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2020-02-02 17:40:13,735 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-02-02 17:40:13,736 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2020-02-02 17:40:13,736 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2020-02-02 17:40:13,745 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2020-02-02 17:40:13,746 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2020-02-02 17:40:13,746 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2020-02-02 17:40:13,746 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2020-02-02 17:40:13,746 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2020-02-02 17:40:13,746 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2020-02-02 17:40:13,746 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2020-02-02 17:40:13,746 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2020-02-02 17:40:13,746 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2020-02-02 17:40:13,747 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2020-02-02 17:40:13,747 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2020-02-02 17:40:13,747 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2020-02-02 17:40:13,748 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2020-02-02 17:40:14,021 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2020-02-02 17:40:14,021 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-02-02 17:40:14,021 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2020-02-02 17:40:14,021 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2020-02-02 17:40:14,023 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2020-02-02 17:40:14,029 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2020-02-02 17:40:14,029 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-02-02 17:40:14,029 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2020-02-02 17:40:14,029 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2020-02-02 17:40:14,031 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-02-02 17:40:14,031 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2020-02-02 17:40:14,031 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2020-02-02 17:40:14,033 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2020-02-02 17:40:14,033 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2020-02-02 17:40:14,033 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2020-02-02 17:40:14,042 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2020-02-02 17:40:14,080 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-02-02 17:40:14,083 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2020-02-02 17:40:14,092 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-02-02 17:40:14,094 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2020-02-02 17:40:14,094 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-02-02 17:40:14,094 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-02-02 17:40:14,111 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2020-02-02 17:40:14,111 INFO org.mortbay.log: jetty-6.1.26
2020-02-02 17:40:14,317 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2020-02-02 17:40:14,318 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2020-02-02 17:40:14,318 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2020-02-02 17:40:14,318 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2020-02-02 17:41:14,535 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2020-02-02 17:41:14,658 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=0&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-02 17:41:14,698 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2020-02-02 17:41:14,926 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 0.00 KB/s
2020-02-02 17:41:14,926 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 320 bytes.
2020-02-02 17:41:14,932 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=1&endTxId=2&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-02 17:41:14,938 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-02 17:41:14,938 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000002_0000000000003988794 size 0 bytes.
2020-02-02 17:41:14,974 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2020-02-02 17:41:14,993 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2020-02-02 17:41:14,993 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /orgz/snnfsi/current/fsimage_0000000000000000000
2020-02-02 17:41:14,993 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2020-02-02 17:41:14,999 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-02 17:41:15,003 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000001-0000000000000000002 expecting start txid #1
2020-02-02 17:41:15,003 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000001-0000000000000000002
2020-02-02 17:41:15,044 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000001-0000000000000000002 of size 42 edits # 2 loaded in 0 seconds
2020-02-02 17:41:15,052 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000002 using no compression
2020-02-02 17:41:15,103 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000002 of size 320 bytes saved in 0 seconds.
2020-02-02 17:41:15,106 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /orgz/snnfsi
2020-02-02 17:41:15,106 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /orgz/snnedits
2020-02-02 17:41:15,153 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2 to namenode at http://um1:50070 in 0.039 seconds
2020-02-02 17:41:15,153 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 320
2020-02-02 17:51:15,302 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-02 17:51:15,302 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=3&endTxId=6&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-02 17:51:15,308 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-02 17:51:15,308 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000003-0000000000000000006_0000000000004589165 size 0 bytes.
2020-02-02 17:51:15,308 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-02 17:51:15,308 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000003-0000000000000000006 expecting start txid #3
2020-02-02 17:51:15,309 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000003-0000000000000000006
2020-02-02 17:51:15,323 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000003-0000000000000000006 of size 187 edits # 4 loaded in 0 seconds
2020-02-02 17:51:15,324 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000006 using no compression
2020-02-02 17:51:15,331 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000006 of size 457 bytes saved in 0 seconds.
2020-02-02 17:51:15,345 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2
2020-02-02 17:51:15,345 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-02-02 17:51:15,364 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 6 to namenode at http://um1:50070 in 0.015 seconds
2020-02-02 17:51:15,364 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 457
2020-02-02 18:01:15,481 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-02 18:01:15,481 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=7&endTxId=14&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-02 18:01:15,487 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-02 18:01:15,487 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000007-0000000000000000014_0000000000005189344 size 0 bytes.
2020-02-02 18:01:15,487 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-02 18:01:15,487 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000007-0000000000000000014 expecting start txid #7
2020-02-02 18:01:15,488 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000007-0000000000000000014
2020-02-02 18:01:15,500 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000007-0000000000000000014 of size 568 edits # 8 loaded in 0 seconds
2020-02-02 18:01:15,505 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000014 using no compression
2020-02-02 18:01:15,511 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000014 of size 535 bytes saved in 0 seconds.
2020-02-02 18:01:15,514 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 6
2020-02-02 18:01:15,514 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000002, cpktTxId=0000000000000000002)
2020-02-02 18:01:15,528 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 14 to namenode at http://um1:50070 in 0.011 seconds
2020-02-02 18:01:15,528 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 535
2020-02-02 18:11:15,630 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-02 18:11:15,630 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=15&endTxId=16&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-02 18:11:15,635 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-02 18:11:15,635 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000015-0000000000000000016_0000000000005789493 size 0 bytes.
2020-02-02 18:11:15,636 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-02 18:11:15,636 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000015-0000000000000000016 expecting start txid #15
2020-02-02 18:11:15,636 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000015-0000000000000000016
2020-02-02 18:11:15,636 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000015-0000000000000000016 of size 42 edits # 2 loaded in 0 seconds
2020-02-02 18:11:15,637 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000016 using no compression
2020-02-02 18:11:15,639 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000016 of size 535 bytes saved in 0 seconds.
2020-02-02 18:11:15,642 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 14
2020-02-02 18:11:15,642 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000006, cpktTxId=0000000000000000006)
2020-02-02 18:11:15,662 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 16 to namenode at http://um1:50070 in 0.014 seconds
2020-02-02 18:11:15,662 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 535
2020-02-02 18:21:15,803 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-02 18:21:15,803 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=17&endTxId=18&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-02 18:21:15,808 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-02 18:21:15,808 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000017-0000000000000000018_0000000000006389666 size 0 bytes.
2020-02-02 18:21:15,808 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-02 18:21:15,808 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000017-0000000000000000018 expecting start txid #17
2020-02-02 18:21:15,809 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000017-0000000000000000018
2020-02-02 18:21:15,809 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000017-0000000000000000018 of size 42 edits # 2 loaded in 0 seconds
2020-02-02 18:21:15,812 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000018 using no compression
2020-02-02 18:21:15,817 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000018 of size 535 bytes saved in 0 seconds.
2020-02-02 18:21:15,823 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 16
2020-02-02 18:21:15,823 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000014, cpktTxId=0000000000000000014)
2020-02-02 18:21:15,838 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 18 to namenode at http://um1:50070 in 0.012 seconds
2020-02-02 18:21:15,838 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 535
2020-02-02 18:31:15,978 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-02 18:31:15,979 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=19&endTxId=20&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-02 18:31:15,985 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-02 18:31:15,985 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000019-0000000000000000020_0000000000006989842 size 0 bytes.
2020-02-02 18:31:15,986 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-02 18:31:15,986 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000019-0000000000000000020 expecting start txid #19
2020-02-02 18:31:15,986 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000019-0000000000000000020
2020-02-02 18:31:15,986 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000019-0000000000000000020 of size 42 edits # 2 loaded in 0 seconds
2020-02-02 18:31:15,987 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000020 using no compression
2020-02-02 18:31:15,989 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000020 of size 535 bytes saved in 0 seconds.
2020-02-02 18:31:15,991 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 18
2020-02-02 18:31:15,991 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000016, cpktTxId=0000000000000000016)
2020-02-02 18:31:16,003 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 20 to namenode at http://um1:50070 in 0.009 seconds
2020-02-02 18:31:16,003 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 535
2020-02-02 18:41:16,178 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-02 18:41:16,178 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=21&endTxId=22&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-02 18:41:16,183 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-02 18:41:16,183 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000021-0000000000000000022_0000000000007590041 size 0 bytes.
2020-02-02 18:41:16,183 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-02 18:41:16,183 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000021-0000000000000000022 expecting start txid #21
2020-02-02 18:41:16,183 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000021-0000000000000000022
2020-02-02 18:41:16,183 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000021-0000000000000000022 of size 42 edits # 2 loaded in 0 seconds
2020-02-02 18:41:16,184 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000022 using no compression
2020-02-02 18:41:16,186 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000022 of size 535 bytes saved in 0 seconds.
2020-02-02 18:41:16,188 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 20
2020-02-02 18:41:16,189 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000018, cpktTxId=0000000000000000018)
2020-02-02 18:41:16,200 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 22 to namenode at http://um1:50070 in 0.008 seconds
2020-02-02 18:41:16,200 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 535
2020-02-02 18:51:16,348 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-02 18:51:16,348 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=23&endTxId=24&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-02 18:51:16,353 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-02 18:51:16,353 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000023-0000000000000000024_0000000000008190211 size 0 bytes.
2020-02-02 18:51:16,353 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-02 18:51:16,353 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000023-0000000000000000024 expecting start txid #23
2020-02-02 18:51:16,353 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000023-0000000000000000024
2020-02-02 18:51:16,354 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000023-0000000000000000024 of size 42 edits # 2 loaded in 0 seconds
2020-02-02 18:51:16,357 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000024 using no compression
2020-02-02 18:51:16,360 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000024 of size 535 bytes saved in 0 seconds.
2020-02-02 18:51:16,363 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 22
2020-02-02 18:51:16,363 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000020, cpktTxId=0000000000000000020)
2020-02-02 18:51:16,373 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 24 to namenode at http://um1:50070 in 0.007 seconds
2020-02-02 18:51:16,374 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 535
2020-02-02 19:01:16,551 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-02 19:01:16,551 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=25&endTxId=26&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-02 19:01:16,556 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-02 19:01:16,556 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000025-0000000000000000026_0000000000008790414 size 0 bytes.
2020-02-02 19:01:16,556 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-02 19:01:16,556 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000025-0000000000000000026 expecting start txid #25
2020-02-02 19:01:16,556 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000025-0000000000000000026
2020-02-02 19:01:16,556 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000025-0000000000000000026 of size 42 edits # 2 loaded in 0 seconds
2020-02-02 19:01:16,557 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000026 using no compression
2020-02-02 19:01:16,559 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000026 of size 535 bytes saved in 0 seconds.
2020-02-02 19:01:16,561 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 24
2020-02-02 19:01:16,561 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000022, cpktTxId=0000000000000000022)
2020-02-02 19:01:16,582 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 26 to namenode at http://um1:50070 in 0.019 seconds
2020-02-02 19:01:16,582 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 535
2020-02-02 19:11:16,752 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-02 19:11:16,753 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=27&endTxId=28&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-02 19:11:16,760 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-02 19:11:16,760 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000027-0000000000000000028_0000000000009390615 size 0 bytes.
2020-02-02 19:11:16,760 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-02 19:11:16,760 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000027-0000000000000000028 expecting start txid #27
2020-02-02 19:11:16,760 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000027-0000000000000000028
2020-02-02 19:11:16,761 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000027-0000000000000000028 of size 42 edits # 2 loaded in 0 seconds
2020-02-02 19:11:16,761 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000028 using no compression
2020-02-02 19:11:16,763 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000028 of size 535 bytes saved in 0 seconds.
2020-02-02 19:11:16,766 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 26
2020-02-02 19:11:16,767 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000024, cpktTxId=0000000000000000024)
2020-02-02 19:11:16,779 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 28 to namenode at http://um1:50070 in 0.01 seconds
2020-02-02 19:11:16,780 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 535
2020-02-02 19:21:16,916 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-02 19:21:16,916 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=29&endTxId=30&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-02 19:21:16,921 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-02 19:21:16,922 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000029-0000000000000000030_0000000000009990779 size 0 bytes.
2020-02-02 19:21:16,922 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-02 19:21:16,922 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000029-0000000000000000030 expecting start txid #29
2020-02-02 19:21:16,922 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000029-0000000000000000030
2020-02-02 19:21:16,923 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000029-0000000000000000030 of size 42 edits # 2 loaded in 0 seconds
2020-02-02 19:21:16,923 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000030 using no compression
2020-02-02 19:21:16,925 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000030 of size 535 bytes saved in 0 seconds.
2020-02-02 19:21:16,929 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 28
2020-02-02 19:21:16,929 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000026, cpktTxId=0000000000000000026)
2020-02-02 19:21:16,941 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 30 to namenode at http://um1:50070 in 0.007 seconds
2020-02-02 19:21:16,941 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 535
2020-02-02 20:56:28,517 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-02 20:56:28,518 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=31&endTxId=32&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-02 20:56:28,528 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-02 20:56:28,528 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000031-0000000000000000032_0000000000010591165 size 0 bytes.
2020-02-02 20:56:28,528 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-02 20:56:28,528 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000031-0000000000000000032 expecting start txid #31
2020-02-02 20:56:28,528 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000031-0000000000000000032
2020-02-02 20:56:28,528 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000031-0000000000000000032 of size 42 edits # 2 loaded in 0 seconds
2020-02-02 20:56:28,530 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000032 using no compression
2020-02-02 20:56:28,537 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000032 of size 535 bytes saved in 0 seconds.
2020-02-02 20:56:28,542 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 30
2020-02-02 20:56:28,542 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000028, cpktTxId=0000000000000000028)
2020-02-02 20:56:28,556 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 32 to namenode at http://um1:50070 in 0.011 seconds
2020-02-02 20:56:28,556 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 535
2020-02-06 08:13:14,028 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.251.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2020-02-06 08:13:14,056 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-02-06 08:13:14,981 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-02-06 08:13:15,066 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-02-06 08:13:15,066 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2020-02-06 08:13:15,226 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2020-02-06 08:13:15,227 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2020-02-06 08:13:15,328 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 13702@um2
2020-02-06 08:13:15,393 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 13702@um2
2020-02-06 08:13:15,400 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2020-02-06 08:13:15,409 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2020-02-06 08:13:15,470 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2020-02-06 08:13:15,470 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2020-02-06 08:13:15,471 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-02-06 08:13:15,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2020 Feb 06 08:13:15
2020-02-06 08:13:15,475 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2020-02-06 08:13:15,475 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-02-06 08:13:15,476 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2020-02-06 08:13:15,476 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2020-02-06 08:13:15,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2020-02-06 08:13:15,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2020-02-06 08:13:15,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2020-02-06 08:13:15,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2020-02-06 08:13:15,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2020-02-06 08:13:15,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2020-02-06 08:13:15,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2020-02-06 08:13:15,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2020-02-06 08:13:15,496 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2020-02-06 08:13:15,496 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2020-02-06 08:13:15,497 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2020-02-06 08:13:15,497 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2020-02-06 08:13:15,499 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2020-02-06 08:13:15,886 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2020-02-06 08:13:15,886 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-02-06 08:13:15,886 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2020-02-06 08:13:15,886 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2020-02-06 08:13:15,887 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2020-02-06 08:13:15,894 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2020-02-06 08:13:15,894 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-02-06 08:13:15,895 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2020-02-06 08:13:15,895 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2020-02-06 08:13:16,216 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-02-06 08:13:16,216 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2020-02-06 08:13:16,216 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2020-02-06 08:13:16,221 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2020-02-06 08:13:16,222 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2020-02-06 08:13:16,222 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2020-02-06 08:13:16,319 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2020-02-06 08:13:16,428 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-02-06 08:13:16,435 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2020-02-06 08:13:16,452 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-02-06 08:13:16,455 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2020-02-06 08:13:16,455 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-02-06 08:13:16,456 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-02-06 08:13:16,480 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2020-02-06 08:13:16,480 INFO org.mortbay.log: jetty-6.1.26
2020-02-06 08:13:17,057 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2020-02-06 08:13:17,058 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2020-02-06 08:13:17,058 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2020-02-06 08:13:17,058 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2020-02-06 08:14:17,578 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2020-02-06 08:14:17,919 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=33&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-06 08:14:17,986 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2020-02-06 08:14:18,356 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2020-02-06 08:14:18,358 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000033 size 535 bytes.
2020-02-06 08:14:18,372 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=34&endTxId=35&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-06 08:14:18,386 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-06 08:14:18,386 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000034-0000000000000000035_0000000000001386790 size 0 bytes.
2020-02-06 08:14:18,522 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 4 INodes.
2020-02-06 08:14:18,567 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2020-02-06 08:14:18,568 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 33 from /orgz/snnfsi/current/fsimage_0000000000000000033
2020-02-06 08:14:18,568 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2020-02-06 08:14:18,576 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-06 08:14:18,583 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000034-0000000000000000035 expecting start txid #34
2020-02-06 08:14:18,583 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000034-0000000000000000035
2020-02-06 08:14:18,621 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000034-0000000000000000035 of size 42 edits # 2 loaded in 0 seconds
2020-02-06 08:14:18,631 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000035 using no compression
2020-02-06 08:14:18,726 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000035 of size 535 bytes saved in 0 seconds.
2020-02-06 08:14:18,741 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 33
2020-02-06 08:14:18,741 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000032, cpktTxId=0000000000000000032)
2020-02-06 08:14:18,744 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000030, cpktTxId=0000000000000000030)
2020-02-06 08:14:18,804 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 35 to namenode at http://um1:50070 in 0.039 seconds
2020-02-06 08:14:18,804 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 535
2020-02-06 08:24:18,996 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-06 08:24:18,997 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=36&endTxId=37&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-06 08:24:19,001 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-06 08:24:19,002 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000036-0000000000000000037_0000000000001987417 size 0 bytes.
2020-02-06 08:24:19,003 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-06 08:24:19,003 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000036-0000000000000000037 expecting start txid #36
2020-02-06 08:24:19,003 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000036-0000000000000000037
2020-02-06 08:24:19,004 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000036-0000000000000000037 of size 42 edits # 2 loaded in 0 seconds
2020-02-06 08:24:19,005 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000037 using no compression
2020-02-06 08:24:19,008 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000037 of size 535 bytes saved in 0 seconds.
2020-02-06 08:24:19,012 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 35
2020-02-06 08:24:19,012 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000033, cpktTxId=0000000000000000033)
2020-02-06 08:24:19,043 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 37 to namenode at http://um1:50070 in 0.026 seconds
2020-02-06 08:24:19,044 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 535
2020-02-06 08:34:19,297 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-06 08:34:19,297 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=38&endTxId=39&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-06 08:34:19,310 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2020-02-06 08:34:19,311 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000038-0000000000000000039_0000000000002587718 size 0 bytes.
2020-02-06 08:34:19,311 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-06 08:34:19,311 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000038-0000000000000000039 expecting start txid #38
2020-02-06 08:34:19,311 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000038-0000000000000000039
2020-02-06 08:34:19,312 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000038-0000000000000000039 of size 42 edits # 2 loaded in 0 seconds
2020-02-06 08:34:19,312 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000039 using no compression
2020-02-06 08:34:19,315 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000039 of size 535 bytes saved in 0 seconds.
2020-02-06 08:34:19,323 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 37
2020-02-06 08:34:19,324 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000035, cpktTxId=0000000000000000035)
2020-02-06 08:34:19,349 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 39 to namenode at http://um1:50070 in 0.012 seconds
2020-02-06 08:34:19,349 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 535
2020-02-15 14:58:07,160 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.251.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2020-02-15 14:58:07,176 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-02-15 14:58:07,922 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-02-15 14:58:08,008 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-02-15 14:58:08,009 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2020-02-15 14:58:08,221 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2020-02-15 14:58:08,222 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2020-02-15 14:58:08,316 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 3255@um2
2020-02-15 14:58:08,390 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 3255@um2
2020-02-15 14:58:08,398 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2020-02-15 14:58:08,408 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2020-02-15 14:58:08,453 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2020-02-15 14:58:08,453 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2020-02-15 14:58:08,454 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-02-15 14:58:08,456 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2020 Feb 15 14:58:08
2020-02-15 14:58:08,458 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2020-02-15 14:58:08,458 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-02-15 14:58:08,460 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2020-02-15 14:58:08,460 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2020-02-15 14:58:08,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2020-02-15 14:58:08,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2020-02-15 14:58:08,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2020-02-15 14:58:08,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2020-02-15 14:58:08,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2020-02-15 14:58:08,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2020-02-15 14:58:08,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2020-02-15 14:58:08,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2020-02-15 14:58:08,473 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2020-02-15 14:58:08,474 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2020-02-15 14:58:08,474 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2020-02-15 14:58:08,474 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2020-02-15 14:58:08,475 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2020-02-15 14:58:08,919 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2020-02-15 14:58:08,919 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-02-15 14:58:08,920 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2020-02-15 14:58:08,920 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2020-02-15 14:58:08,951 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2020-02-15 14:58:08,968 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2020-02-15 14:58:08,968 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-02-15 14:58:08,968 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2020-02-15 14:58:08,968 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2020-02-15 14:58:08,986 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-02-15 14:58:08,986 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2020-02-15 14:58:08,987 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2020-02-15 14:58:08,990 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2020-02-15 14:58:08,990 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2020-02-15 14:58:08,990 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2020-02-15 14:58:09,008 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2020-02-15 14:58:09,110 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-02-15 14:58:09,116 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2020-02-15 14:58:09,148 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-02-15 14:58:09,152 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2020-02-15 14:58:09,152 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-02-15 14:58:09,152 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-02-15 14:58:09,392 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2020-02-15 14:58:09,393 INFO org.mortbay.log: jetty-6.1.26
2020-02-15 14:58:09,798 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2020-02-15 14:58:09,798 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2020-02-15 14:58:09,799 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2020-02-15 14:58:09,799 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2020-02-15 14:59:10,387 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2020-02-15 14:59:10,710 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=40&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-15 14:59:10,798 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2020-02-15 14:59:11,481 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2020-02-15 14:59:11,483 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000040 size 535 bytes.
2020-02-15 14:59:11,500 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=41&endTxId=42&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-15 14:59:11,507 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-15 14:59:11,507 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000041-0000000000000000042_0000000000000871660 size 0 bytes.
2020-02-15 14:59:11,604 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 4 INodes.
2020-02-15 14:59:11,658 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2020-02-15 14:59:11,659 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 40 from /orgz/snnfsi/current/fsimage_0000000000000000040
2020-02-15 14:59:11,659 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2020-02-15 14:59:11,690 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-15 14:59:11,696 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000041-0000000000000000042 expecting start txid #41
2020-02-15 14:59:11,696 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000041-0000000000000000042
2020-02-15 14:59:11,734 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000041-0000000000000000042 of size 42 edits # 2 loaded in 0 seconds
2020-02-15 14:59:11,745 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000042 using no compression
2020-02-15 14:59:11,843 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000042 of size 535 bytes saved in 0 seconds.
2020-02-15 14:59:11,867 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 40
2020-02-15 14:59:11,867 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000037, cpktTxId=0000000000000000037)
2020-02-15 14:59:11,869 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000039, cpktTxId=0000000000000000039)
2020-02-15 14:59:11,962 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 42 to namenode at http://um1:50070 in 0.067 seconds
2020-02-15 14:59:11,962 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 535
2020-02-15 15:09:12,089 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-15 15:09:12,090 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=43&endTxId=153&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-15 15:09:12,096 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 6000.00 KB/s
2020-02-15 15:09:12,096 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000043-0000000000000000153_0000000000001472252 size 0 bytes.
2020-02-15 15:09:12,096 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-15 15:09:12,096 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000043-0000000000000000153 expecting start txid #43
2020-02-15 15:09:12,097 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000043-0000000000000000153
2020-02-15 15:09:12,179 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000043-0000000000000000153 of size 12931 edits # 111 loaded in 0 seconds
2020-02-15 15:09:12,181 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000153 using no compression
2020-02-15 15:09:12,186 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000153 of size 1953 bytes saved in 0 seconds.
2020-02-15 15:09:12,190 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 42
2020-02-15 15:09:12,190 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000040, cpktTxId=0000000000000000040)
2020-02-15 15:09:12,215 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 153 to namenode at http://um1:50070 in 0.018 seconds
2020-02-15 15:09:12,215 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1953
2020-02-15 15:19:12,351 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-15 15:19:12,351 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=154&endTxId=425&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-15 15:19:12,357 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 16000.00 KB/s
2020-02-15 15:19:12,357 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000154-0000000000000000425_0000000000002072514 size 0 bytes.
2020-02-15 15:19:12,357 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-15 15:19:12,357 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000154-0000000000000000425 expecting start txid #154
2020-02-15 15:19:12,357 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000154-0000000000000000425
2020-02-15 15:19:12,385 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000154-0000000000000000425 of size 33748 edits # 272 loaded in 0 seconds
2020-02-15 15:19:12,386 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000425 using no compression
2020-02-15 15:19:12,395 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000425 of size 4105 bytes saved in 0 seconds.
2020-02-15 15:19:12,398 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 153
2020-02-15 15:19:12,398 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000042, cpktTxId=0000000000000000042)
2020-02-15 15:19:12,414 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 425 to namenode at http://um1:50070 in 0.013 seconds
2020-02-15 15:19:12,415 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4105
2020-02-15 15:29:12,569 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-15 15:29:12,569 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=426&endTxId=427&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-15 15:29:12,574 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-15 15:29:12,574 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000426-0000000000000000427_0000000000002672731 size 0 bytes.
2020-02-15 15:29:12,574 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-15 15:29:12,574 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000426-0000000000000000427 expecting start txid #426
2020-02-15 15:29:12,574 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000426-0000000000000000427
2020-02-15 15:29:12,575 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000426-0000000000000000427 of size 42 edits # 2 loaded in 0 seconds
2020-02-15 15:29:12,576 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000427 using no compression
2020-02-15 15:29:12,584 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000427 of size 4105 bytes saved in 0 seconds.
2020-02-15 15:29:12,586 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 425
2020-02-15 15:29:12,586 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000153, cpktTxId=0000000000000000153)
2020-02-15 15:29:12,600 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 427 to namenode at http://um1:50070 in 0.011 seconds
2020-02-15 15:29:12,600 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4105
2020-02-15 15:39:12,722 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-15 15:39:12,722 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=428&endTxId=429&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-15 15:39:12,727 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-15 15:39:12,727 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000428-0000000000000000429_0000000000003272884 size 0 bytes.
2020-02-15 15:39:12,727 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-15 15:39:12,727 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000428-0000000000000000429 expecting start txid #428
2020-02-15 15:39:12,727 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000428-0000000000000000429
2020-02-15 15:39:12,728 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000428-0000000000000000429 of size 42 edits # 2 loaded in 0 seconds
2020-02-15 15:39:12,729 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000429 using no compression
2020-02-15 15:39:12,740 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000429 of size 4105 bytes saved in 0 seconds.
2020-02-15 15:39:12,742 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 427
2020-02-15 15:39:12,742 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000425, cpktTxId=0000000000000000425)
2020-02-15 15:39:12,757 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 429 to namenode at http://um1:50070 in 0.011 seconds
2020-02-15 15:39:12,757 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4105
2020-02-15 15:49:12,891 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-15 15:49:12,891 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=430&endTxId=431&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-15 15:49:12,897 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-15 15:49:12,897 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000430-0000000000000000431_0000000000003873054 size 0 bytes.
2020-02-15 15:49:12,897 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-15 15:49:12,897 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000430-0000000000000000431 expecting start txid #430
2020-02-15 15:49:12,897 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000430-0000000000000000431
2020-02-15 15:49:12,897 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000430-0000000000000000431 of size 42 edits # 2 loaded in 0 seconds
2020-02-15 15:49:12,899 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000431 using no compression
2020-02-15 15:49:12,903 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000431 of size 4105 bytes saved in 0 seconds.
2020-02-15 15:49:12,906 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 429
2020-02-15 15:49:12,907 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000427, cpktTxId=0000000000000000427)
2020-02-15 15:49:12,926 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 431 to namenode at http://um1:50070 in 0.016 seconds
2020-02-15 15:49:12,927 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4105
2020-02-15 15:59:13,057 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-15 15:59:13,058 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=432&endTxId=433&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-15 15:59:13,063 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-15 15:59:13,063 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000432-0000000000000000433_0000000000004473220 size 0 bytes.
2020-02-15 15:59:13,063 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-15 15:59:13,063 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000432-0000000000000000433 expecting start txid #432
2020-02-15 15:59:13,063 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000432-0000000000000000433
2020-02-15 15:59:13,063 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000432-0000000000000000433 of size 42 edits # 2 loaded in 0 seconds
2020-02-15 15:59:13,064 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000433 using no compression
2020-02-15 15:59:13,069 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000433 of size 4105 bytes saved in 0 seconds.
2020-02-15 15:59:13,072 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 431
2020-02-15 15:59:13,072 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000429, cpktTxId=0000000000000000429)
2020-02-15 15:59:13,085 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 433 to namenode at http://um1:50070 in 0.01 seconds
2020-02-15 15:59:13,086 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4105
2020-02-15 16:09:13,202 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-15 16:09:13,203 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=434&endTxId=435&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-15 16:09:13,207 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-15 16:09:13,207 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000434-0000000000000000435_0000000000005073365 size 0 bytes.
2020-02-15 16:09:13,207 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-15 16:09:13,207 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000434-0000000000000000435 expecting start txid #434
2020-02-15 16:09:13,207 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000434-0000000000000000435
2020-02-15 16:09:13,207 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000434-0000000000000000435 of size 42 edits # 2 loaded in 0 seconds
2020-02-15 16:09:13,209 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000435 using no compression
2020-02-15 16:09:13,215 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000435 of size 4105 bytes saved in 0 seconds.
2020-02-15 16:09:13,217 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 433
2020-02-15 16:09:13,217 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000431, cpktTxId=0000000000000000431)
2020-02-15 16:09:13,229 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 435 to namenode at http://um1:50070 in 0.009 seconds
2020-02-15 16:09:13,229 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4105
2020-02-15 16:19:13,361 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-15 16:19:13,362 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=436&endTxId=437&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-15 16:19:13,378 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-15 16:19:13,378 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000436-0000000000000000437_0000000000005673524 size 0 bytes.
2020-02-15 16:19:13,378 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-15 16:19:13,378 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000436-0000000000000000437 expecting start txid #436
2020-02-15 16:19:13,378 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000436-0000000000000000437
2020-02-15 16:19:13,379 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000436-0000000000000000437 of size 42 edits # 2 loaded in 0 seconds
2020-02-15 16:19:13,381 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000437 using no compression
2020-02-15 16:19:13,388 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000437 of size 4105 bytes saved in 0 seconds.
2020-02-15 16:19:13,393 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 435
2020-02-15 16:19:13,394 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000433, cpktTxId=0000000000000000433)
2020-02-15 16:19:13,413 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 437 to namenode at http://um1:50070 in 0.014 seconds
2020-02-15 16:19:13,413 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4105
2020-02-15 16:29:13,548 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-15 16:29:13,548 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=438&endTxId=439&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-15 16:29:13,554 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-15 16:29:13,554 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000438-0000000000000000439_0000000000006273711 size 0 bytes.
2020-02-15 16:29:13,554 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-15 16:29:13,554 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000438-0000000000000000439 expecting start txid #438
2020-02-15 16:29:13,554 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000438-0000000000000000439
2020-02-15 16:29:13,555 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000438-0000000000000000439 of size 42 edits # 2 loaded in 0 seconds
2020-02-15 16:29:13,555 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000439 using no compression
2020-02-15 16:29:13,558 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000439 of size 4105 bytes saved in 0 seconds.
2020-02-15 16:29:13,560 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 437
2020-02-15 16:29:13,560 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000435, cpktTxId=0000000000000000435)
2020-02-15 16:29:13,574 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 439 to namenode at http://um1:50070 in 0.008 seconds
2020-02-15 16:29:13,574 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4105
2020-02-15 16:39:13,736 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-15 16:39:13,737 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=440&endTxId=554&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-15 16:39:13,754 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 1181.82 KB/s
2020-02-15 16:39:13,754 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000440-0000000000000000554_0000000000006873899 size 0 bytes.
2020-02-15 16:39:13,754 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-15 16:39:13,754 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000440-0000000000000000554 expecting start txid #440
2020-02-15 16:39:13,754 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000440-0000000000000000554
2020-02-15 16:39:13,773 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000440-0000000000000000554 of size 13857 edits # 115 loaded in 0 seconds
2020-02-15 16:39:13,776 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000554 using no compression
2020-02-15 16:39:13,782 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000554 of size 4939 bytes saved in 0 seconds.
2020-02-15 16:39:13,786 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 439
2020-02-15 16:39:13,786 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000437, cpktTxId=0000000000000000437)
2020-02-15 16:39:13,804 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 554 to namenode at http://um1:50070 in 0.014 seconds
2020-02-15 16:39:13,804 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4939
2020-02-15 16:49:13,903 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-15 16:49:13,903 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=555&endTxId=556&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-15 16:49:13,908 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-15 16:49:13,908 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000555-0000000000000000556_0000000000007474066 size 0 bytes.
2020-02-15 16:49:13,908 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-15 16:49:13,908 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000555-0000000000000000556 expecting start txid #555
2020-02-15 16:49:13,908 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000555-0000000000000000556
2020-02-15 16:49:13,909 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000555-0000000000000000556 of size 42 edits # 2 loaded in 0 seconds
2020-02-15 16:49:13,910 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000556 using no compression
2020-02-15 16:49:13,920 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000556 of size 4939 bytes saved in 0 seconds.
2020-02-15 16:49:13,923 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 554
2020-02-15 16:49:13,923 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000439, cpktTxId=0000000000000000439)
2020-02-15 16:49:13,933 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 556 to namenode at http://um1:50070 in 0.007 seconds
2020-02-15 16:49:13,934 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4939
2020-02-15 16:59:14,039 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-15 16:59:14,039 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=557&endTxId=558&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-15 16:59:14,044 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-15 16:59:14,044 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000557-0000000000000000558_0000000000008074202 size 0 bytes.
2020-02-15 16:59:14,045 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-15 16:59:14,045 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000557-0000000000000000558 expecting start txid #557
2020-02-15 16:59:14,045 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000557-0000000000000000558
2020-02-15 16:59:14,045 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000557-0000000000000000558 of size 42 edits # 2 loaded in 0 seconds
2020-02-15 16:59:14,045 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000558 using no compression
2020-02-15 16:59:14,051 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000558 of size 4939 bytes saved in 0 seconds.
2020-02-15 16:59:14,053 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 556
2020-02-15 16:59:14,053 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000554, cpktTxId=0000000000000000554)
2020-02-15 16:59:14,063 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 558 to namenode at http://um1:50070 in 0.007 seconds
2020-02-15 16:59:14,064 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4939
2020-02-15 17:09:14,252 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-15 17:09:14,253 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=559&endTxId=560&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-15 17:09:14,259 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-15 17:09:14,260 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000559-0000000000000000560_0000000000008674415 size 0 bytes.
2020-02-15 17:09:14,260 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-15 17:09:14,263 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000559-0000000000000000560 expecting start txid #559
2020-02-15 17:09:14,263 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000559-0000000000000000560
2020-02-15 17:09:14,263 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000559-0000000000000000560 of size 42 edits # 2 loaded in 0 seconds
2020-02-15 17:09:14,269 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000560 using no compression
2020-02-15 17:09:14,272 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000560 of size 4939 bytes saved in 0 seconds.
2020-02-15 17:09:14,275 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 558
2020-02-15 17:09:14,275 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000556, cpktTxId=0000000000000000556)
2020-02-15 17:09:14,291 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 560 to namenode at http://um1:50070 in 0.008 seconds
2020-02-15 17:09:14,291 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4939
2020-02-15 17:19:14,406 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-15 17:19:14,406 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=561&endTxId=562&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-15 17:19:14,411 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-15 17:19:14,411 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000561-0000000000000000562_0000000000009274569 size 0 bytes.
2020-02-15 17:19:14,411 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-15 17:19:14,411 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000561-0000000000000000562 expecting start txid #561
2020-02-15 17:19:14,411 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000561-0000000000000000562
2020-02-15 17:19:14,411 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000561-0000000000000000562 of size 42 edits # 2 loaded in 0 seconds
2020-02-15 17:19:14,412 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000562 using no compression
2020-02-15 17:19:14,419 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000562 of size 4939 bytes saved in 0 seconds.
2020-02-15 17:19:14,421 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 560
2020-02-15 17:19:14,421 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000558, cpktTxId=0000000000000000558)
2020-02-15 17:19:14,432 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 562 to namenode at http://um1:50070 in 0.009 seconds
2020-02-15 17:19:14,432 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4939
2020-02-15 17:29:14,602 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-15 17:29:14,602 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=563&endTxId=564&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-15 17:29:14,607 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-15 17:29:14,607 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000563-0000000000000000564_0000000000009874764 size 0 bytes.
2020-02-15 17:29:14,607 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-15 17:29:14,607 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000563-0000000000000000564 expecting start txid #563
2020-02-15 17:29:14,607 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000563-0000000000000000564
2020-02-15 17:29:14,607 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000563-0000000000000000564 of size 42 edits # 2 loaded in 0 seconds
2020-02-15 17:29:14,608 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000564 using no compression
2020-02-15 17:29:14,611 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000564 of size 4939 bytes saved in 0 seconds.
2020-02-15 17:29:14,614 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 562
2020-02-15 17:29:14,614 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000560, cpktTxId=0000000000000000560)
2020-02-15 17:29:14,634 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 564 to namenode at http://um1:50070 in 0.011 seconds
2020-02-15 17:29:14,634 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4939
2020-02-15 17:39:14,773 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-15 17:39:14,773 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=565&endTxId=566&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-15 17:39:14,783 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 0.00 KB/s
2020-02-15 17:39:14,783 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000565-0000000000000000566_0000000000010474936 size 0 bytes.
2020-02-15 17:39:14,783 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-15 17:39:14,783 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000565-0000000000000000566 expecting start txid #565
2020-02-15 17:39:14,783 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000565-0000000000000000566
2020-02-15 17:39:14,783 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000565-0000000000000000566 of size 42 edits # 2 loaded in 0 seconds
2020-02-15 17:39:14,785 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000566 using no compression
2020-02-15 17:39:14,790 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000566 of size 4939 bytes saved in 0 seconds.
2020-02-15 17:39:14,793 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 564
2020-02-15 17:39:14,793 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000562, cpktTxId=0000000000000000562)
2020-02-15 17:39:14,813 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 566 to namenode at http://um1:50070 in 0.015 seconds
2020-02-15 17:39:14,813 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4939
2020-02-15 17:49:15,012 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-15 17:49:15,012 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=567&endTxId=568&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-15 17:49:15,018 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-15 17:49:15,018 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000567-0000000000000000568_0000000000011075175 size 0 bytes.
2020-02-15 17:49:15,018 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-15 17:49:15,018 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000567-0000000000000000568 expecting start txid #567
2020-02-15 17:49:15,018 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000567-0000000000000000568
2020-02-15 17:49:15,019 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000567-0000000000000000568 of size 42 edits # 2 loaded in 0 seconds
2020-02-15 17:49:15,021 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000568 using no compression
2020-02-15 17:49:15,035 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000568 of size 4939 bytes saved in 0 seconds.
2020-02-15 17:49:15,037 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 566
2020-02-15 17:49:15,038 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000564, cpktTxId=0000000000000000564)
2020-02-15 17:49:15,049 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 568 to namenode at http://um1:50070 in 0.008 seconds
2020-02-15 17:49:15,049 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4939
2020-02-15 17:59:15,171 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-15 17:59:15,171 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=569&endTxId=570&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-15 17:59:15,176 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-15 17:59:15,176 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000569-0000000000000000570_0000000000011675334 size 0 bytes.
2020-02-15 17:59:15,176 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-15 17:59:15,176 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000569-0000000000000000570 expecting start txid #569
2020-02-15 17:59:15,176 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000569-0000000000000000570
2020-02-15 17:59:15,176 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000569-0000000000000000570 of size 42 edits # 2 loaded in 0 seconds
2020-02-15 17:59:15,177 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000570 using no compression
2020-02-15 17:59:15,180 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000570 of size 4939 bytes saved in 0 seconds.
2020-02-15 17:59:15,182 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 568
2020-02-15 17:59:15,182 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000566, cpktTxId=0000000000000000566)
2020-02-15 17:59:15,203 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 570 to namenode at http://um1:50070 in 0.011 seconds
2020-02-15 17:59:15,203 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4939
2020-02-15 18:09:15,293 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-15 18:09:15,293 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=571&endTxId=572&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-15 18:09:15,300 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-15 18:09:15,300 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000571-0000000000000000572_0000000000012275456 size 0 bytes.
2020-02-15 18:09:15,300 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-15 18:09:15,300 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000571-0000000000000000572 expecting start txid #571
2020-02-15 18:09:15,300 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000571-0000000000000000572
2020-02-15 18:09:15,300 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000571-0000000000000000572 of size 42 edits # 2 loaded in 0 seconds
2020-02-15 18:09:15,301 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000572 using no compression
2020-02-15 18:09:15,307 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000572 of size 4939 bytes saved in 0 seconds.
2020-02-15 18:09:15,318 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 570
2020-02-15 18:09:15,318 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000568, cpktTxId=0000000000000000568)
2020-02-15 18:09:15,343 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 572 to namenode at http://um1:50070 in 0.021 seconds
2020-02-15 18:09:15,343 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4939
2020-02-15 18:19:15,430 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-15 18:19:15,430 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=573&endTxId=574&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-15 18:19:15,434 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-15 18:19:15,434 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000573-0000000000000000574_0000000000012875593 size 0 bytes.
2020-02-15 18:19:15,434 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-15 18:19:15,434 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000573-0000000000000000574 expecting start txid #573
2020-02-15 18:19:15,434 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000573-0000000000000000574
2020-02-15 18:19:15,434 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000573-0000000000000000574 of size 42 edits # 2 loaded in 0 seconds
2020-02-15 18:19:15,435 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000574 using no compression
2020-02-15 18:19:15,437 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000574 of size 4939 bytes saved in 0 seconds.
2020-02-15 18:19:15,440 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 572
2020-02-15 18:19:15,440 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000570, cpktTxId=0000000000000000570)
2020-02-15 18:19:15,453 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 574 to namenode at http://um1:50070 in 0.009 seconds
2020-02-15 18:19:15,453 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4939
2020-02-15 18:29:15,565 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-15 18:29:15,565 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=575&endTxId=576&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-15 18:29:15,572 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-15 18:29:15,573 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000575-0000000000000000576_0000000000013475728 size 0 bytes.
2020-02-15 18:29:15,573 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-15 18:29:15,573 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000575-0000000000000000576 expecting start txid #575
2020-02-15 18:29:15,573 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000575-0000000000000000576
2020-02-15 18:29:15,573 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000575-0000000000000000576 of size 42 edits # 2 loaded in 0 seconds
2020-02-15 18:29:15,574 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000576 using no compression
2020-02-15 18:29:15,579 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000576 of size 4939 bytes saved in 0 seconds.
2020-02-15 18:29:15,582 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 574
2020-02-15 18:29:15,582 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000572, cpktTxId=0000000000000000572)
2020-02-15 18:29:15,592 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 576 to namenode at http://um1:50070 in 0.006 seconds
2020-02-15 18:29:15,592 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 4939
2020-02-15 18:31:35,143 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:31:39,205 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:31:42,276 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:31:45,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:31:48,420 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:31:51,491 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:31:54,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:31:57,635 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:32:00,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:32:03,785 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:32:05,856 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 18:33:09,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:33:13,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:33:16,098 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:33:19,234 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:33:22,313 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:33:25,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:33:28,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:33:31,523 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:33:34,595 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:33:37,668 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:33:39,777 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 18:34:43,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:34:46,914 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:34:50,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:34:53,064 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:34:56,130 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:34:59,209 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:35:02,280 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:35:05,356 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:35:08,515 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:35:11,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:35:13,962 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 18:36:18,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:36:21,095 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:36:24,166 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:36:27,237 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:36:30,307 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:36:33,381 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:36:36,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:36:39,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:36:42,594 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:36:45,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:36:47,739 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 18:37:51,812 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:37:54,894 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:37:57,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:38:01,037 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:38:04,108 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:38:07,176 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:38:10,244 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:38:13,320 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:38:16,388 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:38:19,458 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:38:21,530 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 18:39:22,857 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:39:26,914 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:39:29,987 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:39:33,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:39:36,145 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:39:39,215 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:39:42,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:39:45,357 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:39:48,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:39:51,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:39:53,563 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 18:40:57,681 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:41:00,743 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:41:03,813 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:41:06,883 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:41:09,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:41:13,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:41:16,098 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:41:19,170 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:41:22,243 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:41:25,321 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:41:27,386 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 18:42:31,462 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:42:34,551 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:42:37,626 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:42:40,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:42:43,782 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:42:46,855 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:42:49,929 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:42:53,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:42:56,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:42:59,140 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:43:01,210 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 18:44:05,289 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:44:08,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:44:11,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:44:14,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:44:17,575 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:44:20,642 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:44:23,718 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:44:26,788 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:44:29,867 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:44:32,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:44:35,034 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 18:45:39,107 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:45:42,178 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:45:45,253 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:45:48,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:45:51,394 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:45:54,470 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:45:57,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:46:00,611 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:46:03,685 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:46:06,760 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:46:08,829 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 18:47:11,845 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:47:14,913 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:47:17,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:47:21,076 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:47:24,130 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:47:27,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:47:30,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:47:33,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:47:36,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:47:39,490 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:47:41,563 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 18:48:44,045 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:48:47,113 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:48:50,183 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:48:53,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:48:56,398 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:48:59,461 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:49:02,533 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:49:05,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:49:08,682 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:49:11,748 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:49:13,819 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 18:50:16,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:50:19,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:50:22,569 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:50:25,638 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:50:28,706 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:50:31,779 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:50:34,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:50:37,964 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:50:41,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:50:44,100 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:50:46,178 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 18:51:48,792 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:51:51,849 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:51:54,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:51:58,011 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:52:01,062 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:52:04,131 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:52:07,202 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:52:10,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:52:13,348 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:52:16,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:52:18,492 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 18:53:20,931 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:53:24,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:53:27,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:53:30,151 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:53:33,220 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:53:36,304 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:53:39,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:53:42,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:53:45,507 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:53:48,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:53:50,650 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 18:54:53,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:54:56,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:54:59,401 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:55:02,482 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:55:05,542 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:55:08,611 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:55:11,683 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:55:14,764 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:55:17,828 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:55:20,904 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:55:22,982 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 18:56:25,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:56:28,778 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:56:31,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:56:34,918 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:56:38,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:56:41,059 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:56:44,135 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:56:47,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:56:50,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:56:53,353 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:56:55,420 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 18:57:57,970 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:58:01,029 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:58:04,107 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:58:07,172 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:58:10,245 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:58:13,315 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:58:16,387 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:58:19,468 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:58:22,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:58:25,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:58:27,674 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 18:59:30,147 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:59:33,224 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:59:36,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:59:39,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:59:42,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:59:45,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:59:48,579 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:59:51,651 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:59:54,723 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:59:57,796 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 18:59:59,868 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:01:02,345 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:01:05,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:01:08,489 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:01:11,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:01:14,628 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:01:17,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:01:20,772 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:01:23,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:01:26,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:01:29,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:01:32,063 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:02:34,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:02:37,607 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:02:40,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:02:44,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:02:47,112 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:02:50,180 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:02:53,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:02:56,325 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:02:59,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:03:02,475 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:03:04,540 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:04:07,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:04:10,116 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:04:13,188 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:04:16,291 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:04:19,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:04:22,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:04:25,479 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:04:28,553 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:04:31,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:04:34,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:04:36,766 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:05:39,209 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:05:42,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:05:45,350 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:05:48,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:05:51,491 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:05:54,561 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:05:57,635 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:06:00,717 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:06:03,778 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:06:06,856 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:06:08,926 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:07:11,428 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:07:14,499 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:07:17,572 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:07:20,651 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:07:23,715 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:07:26,793 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:07:29,860 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:07:32,931 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:07:36,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:07:39,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:07:41,165 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:08:43,684 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:08:46,755 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:08:49,829 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:08:52,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:08:56,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:08:59,110 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:09:02,183 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:09:05,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:09:08,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:09:11,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:09:13,466 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:10:15,910 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:10:18,984 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:10:22,053 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:10:25,154 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:10:28,194 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:10:31,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:10:34,345 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:10:37,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:10:40,488 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:10:43,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:10:45,628 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:11:48,642 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:11:51,715 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:11:54,759 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:11:57,832 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:12:00,908 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:12:03,983 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:12:07,049 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:12:10,127 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:12:13,200 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:12:16,286 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:12:18,334 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:13:20,792 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:13:23,847 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:13:26,923 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:13:29,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:13:33,059 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:13:36,137 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:13:39,207 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:13:42,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:13:45,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:13:48,429 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:13:50,492 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:14:52,980 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:14:56,037 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:14:59,107 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:15:02,180 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:15:05,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:15:08,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:15:11,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:15:14,468 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:15:17,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:15:20,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:15:22,700 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:16:25,165 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:16:28,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:16:31,310 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:16:34,386 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:16:37,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:16:40,515 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:16:43,586 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:16:46,749 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:16:49,837 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:16:52,923 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:16:54,976 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:17:57,499 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:18:00,548 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:18:03,618 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:18:06,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:18:09,797 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:18:12,868 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:18:15,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:18:19,011 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:18:22,087 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:18:25,156 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:18:27,228 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:19:29,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:19:32,740 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:19:35,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:19:38,883 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:19:41,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:19:45,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:19:48,099 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:19:51,173 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:19:54,247 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:19:57,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:19:59,387 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:21:01,839 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:21:04,944 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:21:08,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:21:11,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:21:14,148 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:21:17,220 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:21:20,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:21:23,366 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:21:26,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:21:29,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:21:31,580 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:22:34,053 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:22:37,124 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:22:40,194 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:22:43,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:22:46,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:22:49,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:22:52,502 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:22:55,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:22:58,633 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:23:01,700 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:23:03,785 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:24:06,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:24:09,289 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:24:12,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:24:15,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:24:18,524 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:24:21,604 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:24:24,681 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:24:27,765 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:24:30,820 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:24:33,892 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:24:35,964 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:25:38,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:25:41,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:25:44,579 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:25:47,658 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:25:50,724 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:25:53,847 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:25:56,899 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:25:59,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:26:03,057 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:26:06,130 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:26:08,187 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:27:10,627 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:27:13,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:27:16,771 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:27:19,848 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:27:22,921 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:27:25,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:27:29,058 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:27:32,131 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:27:35,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:27:38,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:27:40,346 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:28:42,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:28:45,948 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:28:48,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:28:52,066 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:28:55,141 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:28:58,211 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:29:01,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:29:04,357 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:29:07,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:29:10,500 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:29:12,572 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:30:15,051 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:30:18,123 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:30:21,187 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:30:24,264 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:30:27,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:30:30,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:30:33,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:30:36,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:30:39,620 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:30:42,725 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:30:44,797 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:31:47,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:31:50,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:31:53,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:31:56,484 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:31:59,554 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:32:02,645 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:32:05,719 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:32:08,771 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:32:11,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:32:14,923 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:32:16,988 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:33:19,478 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:33:22,531 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:33:25,606 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:33:28,674 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:33:31,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:33:34,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:33:37,890 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:33:40,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:33:44,068 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:33:47,142 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:33:49,212 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:34:51,688 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:34:54,754 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:34:57,827 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:35:00,904 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:35:03,972 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:35:07,047 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:35:10,155 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:35:13,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:35:16,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:35:19,534 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:35:21,699 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:36:24,162 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:36:27,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:36:30,338 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:36:33,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:36:36,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:36:39,554 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:36:42,626 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:36:45,710 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:36:48,772 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:36:51,850 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:36:53,917 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:37:56,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:37:59,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:38:02,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:38:05,570 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:38:08,642 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:38:11,717 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:38:14,787 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:38:17,861 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:38:20,938 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:38:24,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:38:26,089 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:39:28,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:39:31,625 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:39:34,659 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:39:37,730 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:39:40,802 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:39:43,875 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:39:46,952 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:39:50,018 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:39:53,091 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:39:56,164 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:39:58,234 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:41:00,674 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:41:03,746 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:41:06,819 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:41:09,890 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:41:12,965 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:41:16,033 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:41:19,159 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:41:22,300 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:41:25,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:41:28,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:41:30,490 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:42:32,942 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:42:36,006 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:42:39,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:42:42,146 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:42:45,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:42:48,295 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:42:51,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:42:54,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:42:57,512 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:43:00,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:43:02,650 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:44:05,123 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:44:08,200 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:44:11,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:44:14,356 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:44:17,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:44:20,484 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:44:23,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:44:26,632 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:44:29,715 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:44:32,779 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:44:34,845 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:45:37,285 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:45:40,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:45:43,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:45:46,507 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:45:49,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:45:52,643 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:45:55,716 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:45:58,793 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:46:01,861 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:46:04,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:46:07,034 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:47:09,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:47:12,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:47:15,618 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:47:18,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:47:21,806 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:47:24,937 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:47:27,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:47:31,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:47:34,114 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:47:37,186 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:47:39,263 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:48:41,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:48:44,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:48:47,847 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:48:50,914 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:48:53,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:48:57,060 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:49:00,130 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:49:03,202 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:49:06,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:49:09,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:49:11,418 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:50:13,933 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:50:17,016 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:50:20,068 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:50:23,149 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:50:26,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:50:29,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:50:32,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:50:35,428 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:50:38,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:50:41,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:50:43,661 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:51:46,147 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:51:49,222 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:51:52,293 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:51:55,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:51:58,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:52:01,516 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:52:04,580 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:52:07,652 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:52:10,723 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:52:13,794 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:52:15,871 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.NoRouteToHostException: No Route to Host from  um2/192.168.251.4 to um1:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor15.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:128)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:641)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:649)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:393)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:361)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:412)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:357)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 17 more
2020-02-15 19:53:18,356 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:53:21,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:53:24,488 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:53:27,563 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:53:30,627 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:53:33,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:53:36,770 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: um1/192.168.251.3:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-02-15 19:53:39,842 INFO org.apache.hadoop.ipc.Client: Retryin2020-02-23 17:14:15,497 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.251.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2020-02-23 17:14:15,529 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-02-23 17:14:16,708 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-02-23 17:14:16,844 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-02-23 17:14:16,844 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2020-02-23 17:14:17,072 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2020-02-23 17:14:17,072 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2020-02-23 17:14:17,233 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 3210@um2
2020-02-23 17:14:17,381 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 3210@um2
2020-02-23 17:14:17,397 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2020-02-23 17:14:17,429 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2020-02-23 17:14:17,590 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2020-02-23 17:14:17,590 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2020-02-23 17:14:17,601 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-02-23 17:14:17,604 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2020 Feb 23 17:14:17
2020-02-23 17:14:17,615 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2020-02-23 17:14:17,615 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-02-23 17:14:17,617 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2020-02-23 17:14:17,617 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2020-02-23 17:14:17,646 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2020-02-23 17:14:17,646 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2020-02-23 17:14:17,646 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2020-02-23 17:14:17,646 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2020-02-23 17:14:17,647 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2020-02-23 17:14:17,647 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2020-02-23 17:14:17,647 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2020-02-23 17:14:17,647 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2020-02-23 17:14:17,656 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2020-02-23 17:14:17,656 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2020-02-23 17:14:17,656 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2020-02-23 17:14:17,657 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2020-02-23 17:14:17,661 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2020-02-23 17:14:18,796 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2020-02-23 17:14:18,796 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-02-23 17:14:18,797 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2020-02-23 17:14:18,797 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2020-02-23 17:14:18,834 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2020-02-23 17:14:18,877 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2020-02-23 17:14:18,877 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-02-23 17:14:18,878 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2020-02-23 17:14:18,878 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2020-02-23 17:14:18,881 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-02-23 17:14:18,881 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2020-02-23 17:14:18,881 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2020-02-23 17:14:18,884 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2020-02-23 17:14:18,884 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2020-02-23 17:14:18,884 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2020-02-23 17:14:18,930 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2020-02-23 17:14:19,081 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-02-23 17:14:19,087 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2020-02-23 17:14:19,126 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-02-23 17:14:19,130 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2020-02-23 17:14:19,130 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-02-23 17:14:19,130 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-02-23 17:14:19,347 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2020-02-23 17:14:19,347 INFO org.mortbay.log: jetty-6.1.26
2020-02-23 17:14:19,764 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2020-02-23 17:14:19,766 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2020-02-23 17:14:19,767 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2020-02-23 17:14:19,767 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2020-02-23 17:20:20,111 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2020-02-23 17:20:20,277 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=577&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-23 17:20:20,337 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2020-02-23 17:20:20,718 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 571.43 KB/s
2020-02-23 17:20:20,719 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000577 size 4939 bytes.
2020-02-23 17:20:20,725 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=578&endTxId=585&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-23 17:20:20,739 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-23 17:20:20,739 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000578-0000000000000000585_0000000000000601930 size 0 bytes.
2020-02-23 17:20:20,778 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 58 INodes.
2020-02-23 17:20:20,810 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2020-02-23 17:20:20,810 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 577 from /orgz/snnfsi/current/fsimage_0000000000000000577
2020-02-23 17:20:20,810 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2020-02-23 17:20:20,816 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-23 17:20:20,821 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000578-0000000000000000585 expecting start txid #578
2020-02-23 17:20:20,821 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000578-0000000000000000585
2020-02-23 17:20:20,848 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000578-0000000000000000585 of size 682 edits # 8 loaded in 0 seconds
2020-02-23 17:20:20,854 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000585 using no compression
2020-02-23 17:20:20,913 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000585 of size 5384 bytes saved in 0 seconds.
2020-02-23 17:20:20,926 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 577
2020-02-23 17:20:20,926 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000576, cpktTxId=0000000000000000576)
2020-02-23 17:20:20,927 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000574, cpktTxId=0000000000000000574)
2020-02-23 17:20:20,977 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 585 to namenode at http://um1:50070 in 0.025 seconds
2020-02-23 17:20:20,977 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5384
2020-02-23 17:30:21,101 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-23 17:30:21,102 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=586&endTxId=595&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-23 17:30:21,108 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-23 17:30:21,108 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000586-0000000000000000595_0000000000001202307 size 0 bytes.
2020-02-23 17:30:21,108 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-23 17:30:21,108 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000586-0000000000000000595 expecting start txid #586
2020-02-23 17:30:21,108 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000586-0000000000000000595
2020-02-23 17:30:21,120 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000586-0000000000000000595 of size 926 edits # 10 loaded in 0 seconds
2020-02-23 17:30:21,122 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000595 using no compression
2020-02-23 17:30:21,131 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000595 of size 5057 bytes saved in 0 seconds.
2020-02-23 17:30:21,134 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 585
2020-02-23 17:30:21,134 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000577, cpktTxId=0000000000000000577)
2020-02-23 17:30:21,187 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 595 to namenode at http://um1:50070 in 0.036 seconds
2020-02-23 17:30:21,187 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5057
2020-02-23 17:40:21,338 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-23 17:40:21,339 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=596&endTxId=597&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-23 17:40:21,344 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-23 17:40:21,345 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000596-0000000000000000597_0000000000001802543 size 0 bytes.
2020-02-23 17:40:21,345 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-23 17:40:21,345 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000596-0000000000000000597 expecting start txid #596
2020-02-23 17:40:21,345 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000596-0000000000000000597
2020-02-23 17:40:21,346 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000596-0000000000000000597 of size 42 edits # 2 loaded in 0 seconds
2020-02-23 17:40:21,346 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000597 using no compression
2020-02-23 17:40:21,359 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000597 of size 5057 bytes saved in 0 seconds.
2020-02-23 17:40:21,368 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 595
2020-02-23 17:40:21,368 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000585, cpktTxId=0000000000000000585)
2020-02-23 17:40:21,400 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 597 to namenode at http://um1:50070 in 0.021 seconds
2020-02-23 17:40:21,400 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5057
2020-02-23 17:50:21,571 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-23 17:50:21,571 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=598&endTxId=599&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-23 17:50:21,577 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-23 17:50:21,577 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000598-0000000000000000599_0000000000002402776 size 0 bytes.
2020-02-23 17:50:21,577 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-23 17:50:21,577 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000598-0000000000000000599 expecting start txid #598
2020-02-23 17:50:21,578 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000598-0000000000000000599
2020-02-23 17:50:21,578 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000598-0000000000000000599 of size 42 edits # 2 loaded in 0 seconds
2020-02-23 17:50:21,586 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000599 using no compression
2020-02-23 17:50:21,591 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000599 of size 5057 bytes saved in 0 seconds.
2020-02-23 17:50:21,595 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 597
2020-02-23 17:50:21,595 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000595, cpktTxId=0000000000000000595)
2020-02-23 17:50:21,613 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 599 to namenode at http://um1:50070 in 0.009 seconds
2020-02-23 17:50:21,613 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5057
2020-02-23 18:00:21,757 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-23 18:00:21,758 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=600&endTxId=601&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-23 18:00:21,764 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-23 18:00:21,765 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000600-0000000000000000601_0000000000003002963 size 0 bytes.
2020-02-23 18:00:21,765 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-23 18:00:21,765 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000600-0000000000000000601 expecting start txid #600
2020-02-23 18:00:21,765 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000600-0000000000000000601
2020-02-23 18:00:21,766 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000600-0000000000000000601 of size 42 edits # 2 loaded in 0 seconds
2020-02-23 18:00:21,768 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000601 using no compression
2020-02-23 18:00:21,773 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000601 of size 5057 bytes saved in 0 seconds.
2020-02-23 18:00:21,776 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 599
2020-02-23 18:00:21,776 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000597, cpktTxId=0000000000000000597)
2020-02-23 18:00:21,792 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 601 to namenode at http://um1:50070 in 0.011 seconds
2020-02-23 18:00:21,792 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5057
2020-02-23 18:10:21,966 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-23 18:10:21,967 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=602&endTxId=603&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-23 18:10:21,975 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-23 18:10:21,975 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000602-0000000000000000603_0000000000003603171 size 0 bytes.
2020-02-23 18:10:21,976 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-23 18:10:21,976 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000602-0000000000000000603 expecting start txid #602
2020-02-23 18:10:21,976 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000602-0000000000000000603
2020-02-23 18:10:21,977 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000602-0000000000000000603 of size 42 edits # 2 loaded in 0 seconds
2020-02-23 18:10:21,983 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000603 using no compression
2020-02-23 18:10:21,999 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000603 of size 5057 bytes saved in 0 seconds.
2020-02-23 18:10:22,019 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 601
2020-02-23 18:10:22,019 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000599, cpktTxId=0000000000000000599)
2020-02-23 18:10:22,095 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 603 to namenode at http://um1:50070 in 0.053 seconds
2020-02-23 18:10:22,095 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5057
2020-02-23 18:20:22,251 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-02-23 18:20:22,251 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=604&endTxId=605&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-02-23 18:20:22,258 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-02-23 18:20:22,258 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000604-0000000000000000605_0000000000004203456 size 0 bytes.
2020-02-23 18:20:22,258 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-02-23 18:20:22,258 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000604-0000000000000000605 expecting start txid #604
2020-02-23 18:20:22,258 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000604-0000000000000000605
2020-02-23 18:20:22,258 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000604-0000000000000000605 of size 42 edits # 2 loaded in 0 seconds
2020-02-23 18:20:22,259 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000605 using no compression
2020-02-23 18:20:22,263 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000605 of size 5057 bytes saved in 0 seconds.
2020-02-23 18:20:22,265 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 603
2020-02-23 18:20:22,266 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000601, cpktTxId=0000000000000000601)
2020-02-23 18:20:22,279 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 605 to namenode at http://um1:50070 in 0.008 seconds
2020-02-23 18:20:22,279 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5057
2020-03-04 06:18:34,272 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.251.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2020-03-04 06:18:34,291 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-04 06:18:35,408 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-03-04 06:18:35,557 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-03-04 06:18:35,557 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2020-03-04 06:18:35,836 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2020-03-04 06:18:35,837 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2020-03-04 06:18:35,965 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 4084@um2
2020-03-04 06:18:36,028 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 4084@um2
2020-03-04 06:18:36,045 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2020-03-04 06:18:36,053 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2020-03-04 06:18:36,110 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2020-03-04 06:18:36,110 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2020-03-04 06:18:36,111 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-03-04 06:18:36,113 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2020 Mar 04 06:18:36
2020-03-04 06:18:36,115 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2020-03-04 06:18:36,115 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-03-04 06:18:36,116 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2020-03-04 06:18:36,116 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2020-03-04 06:18:36,131 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2020-03-04 06:18:36,131 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2020-03-04 06:18:36,131 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2020-03-04 06:18:36,131 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2020-03-04 06:18:36,131 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2020-03-04 06:18:36,131 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2020-03-04 06:18:36,131 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2020-03-04 06:18:36,131 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2020-03-04 06:18:36,132 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2020-03-04 06:18:36,132 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2020-03-04 06:18:36,132 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2020-03-04 06:18:36,132 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2020-03-04 06:18:36,138 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2020-03-04 06:18:36,568 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2020-03-04 06:18:36,568 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-03-04 06:18:36,569 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2020-03-04 06:18:36,569 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2020-03-04 06:18:36,583 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2020-03-04 06:18:36,593 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2020-03-04 06:18:36,593 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-03-04 06:18:36,594 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2020-03-04 06:18:36,594 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2020-03-04 06:18:36,601 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-03-04 06:18:36,601 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2020-03-04 06:18:36,601 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2020-03-04 06:18:36,603 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2020-03-04 06:18:36,603 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2020-03-04 06:18:36,603 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2020-03-04 06:18:36,620 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2020-03-04 06:18:36,674 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-03-04 06:18:36,678 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2020-03-04 06:18:36,695 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-04 06:18:36,697 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2020-03-04 06:18:36,699 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-04 06:18:36,699 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-04 06:18:36,786 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2020-03-04 06:18:36,786 INFO org.mortbay.log: jetty-6.1.26
2020-03-04 06:18:36,997 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2020-03-04 06:18:36,997 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2020-03-04 06:18:36,998 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2020-03-04 06:18:36,998 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2020-03-04 06:21:37,299 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2020-03-04 06:21:37,505 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=606&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-03-04 06:21:37,582 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2020-03-04 06:21:37,771 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 500.00 KB/s
2020-03-04 06:21:37,771 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000606 size 5057 bytes.
2020-03-04 06:21:37,781 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=607&endTxId=608&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-03-04 06:21:37,787 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-03-04 06:21:37,787 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000607-0000000000000000608_0000000000000660492 size 0 bytes.
2020-03-04 06:21:37,837 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 60 INodes.
2020-03-04 06:21:37,879 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2020-03-04 06:21:37,880 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 606 from /orgz/snnfsi/current/fsimage_0000000000000000606
2020-03-04 06:21:37,880 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2020-03-04 06:21:37,889 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-03-04 06:21:37,892 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000607-0000000000000000608 expecting start txid #607
2020-03-04 06:21:37,892 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000607-0000000000000000608
2020-03-04 06:21:37,916 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000607-0000000000000000608 of size 42 edits # 2 loaded in 0 seconds
2020-03-04 06:21:37,922 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000608 using no compression
2020-03-04 06:21:37,985 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000608 of size 5057 bytes saved in 0 seconds.
2020-03-04 06:21:38,000 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 606
2020-03-04 06:21:38,000 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000603, cpktTxId=0000000000000000603)
2020-03-04 06:21:38,001 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000605, cpktTxId=0000000000000000605)
2020-03-04 06:21:38,058 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 608 to namenode at http://um1:50070 in 0.038 seconds
2020-03-04 06:21:38,058 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5057
2020-03-04 06:31:38,223 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-03-04 06:31:38,223 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=609&endTxId=610&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-03-04 06:31:38,229 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-03-04 06:31:38,229 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000609-0000000000000000610_0000000000001260935 size 0 bytes.
2020-03-04 06:31:38,229 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-03-04 06:31:38,229 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000609-0000000000000000610 expecting start txid #609
2020-03-04 06:31:38,229 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000609-0000000000000000610
2020-03-04 06:31:38,230 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000609-0000000000000000610 of size 42 edits # 2 loaded in 0 seconds
2020-03-04 06:31:38,230 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000610 using no compression
2020-03-04 06:31:38,237 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000610 of size 5057 bytes saved in 0 seconds.
2020-03-04 06:31:38,248 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 608
2020-03-04 06:31:38,248 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000606, cpktTxId=0000000000000000606)
2020-03-04 06:31:38,269 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 610 to namenode at http://um1:50070 in 0.014 seconds
2020-03-04 06:31:38,269 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5057
2020-03-04 06:41:38,398 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-03-04 06:41:38,398 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=611&endTxId=612&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-03-04 06:41:38,403 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-03-04 06:41:38,404 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000611-0000000000000000612_0000000000001861109 size 0 bytes.
2020-03-04 06:41:38,404 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-03-04 06:41:38,404 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000611-0000000000000000612 expecting start txid #611
2020-03-04 06:41:38,404 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000611-0000000000000000612
2020-03-04 06:41:38,404 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000611-0000000000000000612 of size 42 edits # 2 loaded in 0 seconds
2020-03-04 06:41:38,405 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000612 using no compression
2020-03-04 06:41:38,410 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000612 of size 5057 bytes saved in 0 seconds.
2020-03-04 06:41:38,413 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 610
2020-03-04 06:41:38,413 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000608, cpktTxId=0000000000000000608)
2020-03-04 06:41:38,429 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 612 to namenode at http://um1:50070 in 0.011 seconds
2020-03-04 06:41:38,429 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5057
2020-03-04 06:51:38,558 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-03-04 06:51:38,558 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=613&endTxId=614&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-03-04 06:51:38,565 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-03-04 06:51:38,565 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000613-0000000000000000614_0000000000002461270 size 0 bytes.
2020-03-04 06:51:38,566 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-03-04 06:51:38,566 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000613-0000000000000000614 expecting start txid #613
2020-03-04 06:51:38,566 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000613-0000000000000000614
2020-03-04 06:51:38,567 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000613-0000000000000000614 of size 42 edits # 2 loaded in 0 seconds
2020-03-04 06:51:38,569 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000614 using no compression
2020-03-04 06:51:38,577 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000614 of size 5057 bytes saved in 0 seconds.
2020-03-04 06:51:38,579 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 612
2020-03-04 06:51:38,579 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000610, cpktTxId=0000000000000000610)
2020-03-04 06:51:38,595 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 614 to namenode at http://um1:50070 in 0.01 seconds
2020-03-04 06:51:38,595 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5057
2020-03-04 07:01:38,756 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-03-04 07:01:38,756 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=615&endTxId=616&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-03-04 07:01:38,762 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-03-04 07:01:38,762 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000615-0000000000000000616_0000000000003061468 size 0 bytes.
2020-03-04 07:01:38,762 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-03-04 07:01:38,762 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000615-0000000000000000616 expecting start txid #615
2020-03-04 07:01:38,762 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000615-0000000000000000616
2020-03-04 07:01:38,763 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000615-0000000000000000616 of size 42 edits # 2 loaded in 0 seconds
2020-03-04 07:01:38,763 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000616 using no compression
2020-03-04 07:01:38,767 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000616 of size 5057 bytes saved in 0 seconds.
2020-03-04 07:01:38,770 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 614
2020-03-04 07:01:38,770 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000612, cpktTxId=0000000000000000612)
2020-03-04 07:01:38,787 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 616 to namenode at http://um1:50070 in 0.012 seconds
2020-03-04 07:01:38,787 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5057
2020-03-04 07:11:38,912 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-03-04 07:11:38,912 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=617&endTxId=618&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-03-04 07:11:38,916 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-03-04 07:11:38,916 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000617-0000000000000000618_0000000000003661623 size 0 bytes.
2020-03-04 07:11:38,916 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-03-04 07:11:38,917 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000617-0000000000000000618 expecting start txid #617
2020-03-04 07:11:38,917 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000617-0000000000000000618
2020-03-04 07:11:38,917 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000617-0000000000000000618 of size 42 edits # 2 loaded in 0 seconds
2020-03-04 07:11:38,918 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000618 using no compression
2020-03-04 07:11:38,922 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000618 of size 5057 bytes saved in 0 seconds.
2020-03-04 07:11:38,925 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 616
2020-03-04 07:11:38,925 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000614, cpktTxId=0000000000000000614)
2020-03-04 07:11:38,956 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 618 to namenode at http://um1:50070 in 0.025 seconds
2020-03-04 07:11:38,956 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5057
2020-03-04 07:21:39,112 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-03-04 07:21:39,112 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=619&endTxId=620&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-03-04 07:21:39,118 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-03-04 07:21:39,118 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000619-0000000000000000620_0000000000004261823 size 0 bytes.
2020-03-04 07:21:39,119 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-03-04 07:21:39,119 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000619-0000000000000000620 expecting start txid #619
2020-03-04 07:21:39,119 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000619-0000000000000000620
2020-03-04 07:21:39,119 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000619-0000000000000000620 of size 42 edits # 2 loaded in 0 seconds
2020-03-04 07:21:39,121 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000620 using no compression
2020-03-04 07:21:39,125 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000620 of size 5057 bytes saved in 0 seconds.
2020-03-04 07:21:39,128 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 618
2020-03-04 07:21:39,128 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000616, cpktTxId=0000000000000000616)
2020-03-04 07:21:39,152 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 620 to namenode at http://um1:50070 in 0.009 seconds
2020-03-04 07:21:39,152 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5057
2020-03-04 07:31:39,355 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-03-04 07:31:39,355 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=621&endTxId=622&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-03-04 07:31:39,363 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-03-04 07:31:39,363 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000621-0000000000000000622_0000000000004862067 size 0 bytes.
2020-03-04 07:31:39,364 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-03-04 07:31:39,364 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000621-0000000000000000622 expecting start txid #621
2020-03-04 07:31:39,364 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000621-0000000000000000622
2020-03-04 07:31:39,365 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000621-0000000000000000622 of size 42 edits # 2 loaded in 0 seconds
2020-03-04 07:31:39,366 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000622 using no compression
2020-03-04 07:31:39,376 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000622 of size 5057 bytes saved in 0 seconds.
2020-03-04 07:31:39,380 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 620
2020-03-04 07:31:39,381 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000618, cpktTxId=0000000000000000618)
2020-03-04 07:31:39,411 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 622 to namenode at http://um1:50070 in 0.017 seconds
2020-03-04 07:31:39,412 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5057
2020-03-04 07:41:39,575 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-03-04 07:41:39,576 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=623&endTxId=624&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-03-04 07:41:39,581 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-03-04 07:41:39,581 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000623-0000000000000000624_0000000000005462287 size 0 bytes.
2020-03-04 07:41:39,581 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-03-04 07:41:39,581 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000623-0000000000000000624 expecting start txid #623
2020-03-04 07:41:39,581 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000623-0000000000000000624
2020-03-04 07:41:39,581 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000623-0000000000000000624 of size 42 edits # 2 loaded in 0 seconds
2020-03-04 07:41:39,584 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000624 using no compression
2020-03-04 07:41:39,590 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000624 of size 5057 bytes saved in 0 seconds.
2020-03-04 07:41:39,609 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 622
2020-03-04 07:41:39,610 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000620, cpktTxId=0000000000000000620)
2020-03-04 07:41:39,643 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 624 to namenode at http://um1:50070 in 0.024 seconds
2020-03-04 07:41:39,643 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5057
2020-03-04 07:51:39,748 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-03-04 07:51:39,748 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=625&endTxId=626&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-03-04 07:51:39,755 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-03-04 07:51:39,755 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000625-0000000000000000626_0000000000006062460 size 0 bytes.
2020-03-04 07:51:39,755 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-03-04 07:51:39,755 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000625-0000000000000000626 expecting start txid #625
2020-03-04 07:51:39,755 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000625-0000000000000000626
2020-03-04 07:51:39,756 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000625-0000000000000000626 of size 42 edits # 2 loaded in 0 seconds
2020-03-04 07:51:39,756 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000626 using no compression
2020-03-04 07:51:39,763 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000626 of size 5057 bytes saved in 0 seconds.
2020-03-04 07:51:39,770 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 624
2020-03-04 07:51:39,770 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000622, cpktTxId=0000000000000000622)
2020-03-04 07:51:39,783 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 626 to namenode at http://um1:50070 in 0.01 seconds
2020-03-04 07:51:39,783 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5057
2020-03-04 08:01:40,000 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-03-04 08:01:40,000 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=627&endTxId=628&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-03-04 08:01:40,005 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-03-04 08:01:40,005 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000627-0000000000000000628_0000000000006662711 size 0 bytes.
2020-03-04 08:01:40,005 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-03-04 08:01:40,005 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000627-0000000000000000628 expecting start txid #627
2020-03-04 08:01:40,006 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000627-0000000000000000628
2020-03-04 08:01:40,006 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000627-0000000000000000628 of size 42 edits # 2 loaded in 0 seconds
2020-03-04 08:01:40,006 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000628 using no compression
2020-03-04 08:01:40,011 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000628 of size 5057 bytes saved in 0 seconds.
2020-03-04 08:01:40,013 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 626
2020-03-04 08:01:40,013 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000624, cpktTxId=0000000000000000624)
2020-03-04 08:01:40,027 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 628 to namenode at http://um1:50070 in 0.009 seconds
2020-03-04 08:01:40,027 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5057
2020-03-04 08:11:40,119 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-03-04 08:11:40,119 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=629&endTxId=630&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-03-04 08:11:40,124 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-03-04 08:11:40,124 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000629-0000000000000000630_0000000000007262831 size 0 bytes.
2020-03-04 08:11:40,124 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-03-04 08:11:40,124 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000629-0000000000000000630 expecting start txid #629
2020-03-04 08:11:40,124 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000629-0000000000000000630
2020-03-04 08:11:40,125 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000629-0000000000000000630 of size 42 edits # 2 loaded in 0 seconds
2020-03-04 08:11:40,125 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000630 using no compression
2020-03-04 08:11:40,129 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000630 of size 5057 bytes saved in 0 seconds.
2020-03-04 08:11:40,133 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 628
2020-03-04 08:11:40,133 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000626, cpktTxId=0000000000000000626)
2020-03-04 08:11:40,155 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 630 to namenode at http://um1:50070 in 0.013 seconds
2020-03-04 08:11:40,155 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5057
2020-03-04 08:21:40,233 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-03-04 08:21:40,233 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=631&endTxId=639&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-03-04 08:21:40,238 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-03-04 08:21:40,238 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000631-0000000000000000639_0000000000007862945 size 0 bytes.
2020-03-04 08:21:40,238 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-03-04 08:21:40,238 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000631-0000000000000000639 expecting start txid #631
2020-03-04 08:21:40,239 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000631-0000000000000000639
2020-03-04 08:21:40,261 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000631-0000000000000000639 of size 645 edits # 9 loaded in 0 seconds
2020-03-04 08:21:40,261 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000639 using no compression
2020-03-04 08:21:40,267 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000639 of size 5193 bytes saved in 0 seconds.
2020-03-04 08:21:40,270 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 630
2020-03-04 08:21:40,270 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000628, cpktTxId=0000000000000000628)
2020-03-04 08:21:40,287 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 639 to namenode at http://um1:50070 in 0.013 seconds
2020-03-04 08:21:40,287 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5193
2020-03-04 08:31:40,398 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-03-04 08:31:40,399 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=640&endTxId=647&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-03-04 08:31:40,405 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-03-04 08:31:40,405 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000640-0000000000000000647_0000000000008463110 size 0 bytes.
2020-03-04 08:31:40,406 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-03-04 08:31:40,406 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000640-0000000000000000647 expecting start txid #640
2020-03-04 08:31:40,406 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000640-0000000000000000647
2020-03-04 08:31:40,407 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000640-0000000000000000647 of size 573 edits # 8 loaded in 0 seconds
2020-03-04 08:31:40,413 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000647 using no compression
2020-03-04 08:31:40,416 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000647 of size 5260 bytes saved in 0 seconds.
2020-03-04 08:31:40,419 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 639
2020-03-04 08:31:40,420 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000630, cpktTxId=0000000000000000630)
2020-03-04 08:31:40,432 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 647 to namenode at http://um1:50070 in 0.01 seconds
2020-03-04 08:31:40,433 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5260
2020-03-04 08:41:40,573 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-03-04 08:41:40,574 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=648&endTxId=649&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-03-04 08:41:40,580 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-03-04 08:41:40,580 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000648-0000000000000000649_0000000000009063285 size 0 bytes.
2020-03-04 08:41:40,581 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-03-04 08:41:40,581 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000648-0000000000000000649 expecting start txid #648
2020-03-04 08:41:40,581 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000648-0000000000000000649
2020-03-04 08:41:40,581 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000648-0000000000000000649 of size 42 edits # 2 loaded in 0 seconds
2020-03-04 08:41:40,581 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000649 using no compression
2020-03-04 08:41:40,585 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000649 of size 5260 bytes saved in 0 seconds.
2020-03-04 08:41:40,591 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 647
2020-03-04 08:41:40,591 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000639, cpktTxId=0000000000000000639)
2020-03-04 08:41:40,602 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 649 to namenode at http://um1:50070 in 0.009 seconds
2020-03-04 08:41:40,602 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5260
2020-03-04 08:51:40,704 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-03-04 08:51:40,704 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=650&endTxId=651&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-03-04 08:51:40,709 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-03-04 08:51:40,709 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000650-0000000000000000651_0000000000009663415 size 0 bytes.
2020-03-04 08:51:40,709 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-03-04 08:51:40,709 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000650-0000000000000000651 expecting start txid #650
2020-03-04 08:51:40,709 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000650-0000000000000000651
2020-03-04 08:51:40,709 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000650-0000000000000000651 of size 42 edits # 2 loaded in 0 seconds
2020-03-04 08:51:40,710 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000651 using no compression
2020-03-04 08:51:40,716 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000651 of size 5260 bytes saved in 0 seconds.
2020-03-04 08:51:40,719 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 649
2020-03-04 08:51:40,719 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000647, cpktTxId=0000000000000000647)
2020-03-04 08:51:40,740 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 651 to namenode at http://um1:50070 in 0.012 seconds
2020-03-04 08:51:40,740 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5260
2020-03-04 09:01:40,868 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-03-04 09:01:40,868 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=652&endTxId=653&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-03-04 09:01:40,872 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-03-04 09:01:40,872 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000652-0000000000000000653_0000000000010263579 size 0 bytes.
2020-03-04 09:01:40,872 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-03-04 09:01:40,872 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000652-0000000000000000653 expecting start txid #652
2020-03-04 09:01:40,872 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000652-0000000000000000653
2020-03-04 09:01:40,872 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000652-0000000000000000653 of size 42 edits # 2 loaded in 0 seconds
2020-03-04 09:01:40,882 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000653 using no compression
2020-03-04 09:01:40,889 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000653 of size 5260 bytes saved in 0 seconds.
2020-03-04 09:01:40,893 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 651
2020-03-04 09:01:40,893 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000649, cpktTxId=0000000000000000649)
2020-03-04 09:01:40,904 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 653 to namenode at http://um1:50070 in 0.008 seconds
2020-03-04 09:01:40,904 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5260
2020-06-21 16:15:26,514 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = um2/192.168.251.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.6.5
STARTUP_MSG:   classpath = /usr/local/hadoop-2.6.5/etc/hadoop:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-auth-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/common/hadoop-common-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-client-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-api-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-registry-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.5-tests.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar:/usr/local/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e8c9fe0b4c252caf2ebf1464220599650f119997; compiled by 'sjlee' on 2016-10-02T23:43Z
STARTUP_MSG:   java = 1.8.0_221
************************************************************/
2020-06-21 16:15:26,585 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-06-21 16:15:28,132 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-06-21 16:15:28,481 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-06-21 16:15:28,481 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2020-06-21 16:15:29,002 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnfsi should be specified as a URI in configuration files. Please update hdfs configuration.
2020-06-21 16:15:29,003 WARN org.apache.hadoop.hdfs.server.common.Util: Path /orgz/snnedits should be specified as a URI in configuration files. Please update hdfs configuration.
2020-06-21 16:15:29,231 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnfsi/in_use.lock acquired by nodename 3210@um2
2020-06-21 16:15:29,439 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /orgz/snnedits/in_use.lock acquired by nodename 3210@um2
2020-06-21 16:15:29,487 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2020-06-21 16:15:29,521 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2020-06-21 16:15:29,647 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2020-06-21 16:15:29,647 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2020-06-21 16:15:29,651 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-06-21 16:15:29,655 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2020 Jun 21 16:15:29
2020-06-21 16:15:29,658 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2020-06-21 16:15:29,658 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-06-21 16:15:29,660 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2020-06-21 16:15:29,660 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2020-06-21 16:15:29,695 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2020-06-21 16:15:29,696 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 2
2020-06-21 16:15:29,696 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2020-06-21 16:15:29,696 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2020-06-21 16:15:29,697 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2020-06-21 16:15:29,697 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2020-06-21 16:15:29,697 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2020-06-21 16:15:29,697 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2020-06-21 16:15:29,699 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hdu (auth:SIMPLE)
2020-06-21 16:15:29,699 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2020-06-21 16:15:29,699 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2020-06-21 16:15:29,700 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2020-06-21 16:15:29,704 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2020-06-21 16:15:31,250 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2020-06-21 16:15:31,250 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-06-21 16:15:31,251 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2020-06-21 16:15:31,251 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2020-06-21 16:15:31,308 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2020-06-21 16:15:31,331 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2020-06-21 16:15:31,331 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2020-06-21 16:15:31,332 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2020-06-21 16:15:31,332 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2020-06-21 16:15:31,400 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-06-21 16:15:31,400 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2020-06-21 16:15:31,400 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2020-06-21 16:15:31,403 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2020-06-21 16:15:31,403 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2020-06-21 16:15:31,403 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2020-06-21 16:15:31,503 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://um2:50090
2020-06-21 16:15:31,762 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-06-21 16:15:31,778 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2020-06-21 16:15:31,823 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-06-21 16:15:31,837 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2020-06-21 16:15:31,837 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-06-21 16:15:31,837 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-06-21 16:15:32,331 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2020-06-21 16:15:32,341 INFO org.mortbay.log: jetty-6.1.26
2020-06-21 16:15:33,199 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@um2:50090
2020-06-21 16:15:33,199 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2020-06-21 16:15:33,200 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :600 secs (10 min)
2020-06-21 16:15:33,200 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2020-06-21 16:16:34,234 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2020-06-21 16:16:35,571 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getimage=1&txid=674&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-06-21 16:16:35,988 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2020-06-21 16:16:36,764 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 294.12 KB/s
2020-06-21 16:16:36,764 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000674 size 5540 bytes.
2020-06-21 16:16:36,799 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=675&endTxId=676&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-06-21 16:16:36,828 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-06-21 16:16:36,828 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000675-0000000000000000676_0000000000000689710 size 0 bytes.
2020-06-21 16:16:37,317 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 67 INodes.
2020-06-21 16:16:37,601 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2020-06-21 16:16:37,602 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 674 from /orgz/snnfsi/current/fsimage_0000000000000000674
2020-06-21 16:16:37,602 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2020-06-21 16:16:37,656 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-06-21 16:16:37,696 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000675-0000000000000000676 expecting start txid #675
2020-06-21 16:16:37,697 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000675-0000000000000000676
2020-06-21 16:16:37,856 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000675-0000000000000000676 of size 42 edits # 2 loaded in 0 seconds
2020-06-21 16:16:37,935 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000676 using no compression
2020-06-21 16:16:38,298 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000676 of size 5540 bytes saved in 0 seconds.
2020-06-21 16:16:38,389 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 674
2020-06-21 16:16:38,390 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000653, cpktTxId=0000000000000000653)
2020-06-21 16:16:38,392 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000651, cpktTxId=0000000000000000651)
2020-06-21 16:16:38,764 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 676 to namenode at http://um1:50070 in 0.166 seconds
2020-06-21 16:16:38,764 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5540
2020-06-21 16:26:39,014 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-06-21 16:26:39,015 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=677&endTxId=678&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-06-21 16:26:39,044 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 0.00 KB/s
2020-06-21 16:26:39,044 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000677-0000000000000000678_0000000000001291926 size 0 bytes.
2020-06-21 16:26:39,045 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-06-21 16:26:39,045 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000677-0000000000000000678 expecting start txid #677
2020-06-21 16:26:39,045 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000677-0000000000000000678
2020-06-21 16:26:39,047 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000677-0000000000000000678 of size 42 edits # 2 loaded in 0 seconds
2020-06-21 16:26:39,050 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000678 using no compression
2020-06-21 16:26:39,066 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000678 of size 5540 bytes saved in 0 seconds.
2020-06-21 16:26:39,073 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 676
2020-06-21 16:26:39,073 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000674, cpktTxId=0000000000000000674)
2020-06-21 16:26:39,137 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 678 to namenode at http://um1:50070 in 0.029 seconds
2020-06-21 16:26:39,137 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5540
2020-06-21 16:36:39,323 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-06-21 16:36:39,323 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=679&endTxId=681&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-06-21 16:36:39,329 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-06-21 16:36:39,329 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000679-0000000000000000681_0000000000001892235 size 0 bytes.
2020-06-21 16:36:39,329 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-06-21 16:36:39,329 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000679-0000000000000000681 expecting start txid #679
2020-06-21 16:36:39,329 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000679-0000000000000000681
2020-06-21 16:36:39,344 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000679-0000000000000000681 of size 122 edits # 3 loaded in 0 seconds
2020-06-21 16:36:39,345 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000681 using no compression
2020-06-21 16:36:39,362 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000681 of size 5606 bytes saved in 0 seconds.
2020-06-21 16:36:39,367 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 678
2020-06-21 16:36:39,368 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000676, cpktTxId=0000000000000000676)
2020-06-21 16:36:39,390 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 681 to namenode at http://um1:50070 in 0.015 seconds
2020-06-21 16:36:39,390 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5606
2020-06-21 16:46:39,519 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-06-21 16:46:39,520 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=682&endTxId=683&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-06-21 16:46:39,526 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-06-21 16:46:39,527 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000682-0000000000000000683_0000000000002492432 size 0 bytes.
2020-06-21 16:46:39,527 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-06-21 16:46:39,527 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000682-0000000000000000683 expecting start txid #682
2020-06-21 16:46:39,528 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000682-0000000000000000683
2020-06-21 16:46:39,529 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000682-0000000000000000683 of size 42 edits # 2 loaded in 0 seconds
2020-06-21 16:46:39,530 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000683 using no compression
2020-06-21 16:46:39,539 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000683 of size 5606 bytes saved in 0 seconds.
2020-06-21 16:46:39,544 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 681
2020-06-21 16:46:39,544 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000678, cpktTxId=0000000000000000678)
2020-06-21 16:46:39,560 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 683 to namenode at http://um1:50070 in 0.011 seconds
2020-06-21 16:46:39,561 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5606
2020-06-21 16:56:39,695 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2020-06-21 16:56:39,695 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://um1:50070/imagetransfer?getedit=1&startTxId=684&endTxId=685&storageInfo=-60:1764777453:0:CID-fa1ec920-c1b6-432b-9ffe-7f9053fe4aea
2020-06-21 16:56:39,703 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2020-06-21 16:56:39,703 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000684-0000000000000000685_0000000000003092607 size 0 bytes.
2020-06-21 16:56:39,704 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2020-06-21 16:56:39,704 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /orgz/snnedits/current/edits_0000000000000000684-0000000000000000685 expecting start txid #684
2020-06-21 16:56:39,704 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /orgz/snnedits/current/edits_0000000000000000684-0000000000000000685
2020-06-21 16:56:39,704 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /orgz/snnedits/current/edits_0000000000000000684-0000000000000000685 of size 42 edits # 2 loaded in 0 seconds
2020-06-21 16:56:39,705 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000685 using no compression
2020-06-21 16:56:39,711 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /orgz/snnfsi/current/fsimage.ckpt_0000000000000000685 of size 5606 bytes saved in 0 seconds.
2020-06-21 16:56:39,714 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 683
2020-06-21 16:56:39,714 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/orgz/snnfsi/current/fsimage_0000000000000000681, cpktTxId=0000000000000000681)
2020-06-21 16:56:39,735 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 685 to namenode at http://um1:50070 in 0.014 seconds
2020-06-21 16:56:39,735 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 5606
