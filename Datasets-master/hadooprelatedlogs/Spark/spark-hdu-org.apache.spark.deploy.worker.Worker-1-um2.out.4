Spark Command: /usr/lib/jvm/jdk1.8.0_221/bin/java -cp /usr/local/spark/conf/:/usr/local/spark/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://um1:7077
========================================
2020-01-26 22:08:50 INFO  Worker:2612 - Started daemon with process name: 3098@um2
2020-01-26 22:08:50 INFO  SignalUtils:54 - Registered signal handler for TERM
2020-01-26 22:08:50 INFO  SignalUtils:54 - Registered signal handler for HUP
2020-01-26 22:08:50 INFO  SignalUtils:54 - Registered signal handler for INT
2020-01-26 22:08:51 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-01-26 22:08:51 INFO  SecurityManager:54 - Changing view acls to: hdu
2020-01-26 22:08:51 INFO  SecurityManager:54 - Changing modify acls to: hdu
2020-01-26 22:08:51 INFO  SecurityManager:54 - Changing view acls groups to: 
2020-01-26 22:08:51 INFO  SecurityManager:54 - Changing modify acls groups to: 
2020-01-26 22:08:51 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hdu); groups with view permissions: Set(); users  with modify permissions: Set(hdu); groups with modify permissions: Set()
2020-01-26 22:08:51 INFO  Utils:54 - Successfully started service 'sparkWorker' on port 36681.
2020-01-26 22:08:52 INFO  Worker:54 - Starting Spark worker 192.168.251.4:36681 with 2 cores, 6.6 GB RAM
2020-01-26 22:08:52 INFO  Worker:54 - Running Spark version 2.3.3
2020-01-26 22:08:52 INFO  Worker:54 - Spark home: /usr/local/spark
2020-01-26 22:08:52 INFO  log:192 - Logging initialized @3531ms
2020-01-26 22:08:52 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-01-26 22:08:52 INFO  Server:419 - Started @3650ms
2020-01-26 22:08:52 INFO  AbstractConnector:278 - Started ServerConnector@51e8343b{HTTP/1.1,[http/1.1]}{0.0.0.0:8081}
2020-01-26 22:08:52 INFO  Utils:54 - Successfully started service 'WorkerUI' on port 8081.
2020-01-26 22:08:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@36ed2e08{/logPage,null,AVAILABLE,@Spark}
2020-01-26 22:08:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@362b9065{/logPage/json,null,AVAILABLE,@Spark}
2020-01-26 22:08:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a890228{/,null,AVAILABLE,@Spark}
2020-01-26 22:08:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d95ee79{/json,null,AVAILABLE,@Spark}
2020-01-26 22:08:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@27d7f716{/static,null,AVAILABLE,@Spark}
2020-01-26 22:08:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67f47b4c{/log,null,AVAILABLE,@Spark}
2020-01-26 22:08:52 INFO  WorkerWebUI:54 - Bound WorkerWebUI to 0.0.0.0, and started at http://um2:8081
2020-01-26 22:08:52 INFO  Worker:54 - Connecting to master um1:7077...
2020-01-26 22:08:52 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e609625{/metrics/json,null,AVAILABLE,@Spark}
2020-01-26 22:08:52 INFO  TransportClientFactory:267 - Successfully created connection to um1/192.168.251.3:7077 after 37 ms (0 ms spent in bootstraps)
2020-01-26 22:08:53 INFO  Worker:54 - Successfully registered with master spark://um1:7077
2020-01-26 23:20:22 INFO  Worker:54 - Asked to launch executor app-20200126232022-0000/1 for PySparkShell
2020-01-26 23:20:22 INFO  SecurityManager:54 - Changing view acls to: hdu
2020-01-26 23:20:22 INFO  SecurityManager:54 - Changing modify acls to: hdu
2020-01-26 23:20:22 INFO  SecurityManager:54 - Changing view acls groups to: 
2020-01-26 23:20:22 INFO  SecurityManager:54 - Changing modify acls groups to: 
2020-01-26 23:20:22 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hdu); groups with view permissions: Set(); users  with modify permissions: Set(hdu); groups with modify permissions: Set()
2020-01-26 23:20:22 INFO  ExecutorRunner:54 - Launch command: "/usr/lib/jvm/jdk1.8.0_221/bin/java" "-cp" "/usr/local/spark/conf/:/usr/local/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=46133" "-XX:+PrintGCDetails" "-Dkey=value" "-Dnumbers=one two three" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@um1:46133" "--executor-id" "1" "--hostname" "192.168.251.4" "--cores" "2" "--app-id" "app-20200126232022-0000" "--worker-url" "spark://Worker@192.168.251.4:36681"
2020-01-27 00:01:12 INFO  Worker:54 - Asked to kill executor app-20200126232022-0000/1
2020-01-27 00:01:12 INFO  ExecutorRunner:54 - Runner thread for executor app-20200126232022-0000/1 interrupted
2020-01-27 00:01:12 INFO  ExecutorRunner:54 - Killing process!
2020-01-27 00:01:12 INFO  Worker:54 - Executor app-20200126232022-0000/1 finished with state KILLED exitStatus 0
2020-01-27 00:01:12 INFO  ExternalShuffleBlockResolver:186 - Application app-20200126232022-0000 removed, cleanupLocalDirs = true
2020-01-27 00:01:12 INFO  Worker:54 - Cleaning up local directories for application app-20200126232022-0000
2020-01-27 00:01:20 INFO  Worker:54 - Asked to launch executor app-20200127000120-0001/1 for PySparkShell
2020-01-27 00:01:20 INFO  SecurityManager:54 - Changing view acls to: hdu
2020-01-27 00:01:20 INFO  SecurityManager:54 - Changing modify acls to: hdu
2020-01-27 00:01:20 INFO  SecurityManager:54 - Changing view acls groups to: 
2020-01-27 00:01:20 INFO  SecurityManager:54 - Changing modify acls groups to: 
2020-01-27 00:01:20 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hdu); groups with view permissions: Set(); users  with modify permissions: Set(hdu); groups with modify permissions: Set()
2020-01-27 00:01:20 INFO  ExecutorRunner:54 - Launch command: "/usr/lib/jvm/jdk1.8.0_221/bin/java" "-cp" "/usr/local/spark/conf/:/usr/local/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=44435" "-XX:+PrintGCDetails" "-Dkey=value" "-Dnumbers=one two three" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@um1:44435" "--executor-id" "1" "--hostname" "192.168.251.4" "--cores" "2" "--app-id" "app-20200127000120-0001" "--worker-url" "spark://Worker@192.168.251.4:36681"
2020-01-27 00:02:41 INFO  Worker:54 - Asked to kill executor app-20200127000120-0001/1
2020-01-27 00:02:41 INFO  ExecutorRunner:54 - Runner thread for executor app-20200127000120-0001/1 interrupted
2020-01-27 00:02:41 INFO  ExecutorRunner:54 - Killing process!
2020-01-27 00:02:41 INFO  Worker:54 - Executor app-20200127000120-0001/1 finished with state KILLED exitStatus 0
2020-01-27 00:02:41 INFO  ExternalShuffleBlockResolver:186 - Application app-20200127000120-0001 removed, cleanupLocalDirs = true
2020-01-27 00:02:41 INFO  Worker:54 - Cleaning up local directories for application app-20200127000120-0001
2020-01-27 00:02:49 INFO  Worker:54 - Asked to launch executor app-20200127000249-0002/1 for PySparkShell
2020-01-27 00:02:49 INFO  SecurityManager:54 - Changing view acls to: hdu
2020-01-27 00:02:49 INFO  SecurityManager:54 - Changing modify acls to: hdu
2020-01-27 00:02:49 INFO  SecurityManager:54 - Changing view acls groups to: 
2020-01-27 00:02:49 INFO  SecurityManager:54 - Changing modify acls groups to: 
2020-01-27 00:02:49 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hdu); groups with view permissions: Set(); users  with modify permissions: Set(hdu); groups with modify permissions: Set()
2020-01-27 00:02:49 INFO  ExecutorRunner:54 - Launch command: "/usr/lib/jvm/jdk1.8.0_221/bin/java" "-cp" "/usr/local/spark/conf/:/usr/local/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=45349" "-XX:+PrintGCDetails" "-Dkey=value" "-Dnumbers=one two three" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@um1:45349" "--executor-id" "1" "--hostname" "192.168.251.4" "--cores" "2" "--app-id" "app-20200127000249-0002" "--worker-url" "spark://Worker@192.168.251.4:36681"
2020-01-27 00:05:26 INFO  Worker:54 - Asked to kill executor app-20200127000249-0002/1
2020-01-27 00:05:26 INFO  ExecutorRunner:54 - Runner thread for executor app-20200127000249-0002/1 interrupted
2020-01-27 00:05:26 INFO  ExecutorRunner:54 - Killing process!
2020-01-27 00:05:27 INFO  Worker:54 - Executor app-20200127000249-0002/1 finished with state KILLED exitStatus 143
2020-01-27 00:05:27 INFO  ExternalShuffleBlockResolver:186 - Application app-20200127000249-0002 removed, cleanupLocalDirs = true
2020-01-27 00:05:27 INFO  Worker:54 - Cleaning up local directories for application app-20200127000249-0002
2020-01-27 00:05:40 INFO  Worker:54 - Asked to launch executor app-20200127000540-0003/1 for PySparkShell
2020-01-27 00:05:40 INFO  SecurityManager:54 - Changing view acls to: hdu
2020-01-27 00:05:40 INFO  SecurityManager:54 - Changing modify acls to: hdu
2020-01-27 00:05:40 INFO  SecurityManager:54 - Changing view acls groups to: 
2020-01-27 00:05:40 INFO  SecurityManager:54 - Changing modify acls groups to: 
2020-01-27 00:05:40 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hdu); groups with view permissions: Set(); users  with modify permissions: Set(hdu); groups with modify permissions: Set()
2020-01-27 00:05:40 INFO  ExecutorRunner:54 - Launch command: "/usr/lib/jvm/jdk1.8.0_221/bin/java" "-cp" "/usr/local/spark/conf/:/usr/local/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=38115" "-XX:+PrintGCDetails" "-Dkey=value" "-Dnumbers=one two three" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@um1:38115" "--executor-id" "1" "--hostname" "192.168.251.4" "--cores" "2" "--app-id" "app-20200127000540-0003" "--worker-url" "spark://Worker@192.168.251.4:36681"
2020-01-27 00:20:57 INFO  Worker:54 - Asked to kill executor app-20200127000540-0003/1
2020-01-27 00:20:57 INFO  ExecutorRunner:54 - Runner thread for executor app-20200127000540-0003/1 interrupted
2020-01-27 00:20:57 INFO  ExecutorRunner:54 - Killing process!
2020-01-27 00:20:57 INFO  Worker:54 - Executor app-20200127000540-0003/1 finished with state KILLED exitStatus 143
2020-01-27 00:20:57 INFO  ExternalShuffleBlockResolver:186 - Application app-20200127000540-0003 removed, cleanupLocalDirs = true
2020-01-27 00:20:57 INFO  Worker:54 - Cleaning up local directories for application app-20200127000540-0003
2020-01-27 00:21:07 INFO  Worker:54 - Asked to launch executor app-20200127002107-0004/1 for PySparkShell
2020-01-27 00:21:07 INFO  SecurityManager:54 - Changing view acls to: hdu
2020-01-27 00:21:07 INFO  SecurityManager:54 - Changing modify acls to: hdu
2020-01-27 00:21:07 INFO  SecurityManager:54 - Changing view acls groups to: 
2020-01-27 00:21:07 INFO  SecurityManager:54 - Changing modify acls groups to: 
2020-01-27 00:21:07 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hdu); groups with view permissions: Set(); users  with modify permissions: Set(hdu); groups with modify permissions: Set()
2020-01-27 00:21:07 INFO  ExecutorRunner:54 - Launch command: "/usr/lib/jvm/jdk1.8.0_221/bin/java" "-cp" "/usr/local/spark/conf/:/usr/local/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=33069" "-XX:+PrintGCDetails" "-Dkey=value" "-Dnumbers=one two three" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@um1:33069" "--executor-id" "1" "--hostname" "192.168.251.4" "--cores" "2" "--app-id" "app-20200127002107-0004" "--worker-url" "spark://Worker@192.168.251.4:36681"
2020-01-27 00:30:45 INFO  Worker:54 - Asked to kill executor app-20200127002107-0004/1
2020-01-27 00:30:45 INFO  ExecutorRunner:54 - Runner thread for executor app-20200127002107-0004/1 interrupted
2020-01-27 00:30:45 INFO  ExecutorRunner:54 - Killing process!
2020-01-27 00:30:46 INFO  Worker:54 - Executor app-20200127002107-0004/1 finished with state KILLED exitStatus 143
2020-01-27 00:30:46 INFO  ExternalShuffleBlockResolver:186 - Application app-20200127002107-0004 removed, cleanupLocalDirs = true
2020-01-27 00:30:46 INFO  Worker:54 - Cleaning up local directories for application app-20200127002107-0004
2020-01-27 00:33:44 INFO  Worker:54 - Asked to launch executor app-20200127003344-0005/1 for PySparkShell
2020-01-27 00:33:44 INFO  SecurityManager:54 - Changing view acls to: hdu
2020-01-27 00:33:44 INFO  SecurityManager:54 - Changing modify acls to: hdu
2020-01-27 00:33:44 INFO  SecurityManager:54 - Changing view acls groups to: 
2020-01-27 00:33:44 INFO  SecurityManager:54 - Changing modify acls groups to: 
2020-01-27 00:33:44 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hdu); groups with view permissions: Set(); users  with modify permissions: Set(hdu); groups with modify permissions: Set()
2020-01-27 00:33:44 INFO  ExecutorRunner:54 - Launch command: "/usr/lib/jvm/jdk1.8.0_221/bin/java" "-cp" "/usr/local/spark/conf/:/usr/local/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=40439" "-XX:+PrintGCDetails" "-Dkey=value" "-Dnumbers=one two three" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@um1:40439" "--executor-id" "1" "--hostname" "192.168.251.4" "--cores" "2" "--app-id" "app-20200127003344-0005" "--worker-url" "spark://Worker@192.168.251.4:36681"
